<!-- doc/src/sgml/arch-dev.sgml -->

 <chapter id="overview">
<!--
  <title>Overview of PostgreSQL Internals</title>
-->
  <title>PostgreSQL内部の概要</title>

  <note>
<!--
   <title>Author</title>
-->
   <title>著者</title>
   <para>
<!--
    This chapter originated as part of
    <xref linkend="SIM98">, Stefan Simkovics'
    Master's Thesis prepared at Vienna University of Technology under the direction
    of O.Univ.Prof.Dr. Georg Gottlob and Univ.Ass. Mag. Katrin Seyr.
-->
本章は<xref linkend="SIM98">として、 ウィーン工科大学にてO.Univ.Prof.Dr. Georg GottlobとUniv.Ass.Mag. Katrin Seyr.の指導の下にStefan Simkovicsが書いた修士論文の一部が基になっています。
   </para>
  </note>

  <para>
<!--
   This chapter gives an overview of the internal structure of the
   backend of <productname>PostgreSQL</productname>.  After having
   read the following sections you should have an idea of how a query
   is processed. This chapter does not aim to provide a detailed
   description of the internal operation of
   <productname>PostgreSQL</productname>, as such a document would be
   very extensive. Rather, this chapter is intended to help the reader
   understand the general sequence of operations that occur within the
   backend from the point at which a query is received, to the point
   at which the results are returned to the client.
-->
本章では<productname>PostgreSQL</productname>のバックエンドの内部構造の概要を説明します。
次からの節を読んだ後には、問い合わせがどのように処理されるかの概念がつかめているはずです。
ここでは<productname>PostgreSQL</productname>の内部操作の詳細な説明は行いません。
記述するとしたら文章が膨大になってしまうからです。
どちらかと言えば、バックエンドが問い合わせを受け取った時点からクライアントに結果を返す時点の間に引き起こる操作の一般的な流れを理解してもらうのが目的です。
  </para>

  <sect1 id="query-path">
<!--
   <title>The Path of a Query</title>
-->
   <title>問い合わせの経路</title>

   <para>
<!--
    Here we give a short overview of the stages a query has to pass in
    order to obtain a result.
-->
ここでは、問い合わせが結果を得るためにたどる過程を簡単に説明します。
   </para>

   <procedure>
    <step>
     <para>
<!--
      A connection from an application program to the <productname>PostgreSQL</productname>
      server has to be established. The application program transmits a
      query to the server and waits to receive the results sent back by the
      server.
-->
アプリケーションプログラムから<productname>PostgreSQL</productname>サーバに接続が確立されなくてはなりません。
アプリケーションプログラムはサーバに問い合わせを送り、そしてサーバから送り返される結果を待ちます。
     </para>
    </step>

    <step>
     <para>
<!--
      The <firstterm>parser stage</firstterm> checks the query
      transmitted by the application
      program for correct syntax and creates
      a <firstterm>query tree</firstterm>.
-->
<firstterm>構文解析過程</firstterm>で、アプリケーションプログラムから送られた問い合わせの構文が正しいかをチェックし、<firstterm>問い合わせツリー</firstterm>を作成します。
     </para>
    </step>

    <step>
     <para>
<!--
      The <firstterm>rewrite system</firstterm> takes
      the query tree created by the parser stage and looks for
      any <firstterm>rules</firstterm> (stored in the
      <firstterm>system catalogs</firstterm>) to apply to
      the query tree.  It performs the
      transformations given in the <firstterm>rule bodies</firstterm>.
-->
<firstterm>書き換えシステム</firstterm>は構文解析過程で作られた問い合わせツリーを受け取り、<firstterm>問い合わせツリー</firstterm>に適用するための（<firstterm>システムカタログ</firstterm>に格納されている）<firstterm>ルール</firstterm>を探します。
そして<firstterm>ルール本体</firstterm>で与えられた変換を実行します。
     </para>

     <para>
<!--
      One application of the rewrite system is in the realization of
      <firstterm>views</firstterm>.
      Whenever a query against a view
      (i.e., a <firstterm>virtual table</firstterm>) is made,
      the rewrite system rewrites the user's query to
      a query that accesses the <firstterm>base tables</firstterm> given in
      the <firstterm>view definition</firstterm> instead.
-->
書き換えシステムの適用例の1つとして<firstterm>ビュー</firstterm>の具現化が挙げられます。
ビュー（すなわち<firstterm>仮想テーブル</firstterm>）に対して問い合わせがあると、書き換えシステムが代わってユーザの問い合わせを、<firstterm>ビュー定義</firstterm>で与えられた<firstterm>実テーブル</firstterm>にアクセスする問い合わせに書き換えます。
     </para>
    </step>

    <step>
     <para>
<!--
      The <firstterm>planner/optimizer</firstterm> takes
      the (rewritten) query tree and creates a
      <firstterm>query plan</firstterm> that will be the input to the
      <firstterm>executor</firstterm>.
-->
<firstterm>プランナ/オプティマイザ</firstterm>は、（書き換えられた）問い合わせツリーを見て、<firstterm>エクゼキュータ</firstterm>に渡すための<firstterm>問い合わせ計画</firstterm>を作ります。
     </para>

     <para>
<!--
      It does so by first creating all possible <firstterm>paths</firstterm>
      leading to the same result. For example if there is an index on a
      relation to be scanned, there are two paths for the
      scan. One possibility is a simple sequential scan and the other
      possibility is to use the index. Next the cost for the execution of
      each path is estimated and the cheapest path is chosen.  The cheapest
      path is expanded into a complete plan that the executor can use.
-->
そのためにまず同じ結果をもたらす全ての可能な限りの<firstterm>経路</firstterm>を作ります。
例えば、スキャンの対象となるリレーション上にインデックスがあるとすると2つの経路があります。
1つは単純なシーケンシャルスキャンで、もう1つはインデックスを使ったスキャンです。
次にそれぞれの経路を実行するためのコストが見積もられ、一番コストの小さい経路が選ばれます。
一番コストの小さな経路は、エクゼキュータが実行できるように完全な計画に拡張されます。
     </para>
    </step>

    <step>
     <para>
<!--
      The executor recursively steps through
      the <firstterm>plan tree</firstterm> and
      retrieves rows in the way represented by the plan.
      The executor makes use of the
      <firstterm>storage system</firstterm> while scanning
      relations, performs <firstterm>sorts</firstterm> and <firstterm>joins</firstterm>,
      evaluates <firstterm>qualifications</firstterm> and finally hands back the rows derived.
-->
エクゼキュータは再帰的に<firstterm>計画ツリー</firstterm>上を進み、計画で示されている方法で行を抽出します。
エクゼキュータはリレーションをスキャンする間<firstterm>保存システム</firstterm>を利用して<firstterm>ソート</firstterm>と<firstterm>結合</firstterm>を実行し、<firstterm>検索条件</firstterm>の評価を行い、最後に得られた行を返します。
     </para>
    </step>
   </procedure>

   <para>
<!--
    In the following sections we will cover each of the above listed items
    in more detail to give a better understanding of <productname>PostgreSQL</productname>'s internal
    control and data structures.
-->
これからの節では、<productname>PostgreSQL</productname>の内部制御とデータ構造をより良く理解するために、上に記載した事柄をさらに詳しく説明します。
   </para>
  </sect1>

  <sect1 id="connect-estab">
<!--
   <title>How Connections are Established</title>
-->
   <title>接続の確立</title>

   <para>
<!--
    <productname>PostgreSQL</productname> is implemented using a
    simple <quote>process per user</> client/server model.  In this model
    there is one <firstterm>client process</firstterm> connected to
    exactly one <firstterm>server process</firstterm>.  As we do not
    know ahead of time how many connections will be made, we have to
    use a <firstterm>master process</firstterm> that spawns a new
    server process every time a connection is requested. This master
    process is called <literal>postgres</literal> and listens at a
    specified TCP/IP port for incoming connections. Whenever a request
    for a connection is detected the <literal>postgres</literal>
    process spawns a new server process. The server tasks
    communicate with each other using <firstterm>semaphores</firstterm> and
    <firstterm>shared memory</firstterm> to ensure data integrity
    throughout concurrent data access.
-->
<productname>PostgreSQL</productname>は単純な「1プロセスに1ユーザ」のクライアント/サーバモデルによって実装されています。
このモデルでは1つの<firstterm>サーバプロセス</firstterm>に対し厳密に1つの<firstterm>クライアントプロセス</firstterm>しか存在しません。
いくつの接続が行われるか事前にわからないので、接続要求の度に新しいプロセスを作る<firstterm>マスタープロセス</firstterm>を使わなければなりません。
このマスタープロセスは<literal>postgres</literal>と呼ばれ、指定されたTCP/IPポートで入ってくる接続要求を監視します。
接続要求を検出すると、<literal>postgres</literal>プロセスは新しいサーバプロセスを生み出します。
このサーバのタスクは<firstterm>セマフォ</firstterm>と<firstterm>共有メモリ</firstterm>を活用してお互いに連絡を取り合い、同時にデータにアクセスしても整合性が保たれるようにします。
   </para>

   <para>
<!--
    The client process can be any program that understands the
    <productname>PostgreSQL</productname> protocol described in
    <xref linkend="protocol">.  Many clients are based on the
    C-language library <application>libpq</>, but several independent
    implementations of the protocol exist, such as the Java
    <application>JDBC</> driver.
-->
クライアントプロセスは<xref linkend="protocol">に記載された<productname>PostgreSQL</productname>プロトコルを理解できるどんなプログラムでも構いません。
多くのクライアントは<application>libpq</> C言語ライブラリに基づいていますが、Java <application>JDBC</>ドライバのようにいくつかの独立したプロトコル実装も存在します。
   </para>

   <para>
<!--
    Once a connection is established the client process can send a query
    to the <firstterm>backend</firstterm> (server). The query is transmitted using plain text,
    i.e., there is no parsing done in the <firstterm>frontend</firstterm> (client). The
    server parses the query, creates an <firstterm>execution plan</firstterm>,
    executes the plan and returns the retrieved rows to the client
    by transmitting them over the established connection.
-->
いったん接続が確立されると、クライアントプロセスは<firstterm>バックエンド</firstterm>（サーバ）に問い合わせを送ることができます。
問い合わせは平文で送信されます。
つまり、<firstterm>フロントエンド</firstterm>（クライアント）は構文解析を行いません。
サーバは問い合わせの構文解析を行い、<firstterm>実行計画</firstterm>を作り、そして計画を実行し、抽出した行を確立された接続を通じてクライアントに返します。
   </para>
  </sect1>

  <sect1 id="parser-stage">
<!--
   <title>The Parser Stage</title>
-->
   <title>構文解析過程</title>

   <para>
<!--
    The <firstterm>parser stage</firstterm> consists of two parts:
-->
<firstterm>構文解析過程</firstterm>は2つの部分から構成されています。

    <itemizedlist>
     <listitem>
      <para>
<!--
       The <firstterm>parser</firstterm> defined in
       <filename>gram.y</filename> and <filename>scan.l</filename> is
       built using the Unix tools <application>bison</application>
       and <application>flex</application>.
-->
<filename>gram.y</filename>と<filename>scan.l</filename>で定義されている<firstterm>パーサ</firstterm>は、Unixのツール<application>bison</application>と<application>flex</application>を使って構築されます。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       The <firstterm>transformation process</firstterm> does
       modifications and augmentations to the data structures returned by the parser.
-->
<firstterm>変換プロセス</firstterm>は、パーサから返されたデータ構造の変更や追加を行います。
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <sect2>
<!--
    <title>Parser</title>
-->
    <title>パーサ</title>

    <para>
<!--
     The parser has to check the query string (which arrives as plain
     text) for valid syntax. If the syntax is correct a
     <firstterm>parse tree</firstterm> is built up and handed back;
     otherwise an error is returned. The parser and lexer are
     implemented using the well-known Unix tools <application>bison</>
     and <application>flex</>.
-->
パーサは、（平文のテキストとして渡される）問い合わせ文字列が正しい構文になっているかチェックしなければいけません。
もし構文が正しい場合は<firstterm>構文解析ツリー</firstterm>が作られて返されます。 
正しくない場合はエラーが返されます。
パーサと字句解析はUnixでよく知られたツールの<application>bison</>と<application>flex</>を使用して実装されています。
    </para>

    <para>
<!--
     The <firstterm>lexer</firstterm> is defined in the file
     <filename>scan.l</filename> and is responsible
     for recognizing <firstterm>identifiers</firstterm>,
     the <firstterm>SQL key words</firstterm> etc. For
     every key word or identifier that is found, a <firstterm>token</firstterm>
     is generated and handed to the parser.
-->
<firstterm>字句解析</firstterm>はファイル<filename>scan.l</filename>で定義され、<firstterm>識別子</firstterm>や<firstterm>SQLキーワード</firstterm>などの確認を担当します。
検出された全てのキーワードや識別子に対し<firstterm>トークン</firstterm>が生成されパーサに渡されます。
    </para>

    <para>
<!--
     The parser is defined in the file <filename>gram.y</filename> and
     consists of a set of <firstterm>grammar rules</firstterm> and
     <firstterm>actions</firstterm> that are executed whenever a rule
     is fired. The code of the actions (which is actually C code) is
     used to build up the parse tree.
-->
パーサはファイル<filename>gram.y</filename>の中で定義され、<firstterm>文法ルール</firstterm>とルールが実行された時に実行される<firstterm>アクション</firstterm>の組から構成されています。
アクションのコード（実際はC言語コードです）は構文解析ツリーを作るのに使われます。
    </para>

    <para>
<!--
     The file <filename>scan.l</filename> is transformed to the C
     source file <filename>scan.c</filename> using the program
     <application>flex</application> and <filename>gram.y</filename> is
     transformed to <filename>gram.c</filename> using
     <application>bison</application>.  After these transformations
     have taken place a normal C compiler can be used to create the
     parser. Never make any changes to the generated C files as they
     will be overwritten the next time <application>flex</application>
     or <application>bison</application> is called.
-->
ファイル<filename>scan.l</filename>はプログラム<application>flex</application>を使ってCのソースファイル<filename>scan.c</filename>に変換されます。
そして<filename>gram.y</filename>は<application>bison</application>を使って<filename>gram.c</filename>に書き換えられます。
これらの書き換えが終わると、パーサを作るために通常のCコンパイラが使えるようになります。
生成されたCのファイルには絶対に変更を加えないでください。
と言うのは次に<application>flex</application>もしくは<application>bison</application> が呼ばれた時に上書きされるからです。

     <note>
      <para>
<!--
       The mentioned transformations and compilations are normally done
       automatically using the <firstterm>makefiles</firstterm>
       shipped with the <productname>PostgreSQL</productname>
       source distribution.
-->
ここで言及した書き換えやコンパイルは通常<productname>PostgreSQL</productname>のソースと一緒に配布される<firstterm>makefile</firstterm>を使って自動的に行われます。
      </para>
     </note>
    </para>

    <para>
<!--
     A detailed description of <application>bison</application> or
     the grammar rules given in <filename>gram.y</filename> would be
     beyond the scope of this paper. There are many books and
     documents dealing with <application>flex</application> and
     <application>bison</application>. You should be familiar with
     <application>bison</application> before you start to study the
     grammar given in <filename>gram.y</filename> otherwise you won't
     understand what happens there.
-->
<application>bison</application>または<filename>gram.y</filename>で定義される文法ルールの詳細は本稿では説明しきれません。
<application>flex</application>や<application>bison</application>については本や資料がたくさん出ています。
<filename>gram.y</filename>の文法の勉強を始める前に<application>bison</application>の知識が必須となります。
その知識なしではそこで何が起こっているのかを理解することは難しいでしょう。
    </para>

   </sect2>

   <sect2>
<!--
     <title>Transformation Process</title>
-->
     <title>書き換えプロセス</title>

    <para>
<!--
     The parser stage creates a parse tree using only fixed rules about
     the syntactic structure of SQL.  It does not make any lookups in the
     system catalogs, so there is no possibility to understand the detailed
     semantics of the requested operations.  After the parser completes,
     the <firstterm>transformation process</firstterm> takes the tree handed
     back by the parser as input and does the semantic interpretation needed
     to understand which tables, functions, and operators are referenced by
     the query.  The data structure that is built to represent this
     information is called the <firstterm>query tree</>.
-->
構文解析過程ではSQLの構文構造に関する固定ルールのみを使って構文解析ツリーを作成します。
システムカタログの参照を行わないので、要求されている操作の詳細な語義は理解しません。
構文解析が終わった後に入力としてパーサから戻されたツリーを<firstterm>書き換えプロセス</firstterm>が引き受け、どのテーブル、関数、そして演算子が問い合わせによって参照されているのかの判断に必要な語義翻訳を行います。
この情報を表すために作成されるデータ構造を<firstterm>問い合わせツリー</>と呼びます。
    </para>

    <para>
<!--
     The reason for separating raw parsing from semantic analysis is that
     system catalog lookups can only be done within a transaction, and we
     do not wish to start a transaction immediately upon receiving a query
     string.  The raw parsing stage is sufficient to identify the transaction
     control commands (<command>BEGIN</>, <command>ROLLBACK</>, etc), and
     these can then be correctly executed without any further analysis.
     Once we know that we are dealing with an actual query (such as
     <command>SELECT</> or <command>UPDATE</>), it is okay to
     start a transaction if we're not already in one.  Only then can the
     transformation process be invoked.
-->
語義解釈と入力の構文解釈を切り分ける理由は、システムカタログの参照はトランザクション内でのみ行うことができますが、問い合わせ文字列を受け取ってすぐにトランザクションを開始することは好ましくないと考えられるからです。
入力に対する構文解析過程ではトランザクション管理コマンド（<command>BEGIN</>、<command>ROLLBACK</>など）を特定するだけで十分であるとともに、それ以上の分析を行わなくても正しい処理が実行されます。
実際の問い合わせ（例えば<command>SELECT</>もしくは<command>UPDATE</>）に関わっていると言うことがわかっていて既にあるトランザクション内にいなければ新規トランザクションを開始することは問題ありません。これ以降に限り書き換えプロセスを起動することができます。
    </para>

    <para>
<!--
     The query tree created by the transformation process is structurally
     similar to the raw parse tree in most places, but it has many differences
     in detail.  For example, a <structname>FuncCall</> node in the
     parse tree represents something that looks syntactically like a function
     call.  This might be transformed to either a <structname>FuncExpr</>
     or <structname>Aggref</> node depending on whether the referenced
     name turns out to be an ordinary function or an aggregate function.
     Also, information about the actual data types of columns and expression
     results is added to the query tree.
-->
書き換えプロセスで作成された問い合わせツリーはほとんどの箇所で加工されていない構文解析ツリーに構造的には似ていますが、細部では数多くの相違が存在します。
例えば、構文解析ツリーの<structname>FuncCall</>ノードは構文的には関数呼び出しのように見える何かを表わしています。
これは参照された名前が通常の関数になるか集約関数となるかによって<structname>FuncExpr</>もしくは<structname>Aggref</>に書き換えられることがあります。
さらに、列の実際のデータ型と式の結果についての情報が問い合わせツリーに書き加えられます。
    </para>
   </sect2>
  </sect1>

  <sect1 id="rule-system">
<!--
   <title>The <productname>PostgreSQL</productname> Rule System</title>
-->
   <title><productname>PostgreSQL</productname>ルールシステム</title>

   <para>
<!--
    <productname>PostgreSQL</productname> supports a powerful
    <firstterm>rule system</firstterm> for the specification
    of <firstterm>views</firstterm> and ambiguous <firstterm>view updates</firstterm>.
    Originally the <productname>PostgreSQL</productname>
    rule system consisted of two implementations:
-->
<productname>PostgreSQL</productname>には、<firstterm>ビュー</firstterm>と理解の仕方でどうとも取れる<firstterm>ビューの更新</firstterm>の仕様に対応する強力な<firstterm>ルールシステム</firstterm>があります。
元々<productname>PostgreSQL</productname>のルールシステムは2つの実装で構成されていました。

    <itemizedlist>
     <listitem>
      <para>
<!--
       The first one worked using <firstterm>row level</firstterm> processing and was
       implemented deep in the <firstterm>executor</firstterm>. The rule system was
       called whenever an individual row had been accessed. This
       implementation was removed in 1995 when the last official release
       of the <productname>Berkeley Postgres</productname> project was
       transformed into <productname>Postgres95</productname>.
-->
初めの1つは<firstterm>行レベル</firstterm>の処理を使って動き、<firstterm>エクゼキュータ</firstterm>の内部に深く実装されていました。
個別の行がアクセスされる度にルールシステムが呼ばれていました。
この実装は1995年、最後の<productname>Berkeley PostgreSQL</productname>プロジェクトの公式リリースが<productname>Postgres95</productname>へ移行する時に削除されました。 
      </para>
     </listitem>

     <listitem>
      <para>
<!--
       The second implementation of the rule system is a technique
       called <firstterm>query rewriting</firstterm>.
       The <firstterm>rewrite system</firstterm> is a module
       that exists between the <firstterm>parser stage</firstterm> and the
       <firstterm>planner/optimizer</firstterm>. This technique is still implemented.
-->
ルールシステムの2つ目の実装は<firstterm>問い合わせ書き換え</firstterm>と呼ばれる手法です。
<firstterm>書き換えシステム</firstterm>は<firstterm>構文解析過程</firstterm>と<firstterm>プランナ/オプティマイザ</firstterm>の間にあるモジュールです。
この手法は現在でも実装されています。
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
<!--
    The query rewriter is discussed in some detail in
    <xref linkend="rules">, so there is no need to cover it here.
    We will only point out that both the input and the output of the
    rewriter are query trees, that is, there is no change in the
    representation or level of semantic detail in the trees.  Rewriting
    can be thought of as a form of macro expansion.
-->
問い合わせの書き換えについては<xref linkend="rules">にて詳しく論議されますので、ここでは取り扱いません。
書き換えの入出力はともに問い合わせツリーである、つまり、ツリー内の表現の仕方や語義をどの程度詳しく判断するかには変更はない、ということを指摘するのに留めます。
書き換えはマクロの拡張と捉えることもできます。
   </para>

  </sect1>

  <sect1 id="planner-optimizer">
<!--
   <title>Planner/Optimizer</title>
-->
   <title>プランナ/オプティマイザ</title>

   <para>
<!--
    The task of the <firstterm>planner/optimizer</firstterm> is to
    create an optimal execution plan. A given SQL query (and hence, a
    query tree) can be actually executed in a wide variety of
    different ways, each of which will produce the same set of
    results.  If it is computationally feasible, the query optimizer
    will examine each of these possible execution plans, ultimately
    selecting the execution plan that is expected to run the fastest.
-->
<firstterm>プランナ/オプティマイザ</firstterm>の役割は最適な実行計画を作ることです。
ある与えられたSQL問い合わせは（それがある問い合わせツリーになるのですが）、同じ結果をもたらす、多くの異なった方法で実際には実行できます。
もしもコンピュータの演算として可能であれば、問い合わせオプティマイザは可能な実行計画をすべて検証し、実行するとした場合に一番早く結果をもたらすと想定される実行計画を選択します。
   </para>

   <note>
    <para>
<!--
     In some situations, examining each possible way in which a query
     can be executed would take an excessive amount of time and memory
     space. In particular, this occurs when executing queries
     involving large numbers of join operations. In order to determine
     a reasonable (not necessarily optimal) query plan in a reasonable amount
     of time, <productname>PostgreSQL</productname> uses a <firstterm>Genetic
     Query Optimizer</firstterm> (see <xref linkend="geqo">) when the number of joins
     exceeds a threshold (see <xref linkend="guc-geqo-threshold">).
-->
場合によっては、問い合わせがどう実行されるか、可能性のある全ての手段を検証するため、膨大な時間とメモリ空間を消費する可能性があります。
特に数多くの結合操作に問い合わせが関わった時です。
相応な（必ずしも最適ではありませんが）問い合わせ計画を、相応な時間内で決定するため<productname>PostgreSQL</productname>は結合の数が閾値を越えた場合、<firstterm>遺伝的問い合わせオプティマイザ</firstterm>（<xref linkend="geqo">参照）を使用します（<xref linkend="guc-geqo-threshold">を参照ください）。
    </para>
   </note>

   <para>
<!--
    The planner's search procedure actually works with data structures
    called <firstterm>paths</>, which are simply cut-down representations of
    plans containing only as much information as the planner needs to make
    its decisions. After the cheapest path is determined, a full-fledged
    <firstterm>plan tree</> is built to pass to the executor.  This represents
    the desired execution plan in sufficient detail for the executor to run it.
    In the rest of this section we'll ignore the distinction between paths
    and plans.
-->
このプランナの検索手順は、実際には<firstterm>経路</>という名前のデータ構造を使用します。
経路とは、プランナが決定を行うために必要な情報のみに切り詰めた単なる計画の表現です。
最も安価である経路が決定された後、全てが揃った<firstterm>計画ツリー</>が作成されてエクゼキュータに渡されます。
これはつまり、要求されている実行計画はエクゼキュータがそれを実行するために十分な詳しい内容を所有していることを表しています。
本節の残りでは、経路と計画の違いについて無視します。
   </para>

   <sect2>
<!--
    <title>Generating Possible Plans</title>
-->
    <title>実行可能な計画の生成</title>

    <para>
<!--
     The planner/optimizer starts by generating plans for scanning each
     individual relation (table) used in the query.  The possible plans
     are determined by the available indexes on each relation.
     There is always the possibility of performing a
     sequential scan on a relation, so a sequential scan plan is always
     created. Assume an index is defined on a
     relation (for example a B-tree index) and a query contains the
     restriction
     <literal>relation.attribute OPR constant</literal>. If
     <literal>relation.attribute</literal> happens to match the key of the B-tree
     index and <literal>OPR</literal> is one of the operators listed in
     the index's <firstterm>operator class</>, another plan is created using
     the B-tree index to scan the relation. If there are further indexes
     present and the restrictions in the query happen to match a key of an
     index, further plans will be considered.  Index scan plans are also
     generated for indexes that have a sort ordering that can match the
     query's <literal>ORDER BY</> clause (if any), or a sort ordering that
     might be useful for merge joining (see below).
-->
プランナ/オプティマイザは、問い合わせの中で使用される個々のリレーション（テーブル）をスキャンするための計画を生成することから始めます。
各リレーション上で利用できるインデックスにより実行可能な計画が決まります。
リレーションをシーケンシャルスキャンする可能性は常にありますので、シーケンシャルスキャンを使用する計画は常に作成されます。
リレーション上にインデックス（例えばB-treeインデックス）が定義され、問い合わせには<literal>relation.attribute OPR constant</literal>という条件があるとしましょう。
もし<literal>relation.attribute</literal>がB-treeインデックスのキーと一致し、<literal>OPR</literal>がインデックスの<firstterm>演算子クラス</>に列挙されている演算子の1つであれば、リレーションをスキャンするためにB-treeインデックスを使用する別の計画が作られます。
さらに他のインデックスが存在し、問い合わせの中で条件がインデックスのキーに一致した場合、なおその上に計画が検討されます。インデックススキャン計画は、問い合わせの （もし存在すれば）<literal>ORDER BY</>句に一致するソート順、もしくはマージ結合に便利なソート順を所有するインデックスに対して生成されます（以下を参照してください）。
    </para>

    <para>
<!--
     If the query requires joining two or more relations,
     plans for joining relations are considered
     after all feasible plans have been found for scanning single relations.
     The three available join strategies are:
-->
問い合わせが２つ以上のリレーションの結合を必要とすると、リレーションを結合する計画は、単一のリレーションをスキャンするために全ての実行可能な計画が探し出された後に検討されます。３つの実行可能な結合戦略を示します。

     <itemizedlist>
      <listitem>
       <para>
<!--
        <firstterm>nested loop join</firstterm>: The right relation is scanned
        once for every row found in the left relation. This strategy
        is easy to implement but can be very time consuming.  (However,
        if the right relation can be scanned with an index scan, this can
        be a good strategy.  It is possible to use values from the current
        row of the left relation as keys for the index scan of the right.)
-->
<firstterm>入れ子ループ結合</firstterm>：
左側のリレーションの中で見つけられた行ごとに右側のリレーションが1回スキャンされます。
この戦略は実装が簡単ですが、時間がかかる場合があります
（とは言っても右側のリレーションがインデックススキャンによってスキャン可能であればよい戦略になります。
右側のインデックススキャンのキーとして左側のリレーションの現在の行の値を使用することができます。）
       </para>
      </listitem>

      <listitem>
       <para>
<!--
        <firstterm>merge join</firstterm>: Each relation is sorted on the join
        attributes before the join starts. Then the two relations are
        scanned in parallel, and matching rows are combined to form
        join rows. This kind of join is more
        attractive because each relation has to be scanned only once.
        The required sorting might be achieved either by an explicit sort
        step, or by scanning the relation in the proper order using an
        index on the join key.
-->
<firstterm>マージ結合</firstterm>：
結合を開始する前に、それぞれのリレーションを結合属性でソートします。
そして、2つのリレーションを並行してスキャンし、一致する行を結合行の形にまとめます。
それぞれのリレーションがたった1回しかスキャンされなくて済むのでこの結合は魅力的です。
要求されるソートは、明示的なソート段階、または、結合キー上のインデックスを使用して適切な順序でリレーションをスキャンすることにより行われます。
       </para>
      </listitem>

      <listitem>
       <para>
<!--
        <firstterm>hash join</firstterm>: the right relation is first scanned
        and loaded into a hash table, using its join attributes as hash keys.
        Next the left relation is scanned and the
        appropriate values of every row found are used as hash keys to
        locate the matching rows in the table.
-->
<firstterm>ハッシュ結合</firstterm>：
右側のリレーションがハッシュキーとして結合属性を用いて初めにスキャンされ、ハッシュテーブルに読み込まれます。
次に左側のリレーションがスキャンされ、見つかったそれぞれの行に相応しい値が、右側のリレーションの行を探し出すためのハッシュキーとして使われます。
       </para>
      </listitem>
     </itemizedlist>
    </para>

    <para>
<!--
     When the query involves more than two relations, the final result
     must be built up by a tree of join steps, each with two inputs.
     The planner examines different possible join sequences to find the
     cheapest one.
-->
問い合わせが3つ以上のリレーションを含む場合、それぞれ2つの入力を持つ結合段階のツリーによって最終結果を構築しなければなりません。
プランナは最も低コストな計画を見つけ出すために、あり得る異なった結合順序を検証します。
    </para>

    <para>
<!--
     If the query uses fewer than <xref linkend="guc-geqo-threshold">
     relations, a near-exhaustive search is conducted to find the best
     join sequence.  The planner preferentially considers joins between any
     two relations for which there exist a corresponding join clause in the
     <literal>WHERE</literal> qualification (i.e., for
     which a restriction like <literal>where rel1.attr1=rel2.attr2</literal>
     exists). Join pairs with no join clause are considered only when there
     is no other choice, that is, a particular relation has no available
     join clauses to any other relation. All possible plans are generated for
     every join pair considered by the planner, and the one that is
     (estimated to be) the cheapest is chosen.
-->
問い合わせが<xref linkend="guc-geqo-threshold">より少ないリレーションを使用する場合、最適な結合シーケンスを見つけ出すため、完璧に近い検索が行われます。
プランナは<literal>WHERE</literal>条件での対応する結合句が存在する（すなわち、<literal>where rel1.attr1=rel2.attr2</literal>のような制約に対して）、あらゆる２つのリレーション間の結合を優先的に考慮します。
結合句のない結合ペアは他に選択のない場合に考慮されます。つまり、ある特定のリレーションが他のどんなリレーションに対しても有効な結合句を持たない場合です。
すべての有効な計画はプランナが考慮したすべての結合ペアに対し生成され、最も安価な（と評価された）ものが選択されます。
    </para>

    <para>
<!--
     When <varname>geqo_threshold</varname> is exceeded, the join
     sequences considered are determined by heuristics, as described
     in <xref linkend="geqo">.  Otherwise the process is the same.
-->
<varname>geqo_threshold</varname>を上回ると、考慮された結合シーケンスは<xref linkend="geqo">に記載されているように経験則で決定されます。
そうでない時、処理は変わりません。
    </para>

    <para>
<!--
     The finished plan tree consists of sequential or index scans of
     the base relations, plus nested-loop, merge, or hash join nodes as
     needed, plus any auxiliary steps needed, such as sort nodes or
     aggregate-function calculation nodes.  Most of these plan node
     types have the additional ability to do <firstterm>selection</>
     (discarding rows that do not meet a specified Boolean condition)
     and <firstterm>projection</> (computation of a derived column set
     based on given column values, that is, evaluation of scalar
     expressions where needed).  One of the responsibilities of the
     planner is to attach selection conditions from the
     <literal>WHERE</literal> clause and computation of required
     output expressions to the most appropriate nodes of the plan
     tree.
-->
最終的な計画ツリーは基になっているリレーションのシーケンシャルもしくはインデックススキャン、そして必要に応じて入れ子ループ、マージ、またはハッシュ結合のノード、さらにはソートまたは集約関数計算ノードのような必要とされる補助の手順から構成されます。
これらほとんどの計画ノード型は<firstterm>選択</>（特定の論理演算条件に合致しない行を破棄すること）および<firstterm>射影</>（与えられた列の値に基づき派生した列の集合を計算すること、つまり必要なところでスカラ式の評価をすること）を行う追加的能力を持っています。
プランナの1つの責任は、<literal>WHERE</literal>句から選択条件を付加して計画ツリーの最も適切なノードに対し必要とされる出力式を計算することです。
    </para>
   </sect2>
  </sect1>

  <sect1 id="executor">
<!--
   <title>Executor</title>
-->
   <title>エクゼキュータ</title>

   <para>
<!--
    The <firstterm>executor</firstterm> takes the plan created by the
    planner/optimizer and recursively processes it to extract the required set
    of rows.  This is essentially a demand-pull pipeline mechanism.
    Each time a plan node is called, it must deliver one more row, or
    report that it is done delivering rows.
-->
<firstterm>エクゼキュータ</firstterm>は、プランナ/オプティマイザで作成された計画を受け取り、必要な行の集合を抽出するために再帰的に処理します。
これは本質的に要求引き寄せ型（demand-pull）パイプライン機能です。
計画ノードが呼ばれる度にもう1つの行を引き渡すか、行を引き渡したことの報告を行わなければなりません。
   </para>

   <para>
<!--
    To provide a concrete example, assume that the top
    node is a <literal>MergeJoin</literal> node.
    Before any merge can be done two rows have to be fetched (one from
    each subplan). So the executor recursively calls itself to
    process the subplans (it starts with the subplan attached to
    <literal>lefttree</literal>). The new top node (the top node of the left
    subplan) is, let's say, a
    <literal>Sort</literal> node and again recursion is needed to obtain
    an input row.  The child node of the <literal>Sort</literal> might
    be a <literal>SeqScan</> node, representing actual reading of a table.
    Execution of this node causes the executor to fetch a row from the
    table and return it up to the calling node.  The <literal>Sort</literal>
    node will repeatedly call its child to obtain all the rows to be sorted.
    When the input is exhausted (as indicated by the child node returning
    a NULL instead of a row), the <literal>Sort</literal> code performs
    the sort, and finally is able to return its first output row, namely
    the first one in sorted order.  It keeps the remaining rows stored so
    that it can deliver them in sorted order in response to later demands.
-->
具体的な例を提供する目的で頂点のノードが<literal>MergeJoin</literal>ノードである場合を想定しましょう。
いかなるマージも実行される前に（それぞれの副計画から1つずつ）2つの行を取ってこなくてはいけません。
ですからエクゼキュータは副計画を処理するために自分自身を再帰的に呼び出します（<literal>lefttree</literal>に付随する副計画から開始します）。
新しい頂点のノード（左の副計画の頂点のノード）は<literal>Sort</literal>ノードであるとしましょう。ここでもノード自体が処理される前に入力行を取ってこなくてはいけません。
<literal>Sort</literal>の子ノードは実際のテーブルの読み取りを表現している<literal>SeqScan</>ノードのこともあり得ます。
このノードの処理はエクゼキュータにテーブルから行を抽出させ、呼び出しているノードに渡し戻させます。
<literal>Sort</literal>ノードはソート対象の全てのノードを取得するために子ノードを繰り返し呼び出します。
入力がなくなった時（子ノードが行ではなくNULLを返してきた時）<literal>Sort</literal>コードがソートを実行して最終的に最初の出力行を返すことができるようになります。
つまりソート順における最初の結果です。
後での要求に答えるためソート順に引き渡すことができるように残っている行は保存されます。
   </para>

   <para>
<!--
    The <literal>MergeJoin</literal> node similarly demands the first row
    from its right subplan.  Then it compares the two rows to see if they
    can be joined; if so, it returns a join row to its caller.  On the next
    call, or immediately if it cannot join the current pair of inputs,
    it advances to the next row of one table
    or the other (depending on how the comparison came out), and again
    checks for a match.  Eventually, one subplan or the other is exhausted,
    and the <literal>MergeJoin</literal> node returns NULL to indicate that
    no more join rows can be formed.
-->
<literal>MergeJoin</literal>ノードは同じようにしてその右副計画から最初の行を要求します。
そこで2つの行が結合できるかどうか比較されます。もし結合できる場合には呼び出し側に結合された行が返されます。
次の呼び出しの時に、もしくは入力された現在の組み合わせが結合できない場合はすぐに、あるテーブルあるいはそれ以外のテーブル（比較の結果に依存して）の次の行に進んで、さらに一致があるかどうか検証されます。
最終的にはある副計画もしくは他の計画が使いきられ、<literal>MergeJoin</literal>ノードがこれ以上の結合行を生成できないという意味のNULLを返すことになります。
   </para>

   <para>
<!--
    Complex queries can involve many levels of plan nodes, but the general
    approach is the same: each node computes and returns its next output
    row each time it is called.  Each node is also responsible for applying
    any selection or projection expressions that were assigned to it by
    the planner.
-->
複雑な問い合わせは多くの階層となった計画ノードに関わるかもしれませんが、概略的な取り扱い方は同じです。
それぞれのノードは呼び出される度に次の出力行を計算して返します。
それぞれのノードは同時にプランナによって割り当てられたいかなる選択式や射影式でも適用する責任があります。
   </para>

   <para>
<!--
    The executor mechanism is used to evaluate all four basic SQL query types:
    <command>SELECT</>, <command>INSERT</>, <command>UPDATE</>, and
    <command>DELETE</>.  For <command>SELECT</>, the top-level executor
    code only needs to send each row returned by the query plan tree off
    to the client.  For <command>INSERT</>, each returned row is inserted
    into the target table specified for the <command>INSERT</>.  This is
    done in a special top-level plan node called <literal>ModifyTable</>.
    (A simple
    <command>INSERT ... VALUES</> command creates a trivial plan tree
    consisting of a single <literal>Result</> node, which computes just one
    result row, and <literal>ModifyTable</> above it to perform the insertion.
    But <command>INSERT ... SELECT</> can demand the full power
    of the executor mechanism.)  For <command>UPDATE</>, the planner arranges
    that each computed row includes all the updated column values, plus
    the <firstterm>TID</> (tuple ID, or row ID) of the original target row;
    this data is fed into a <literal>ModifyTable</> node, which uses the
    information to create a new updated row and mark the old row deleted.
    For <command>DELETE</>, the only column that is actually returned by the
    plan is the TID, and the <literal>ModifyTable</> node simply uses the TID
    to visit each target row and mark it deleted.
-->
エクゼキュータ機構は全ての4つの基本的なSQL型を検証するために用いられます。
4つのSQL型とは<command>SELECT</>、<command>INSERT</>、<command>UPDATE</>、そして<command>DELETE</>です。
<command>SELECT</>では、最上位階層のエクゼキュータコードは問い合わせ計画によって返されるそれぞれの行をクライアントへ送り返すだけでよいことになっています。
<command>INSERT</>では、<command>INSERT</>で指定された対象となるテーブルに返された行が挿入されます。
これは<literal>ModifyTable</>と呼ばれる特別な最上位階層の計画ノードの中で行われます。
（ある単純な<command>INSERT ... VALUES</>コマンドは1つの<literal>Result</>ノード（これは、結果としての行を1つだけ計算するに留まります）とその上の挿入を実行するための<literal>ModifyTable</>からなる単純な計画ツリーを生成します。
しかし、<command>INSERT ... SELECT</>はエクゼキュータ機構ができ得る限りの能力を発揮することを要求する場合があります）。
<command>UPDATE</>ではプランナはすべての更新された列の値を含んだ行の演算結果と<firstterm>TID</>（タプルID、または行ID）を準備します。
このデータは<literal>ModifyTable</>ノードに入力され、ノードでは新しく更新された行の作成と削除された古い行に印を付けるためこの情報を利用します。
<command>DELETE</>では計画から実際に返されるただ1つの列はTIDで、<literal>ModifyTable</>ノードは単に各対象行を尋ね当てて削除の印を付けるためにこのTIDを使用します。
   </para>

  </sect1>

 </chapter>
