<!-- doc/src/sgml/high-availability.sgml -->

<chapter id="high-availability">
<!-- Changed-v1.29
 <title>High Availability, Load Balancing, and Replication</title>
-->
 <title>高可用性、負荷分散およびレプリケーション</title>

 <indexterm><primary>high availability</></>
 <indexterm><primary>failover</></>
 <indexterm><primary>replication</></>
 <indexterm><primary>load balancing</></>
 <indexterm><primary>clustering</></>
 <indexterm><primary>data partitioning</></>

 <para>
<!--
  Database servers can work together to allow a second server to
  take over quickly if the primary server fails (high
  availability), or to allow several computers to serve the same
  data (load balancing).  Ideally, database servers could work
  together seamlessly.  Web servers serving static web pages can
  be combined quite easily by merely load-balancing web requests
  to multiple machines.  In fact, read-only database servers can
  be combined relatively easily too.  Unfortunately, most database
  servers have a read/write mix of requests, and read/write servers
  are much harder to combine.  This is because though read-only
  data needs to be placed on each server only once, a write to any
  server has to be propagated to all servers so that future read
  requests to those servers return consistent results.
-->
データベースサーバは共同して稼動できます。
その目的は、最初のサーバが故障したとき次のサーバへ速やかに引き継ぎができること（高可用性）および複数のコンピュータが同一のデータを処理できること（負荷分散）です。
データベースサーバがシームレスに共同稼動できれば理想的です。
静的なウェブページを提供するウェブサーバは、ウェブからの要求で生ずる負荷を複数のマシンに分散するだけで、簡単に結合できます。
実際、読み取り専用のデータベースサーバの結合は、同じようにかなり容易です。
しかし、大部分のデータベースサーバは、読み書きの混在した要求を受け取り、読み書き両用のサーバの結合はとても困難です。
なぜなら、読み取り要求だけの場合、全サーバへのデータの配布は1回で終わります。
しかし、書き込み後の読み取り要求に対して一貫性のある結果を返すためには、書き込み要求を受けたサーバだけでなく、他の全サーバにおいてもデータに書き込まなければなりません。
 </para>

 <para>
<!--
  This synchronization problem is the fundamental difficulty for
  servers working together.  Because there is no single solution
  that eliminates the impact of the sync problem for all use cases,
  there are multiple solutions.  Each solution addresses this
  problem in a different way, and minimizes its impact for a specific
  workload.
-->
この同時性を持たせるという問題は、共同して稼動するサーバにおいて根本的に困難なものです。
すべての使用状況において、単一の解法を用いて同時性の問題の影響を軽減できないため、複数の解法が存在します。
各々の解法はこの問題に異なったやり方を適用し、固有の作業負荷に対する影響を最小化します。
 </para>

 <para>
<!--
  Some solutions deal with synchronization by allowing only one
  server to modify the data.  Servers that can modify data are
  called read/write, <firstterm>master</> or <firstterm>primary</> servers.
  Servers that track changes in the master are called <firstterm>standby</>
  or <firstterm>slave</> servers. A standby server that cannot be connected
  to until it is promoted to a master server is called a <firstterm>warm
  standby</> server, and one that can accept connections and serves read-only
  queries is called a <firstterm>hot standby</> server.
-->
幾つかの解法では、1つのサーバだけにデータの更新を許可することにより、同時性を持たせています。
データの更新ができるサーバを、読み書きサーバ、<firstterm>マスタ</>サーバまたは<firstterm>プライマリ</>サーバといいます。
マスタの変更を追跡するサーバを、<firstterm>スタンバイ</>サーバまたは<firstterm>スレーブ</>サーバといいます。
マスタサーバに昇格するまで接続できないスタンバイサーバを<firstterm>ウォームスタンバイ</>サーバといいます。
接続を受理できて読み取り専用の問い合わせを処理できるスタンバイサーバを<firstterm>ホットスタンバイ</>サーバといいます。
 </para>

 <para>
<!-- Changed-v1.29
  Some solutions are synchronous,
  meaning that a data-modifying transaction is not considered
  committed until all servers have committed the transaction.  This
  guarantees that a failover will not lose any data and that all
  load-balanced servers will return consistent results no matter
  which server is queried. In contrast, asynchronous solutions allow some
  delay between the time of a commit and its propagation to the other servers,
  opening the possibility that some transactions might be lost in
  the switch to a backup server, and that load balanced servers
  might return slightly stale results.  Asynchronous communication
  is used when synchronous would be too slow.
-->
いくつかの同期の解法が提供されています。
すなわち、データに書き込むトランザクションでは、全サーバがコミットするまでトランザクションはコミットされません。
これによって、フェールオーバにおいてデータの消失がないことが保証されます。
また、どのサーバが問い合わせを受理したかに関係なく、全ての負荷分散サーバが一貫した結果を返すことが保証されます。
それに対して非同期の解法では、コミット時刻と他サーバへの伝達時刻に時間差がありうるため、バックアップサーバへ交代する時にトランザクションが消失する可能性があります。
また、負荷分散サーバにおいては、最新でない結果を応答する可能性があります。
サーバ間の非同期の通信は、同期が非常に低速な場合に使用されます。
 </para>

 <para>
<!--
  Solutions can also be categorized by their granularity.  Some solutions
  can deal only with an entire database server, while others allow control
  at the per-table or per-database level.
-->
解法は粒度によって分類することもできます。
ある解法ではデータベースサーバ全体だけを範囲として処理しますが、他の解法では各テーブルまたは各データベースを範囲として管理できます。
 </para>

 <para>
<!--
  Performance must be considered in any choice.  There is usually a
  trade-off between functionality and
  performance.  For example, a fully synchronous solution over a slow
  network might cut performance by more than half, while an asynchronous
  one might have a minimal performance impact.
-->
すべての選択において、作業効率を考えなければなりません。
通常、作業効率と機能性は相反する関係にあります。
例えば、遅いネットワークの場合、完全同期の解法を使えば作業効率は半分以下となりますが、非同期の解法を使えば作業効率への影響が最小となります。
 </para>

 <para>
<!--
  The remainder of this section outlines various failover, replication,
  and load balancing solutions.  A <ulink
  url="http://www.postgres-r.org/documentation/terms">glossary</ulink> is
  also available.
-->
本節では、フェールオーバとレプリケーションと負荷分散における種々の解法を説明します。
<ulink url="http://www.postgres-r.org/documentation/terms">glossary</ulink>も利用できます。
 </para>

 <sect1 id="different-replication-solutions">
<!--
 <title>Comparison of Different Solutions</title>
-->
 <title>様々な解法の比較</title>

 <variablelist>

  <varlistentry>
<!--
   <term>Shared Disk Failover</term>
-->
   <term>共有ディスクを用いたフェールオーバ</term>
   <listitem>

    <para>
<!--
     Shared disk failover avoids synchronization overhead by having only one
     copy of the database.  It uses a single disk array that is shared by
     multiple servers.  If the main database server fails, the standby server
     is able to mount and start the database as though it were recovering from
     a database crash.  This allows rapid failover with no data loss.
-->
データベースのコピーを 1つだけ保有すればよいため、共有ディスクを用いたフェールオーバは同期によるオーバーヘッドを回避できます。
本解法では、複数のサーバが単一のディスクアレイを共有します。
主データベースサーバが故障したとき、まるでデータベースの破損から復旧したように、スタンバイサーバが元のデータベースを実装して稼動できます。
これはデータの消失がない高速なフェールオーバを行うことができます。
    </para>

    <para>
<!-- Changed-v1.29
     Shared hardware functionality is common in network storage devices.
     Using a network file system is also possible, though care must be
     taken that the file system has full <acronym>POSIX</> behavior (see <xref
     linkend="creating-cluster-nfs">).  One significant limitation of this
     method is that if the shared disk array fails or becomes corrupt, the
     primary and standby servers are both nonfunctional.  Another issue is
     that the standby server should never access the shared storage while
     the primary server is running.
-->
ハードウェアを共有するという機能は、ネットワーク上の記憶装置では一般的です。
ネットワークファイルシステムの利用も可能ですが、そのファイルシステムがPOSIX仕様を満たしているか注意してください。
（ <xref linkend="creating-cluster-nfs">を見てください）。
本解法には重大な制約があり、共有ディスクアレイが故障または破損したとき、プライマリサーバもスタンバイサーバも機能しなくなります。
また、プライマリサーバが稼動している間は、スタンバイサーバが共有記憶装置にアクセスしてはなりません。
    </para>

   </listitem>
  </varlistentry>

  <varlistentry>
<!-- Added-v1.29
   <term>File System (Block-Device) Replication</term>
-->
   <term>ファイルシステム（ブロックデバイス）レプリケーション</term>
   <listitem>

    <para>
<!--
     A modified version of shared hardware functionality is file system
     replication, where all changes to a file system are mirrored to a file
     system residing on another computer.  The only restriction is that
     the mirroring must be done in a way that ensures the standby server
     has a consistent copy of the file system &mdash; specifically, writes
     to the standby must be done in the same order as those on the master.
     <productname>DRBD</> is a popular file system replication solution
     for Linux.
-->
ハードウェア共有機能の改善の一つとしてファイルシステムのレプリケーションをあげることができます。
それは、あるファイルシステムに対して行われたすべての変更を他のコンピュータに存在するファイルシステムにミラーリングします。
制約はただ一つであり、スタンバイサーバがファイルシステムの一貫したコピーを自身の領域に持つようにミラーリングしなければなりません。具体的には、スタンバイサーバへの書き込みがマスタサーバへの書き込みと同じ順序でおこなわれなければなりません。
Linuxにおける<productname>DRBD</>は、ファイルシステムレプリケーションで広く受けいれられている手法です。
    </para>

<!--
原文におけるコメントアウト
https://forge.continuent.org/pipermail/sequoia/2006-November/004070.html

Oracle RAC is a shared disk approach and just send cache invalidations
to other nodes but not actual data. As the disk is shared, data is
only committed once to disk and there is a distributed locking
protocol to make nodes agree on a serializable transactional order.
コメントアウト終了
-->

   </listitem>
  </varlistentry>

  <varlistentry>
<!--
    <term>Transaction Log Shipping</term>
-->
   <term>トランザクションログシッピング</term>
   <listitem>

    <para>
<!--
     Warm and hot standby servers can be kept current by reading a
     stream of write-ahead log (<acronym>WAL</>)
     records.  If the main server fails, the standby contains
     almost all of the data of the main server, and can be quickly
     made the new master database server.  This can be synchronous or
     asynchronous and can only be done for the entire database server.
-->
ウォームスタンバイおよびホットスタンバイサーバは、ログ先行書き込み（<acronym>WAL</>）のレコードを解読して最新の状態を保持できます。
プライマリサーバが故障したとき、スタンバイサーバがプライマリサーバのほぼすべてのデータを保存して、速やかに新しい主データベースを稼動できます。
本解法は同期、非同期で行うことができ、データベース全体だけを範囲として処理できます。
    </para>
    <para>
<!--
     A standby server can be implemented using file-based log shipping
     (<xref linkend="warm-standby">) or streaming replication (see
     <xref linkend="streaming-replication">), or a combination of both. For
     information on hot standby, see <xref linkend="hot-standby">.
-->
スタンバイサーバは、ファイル単位のログシッピング（<xref linkend="warm-standby">参照）またはストリーミングレプリケーション（<xref linkend="streaming-replication">参照）または両者の併用を使用して実装できます。
ホットスタンバイの情報は <xref linkend="hot-standby"> を参照してください。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>Trigger-Based Master-Standby Replication</term>
-->
   <term>トリガベースのマスタ・スタンバイレプリケーション</term>
   <listitem>

    <para>
<!--
     A master-standby replication setup sends all data modification
     queries to the master server.  The master server asynchronously
     sends data changes to the standby server.  The standby can answer
     read-only queries while the master server is running.  The
     standby server is ideal for data warehouse queries.
-->
マスタとスタンバイによるレプリケーションでは、データ更新のすべての問い合わせをマスタサーバに送付します。
マスタサーバは更新したデータを非同期でスタンバイサーバに送付します。
マスタサーバが稼動している間、スタンバイサーバは読み取り問い合わせだけに応答します。
スタンバイサーバはデータウェアハウスへの問い合わせに理想的です。
    </para>

    <para>
<!--
     <productname>Slony-I</> is an example of this type of replication, with per-table
     granularity, and support for multiple standby servers.  Because it
     updates the standby server asynchronously (in batches), there is
     possible data loss during fail over.
-->
この種類のレプリケーションの一例は<productname>Slony-I</>であり、テーブル単位の粒度を持ち、複数のスタンバイサーバが稼動できます。
（バッチ処理によって）スタンバイサーバのデータを非同期で更新するため、フェールオーバにおけるデータ消失の可能性があります。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>Statement-Based Replication Middleware</term>
-->
   <term>文に基づいたレプリケーションのミドルウェア</term>
   <listitem>

    <para>
<!--
     With statement-based replication middleware, a program intercepts
     every SQL query and sends it to one or all servers.  Each server
     operates independently.  Read-write queries must be sent to all servers,
     so that every server receives any changes.  But read-only queries can be
     sent to just one server, allowing the read workload to be distributed
     among them.
-->
文に基づいたレプリケーションのミドルウェアでは、プログラムがすべてのSQL問い合わせを採取して、1つまたはすべてのサーバに送付します。
なお、各々のサーバは独立して稼動します。
読み書き問い合わせは、すべてのサーバがすべての変更を受け取るように全サーバに送付されなければなりません。
しかし、読み取り専用の問い合わせはサーバ全体の読み取り負荷を分散させるために、1つのサーバだけに送付することができます。
    </para>

    <para>
<!--
     If queries are simply broadcast unmodified, functions like
     <function>random()</>, <function>CURRENT_TIMESTAMP</>, and
     sequences can have different values on different servers.
     This is because each server operates independently, and because
     SQL queries are broadcast (and not actual modified rows).  If
     this is unacceptable, either the middleware or the application
     must query such values from a single server and then use those
     values in write queries.  Another option is to use this replication
     option with a traditional master-standby setup, i.e. data modification
     queries are sent only to the master and are propagated to the
     standby servers via master-standby replication, not by the replication
     middleware.  Care must also be taken that all
     transactions either commit or abort on all servers, perhaps
     using two-phase commit (<xref linkend="sql-prepare-transaction">
     and <xref linkend="sql-commit-prepared">.
     <productname>Pgpool-II</> and <productname>Continuent Tungsten</>
     are examples of this type of replication.
-->
問い合わせを修正しないで送付した場合、<function>random()</>関数による乱数値と<function>CURRENT_TIMESTAMP</>関数による現在時刻およびシーケンス値が、サーバごとに異なることがあります。
その理由は、各サーバが独立して稼動しているため、および、SQL問い合わせの送付では実際に更新した行の識別値を取得できないためです。
これが許容できない場合は、ミドルウェアかアプリケーションにおいて1つのサーバにこのような問い合わせを送付し、その結果を書き込み問い合わせで使用しなければなりません。
その他の選択肢は従来のマスタとスタンバイによるレプリケーションのオプションを使用するものです。
すなわち、データ更新の問い合わせをマスタサーバだけに送付し、ミドルウェアによるレプリケーションを使わずにマスタとスタンバイによるレプリケーションを介してスタンバイサーバに伝達します。
トランザクションをコミットするか中断するかについても、全サーバが同一となるよう注意しなければなりません。
これには2相コミット（<xref linkend="sql-prepare-transaction"> および <xref linkend="sql-commit-prepared">）を使用することになるでしょう。
<productname>Pgpool-II</>と<productname>Continuent Tungsten</>がこのレプリケーションの一例です。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!-- Moved-v1.29
   <term>Asynchronous Multimaster Replication</term>
-->
   <term>非同期マルチマスタレプリケーション</term>
   <listitem>

    <para>
<!--
     For servers that are not regularly connected, like laptops or
     remote servers, keeping data consistent among servers is a
     challenge.  Using asynchronous multimaster replication, each
     server works independently, and periodically communicates with
     the other servers to identify conflicting transactions.  The
     conflicts can be resolved by users or conflict resolution rules.
     Bucardo is an example of this type of replication.
-->
ラップトップやリモートマシンのように、通常は接続されていないサーバ間において、データの一貫性を保持することは挑戦的な課題です。
非同期マルチマスタレプリケーションの使用により、全サーバの独立した稼動、およびトランザクションの衝突を識別するための定期的な通信を実現します。
トランザクションの衝突は、利用者および衝突回避法によって解決できるでしょう。
Bucardoはこの種のレプリケーションの一例です。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>Synchronous Multimaster Replication</term>
-->
   <term>同期マルチマスタレプリケーション</term>
   <listitem>

    <para>
<!--
     In synchronous multimaster replication, each server can accept
     write requests, and modified data is transmitted from the
     original server to every other server before each transaction
     commits.  Heavy write activity can cause excessive locking,
     leading to poor performance.  In fact, write performance is
     often worse than that of a single server.  Read requests can
     be sent to any server.  Some implementations use shared disk
     to reduce the communication overhead.  Synchronous multimaster
     replication is best for mostly read workloads, though its big
     advantage is that any server can accept write requests &mdash;
     there is no need to partition workloads between master and
     standby servers, and because the data changes are sent from one
     server to another, there is no problem with non-deterministic
     functions like <function>random()</>.
-->
同期マルチマスタレプリケーションでは全てのサーバが書き込み要求を受理できます。
受理したサーバは更新したデータを、トランザクションをコミットする前に、他の全サーバへ配布します。
書き込み負荷が重いとき、ロックの掛かり過ぎによる作業効率の低下の原因となりえます。
実際、書き込み効率は単一サーバより悪いことが大半です。
読み取り要求はどのサーバにも送付できます。
通信による負荷を減らすには、共有ディスクが実装されます。
同期マルチマスタレプリケーションは、主に読み取り作業負荷の低減に最適ですが、全てのサーバが書き込み要求を受理できることも大きな利点です。
その利点とは、マスタとスタンバイ間で作業負荷を分けなくてよいこと、および更新データが1つのサーバから他のサーバに送付されるため、出力が確定しない<function>random()</>関数などによる問題が起こらないことです。
    </para>

    <para>
<!--
     <productname>PostgreSQL</> does not offer this type of replication,
     though <productname>PostgreSQL</> two-phase commit (<xref
     linkend="sql-prepare-transaction"> and <xref
     linkend="sql-commit-prepared">)
     can be used to implement this in application code or middleware.
-->
<productname>PostgreSQL</> では、この種類のレプリケーションを提供しません。
しかし、<productname>PostgreSQL</> の 2相コミット（<xref linkend="sql-prepare-transaction">および<xref linkend="sql-commit-prepared">）を使用すれば、アプリケーションのコードまたはミドルウェアにおいて本解法を実装できます。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!-- Moved-v1.29
   <term>Commercial Solutions</term>
-->
   <term>商業的な解法</term>
   <listitem>

    <para>
<!--
     Because <productname>PostgreSQL</> is open source and easily
     extended, a number of companies have taken <productname>PostgreSQL</>
     and created commercial closed-source solutions with unique
     failover, replication, and load balancing capabilities.
-->
<productname>PostgreSQL</> はオープンソースであり、容易に拡張できます。
そのため多数の企業が、<productname>PostgreSQL</>を取り入れて商業的な解法を作成し、フェールオーバとレプリケーションと負荷分散の機能を独自に実現していますが、ソースコードは非公開です。
    </para>
   </listitem>
  </varlistentry>

 </variablelist>

 <para>
<!-- Changed-v1.32
  <xref linkend="high-availability-matrix"> summarizes
  the capabilities of the various solutions listed above.
-->
<xref linkend="high-availability-matrix">は上述した種々の解法の機能を要約したものです。
 </para>

 <table id="high-availability-matrix">
<!-- Added-v1.29
  <title>High Availability, Load Balancing, and Replication Feature Matrix</title>
-->
  <title>高可用性、負荷分散およびレプリケーションの特徴</title>
  <tgroup cols="8">
   <thead>
    <row>
<!--
     <entry>Feature</entry>
     <entry>Shared Disk Failover</entry>
     <entry>File System Replication</entry>
     <entry>Transaction Log Shipping</entry>
     <entry>Trigger-Based Master-Standby Replication</entry>
     <entry>Statement-Based Replication Middleware</entry>
     <entry>Asynchronous Multimaster Replication</entry>
     <entry>Synchronous Multimaster Replication</entry>
-->
     <entry>特徴</entry>
     <entry>共有ディスクを用いたフェールオーバ</entry>
     <entry>ファイルシステムのレプリケーション</entry>
     <entry>トランザクションログシッピング</entry>
     <entry>マスタとスタンバイによるトリガに基づいたレプリケーション</entry>
     <entry>文に基づいたレプリケーションのミドルウェア</entry>
     <entry>非同期マルチマスタレプリケーション</entry>
     <entry>同期マルチマスタレプリケーション</entry>
    </row>
   </thead>

   <tbody>

    <row>
<!-- Added-v1.34
     <entry>Most Common Implementation</entry>
     <entry align="center">NAS</entry>
     <entry align="center">DRBD</entry>
     <entry align="center">Streaming Repl.</entry>
     <entry align="center">Slony</entry>
     <entry align="center">pgpool-II</entry>
     <entry align="center">Bucardo</entry>
     <entry align="center"></entry>
-->
     <entry>最も一般的な実装</entry>
     <entry align="center">NAS</entry>
     <entry align="center">DRBD</entry>
     <entry align="center">ストリーミングレプリケーション</entry>
     <entry align="center">Slony</entry>
     <entry align="center">pgpool-II</entry>
     <entry align="center">Bucardo</entry>
     <entry align="center"></entry>
    </row>

    <row>
<!-- Added-v1.31
     <entry>Communication Method</entry>
     <entry align="center">shared disk</entry>
     <entry align="center">disk blocks</entry>
     <entry align="center">WAL</entry>
     <entry align="center">table rows</entry>
     <entry align="center">SQL</entry>
     <entry align="center">table rows</entry>
     <entry align="center">table rows and row locks</entry>
-->
     <entry>通信方法</entry>
     <entry align="center">共有ディスク</entry>
     <entry align="center">ディスクブロック</entry>
     <entry align="center">WAL</entry>
     <entry align="center">テーブル行</entry>
     <entry align="center">SQL</entry>
     <entry align="center">テーブル行</entry>
     <entry align="center">テーブル行および行ロック</entry>
    </row>

    <row>
<!--
     <entry>No special hardware required</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
-->
     <entry>特別なハードウェアが不要</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
    </row>

    <row>
<!--
     <entry>Allows multiple master servers</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
-->
     <entry>複数のマスタサーバが可能</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
    </row>

    <row>
<!--
     <entry>No master server overhead</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
-->
     <entry>マスタサーバにオーバヘッドがない</entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
    </row>

    <row>
<!--
     <entry>No waiting for multiple servers</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">with sync off</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
-->
     <entry>複数のスレーブサーバを待たない</entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">同期が無効の場合</entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
    </row>

    <row>
<!--
     <entry>Master failure will never lose data</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">with sync on</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
-->
     <entry>マスタの故障によるデータ損失がない</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">同期が有効の場合</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
    </row>

    <row>
<!--
     <entry>Standby accept read-only queries</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">with hot</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
-->
     <entry>スタンバイは読み取り問い合わせだけを受理</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">ホットスタンバイ使用時</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
    </row>

    <row>
<!--
     <entry>Per-table granularity</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
-->
     <entry>テーブルごとの粒度となる</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
    </row>

    <row>
<!--
     <entry>No conflict resolution necessary</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
-->
     <entry>コンフリクトの回避が不要</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
    </row>

   </tbody>
  </tgroup>
 </table>

 <para>
<!-- Added-v1.29
  There are a few solutions that do not fit into the above categories:
-->
上の分類に該当しない解法もあります。
 </para>

 <variablelist>

  <varlistentry>
<!--
   <term>Data Partitioning</term>
-->
   <term>データの分割</term>
   <listitem>

    <para>
<!--
     Data partitioning splits tables into data sets.  Each set can
     be modified by only one server.  For example, data can be
     partitioned by offices, e.g., London and Paris, with a server
     in each office.  If queries combining London and Paris data
     are necessary, an application can query both servers, or
     master/standby replication can be used to keep a read-only copy
     of the other office's data on each server.
-->
データの分割とは、同じテーブルのデータを複数部分に分けることです。
各部分に書き込むことができるのは、1つのサーバだけです。
例えば、データをロンドンとパリの営業所用に分割でき、サーバをロンドンとパリのどちらにも設置できた状態を考えます。
問い合わせにロンドンとパリのデータが混在した場合、アプリケーションは両方のサーバに問い合わせることができます。
または、マスタスタンバイレプリケーションを使用して、他の営業所のデータを読み取り専用コピーとして保持できます。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>Multiple-Server Parallel Query Execution</term>
-->
   <term>複数サーバによる問い合わせの並列実行</term>
   <listitem>

    <para>
<!--
     Many of the above solutions allow multiple servers to handle multiple
     queries, but none allow a single query to use multiple servers to
     complete faster.  This solution allows multiple servers to work
     concurrently on a single query.  It is usually accomplished by
     splitting the data among servers and having each server execute its
     part of the query and return results to a central server where they
     are combined and returned to the user.  <productname>Pgpool-II</>
     has this capability.  Also, this can be implemented using the
     <productname>PL/Proxy</> tool set.
-->
上述した多くの解法は、複数のサーバが複数の問い合わせを処理するものです。
処理速度の向上のために、単一の問い合わせに複数のサーバを使用するものはありません。
本解法は複数のサーバが単一の問い合わせを共同して実行するものです。
その方法は、データをサーバ間で分割し、各サーバが部分的に問い合わせを実行し、各々の結果をプライマリサーバに送付し、プライマリサーバが合体して利用者に返送するものです。
<productname>Pgpool-II</>はこの性能を持っています。
また、<productname>PL/Proxy</>ツールセットを使用して実装できます。
    </para>

   </listitem>
  </varlistentry>

 </variablelist>

 </sect1>


 <sect1 id="warm-standby">
<!-- added by pgsql v9.0 from here to EOF
 <title>Log-Shipping Standby Servers</title>
-->
 <title>ログシッピングスタンバイサーバ</title>


  <para>
<!--
   Continuous archiving can be used to create a <firstterm>high
   availability</> (HA) cluster configuration with one or more
   <firstterm>standby servers</> ready to take over operations if the
   primary server fails. This capability is widely referred to as
   <firstterm>warm standby</> or <firstterm>log shipping</>.
-->
継続的なアーカイブ処理を使用して、プライマリサーバが失敗した場合に操作を引き継ぐ準備がなされた、1つ以上の<firstterm>スタンバイサーバ</>を持つ<firstterm>高可用性</>(HA)クラスタ構成を作成することができます。
この機能は<firstterm>ウォームスタンバイ</>または<firstterm>ログシッピング</>として広く知られています。
  </para>

  <para>
<!--
   The primary and standby server work together to provide this capability,
   though the servers are only loosely coupled. The primary server operates
   in continuous archiving mode, while each standby server operates in
   continuous recovery mode, reading the WAL files from the primary. No
   changes to the database tables are required to enable this capability,
   so it offers low administration overhead compared to some other
   replication solutions. This configuration also has relatively low
   performance impact on the primary server.
-->
プライマリサーバとスタンバイサーバは、この機能を提供するために共同して稼動しますが、サーバとサーバはゆるく結合しています。
プライマリサーバは継続的アーカイブモードで動作し、各スタンバイサーバはプライマリからWALファイルを読み取る、継続的リカバリモードで動作します。
この機能を可能にするために、データベースのテーブル変更は不要です。
したがって、他のレプリケーションの解法に比べて、管理にかかるオーバーヘッドが減少します。
この構成はプライマリサーバの性能への影響も相対的に減少させます。
  </para>

  <para>
<!--
   Directly moving WAL records from one database server to another
   is typically described as log shipping. <productname>PostgreSQL</>
   implements file-based log shipping by transferring WAL records
   one file (WAL segment) at a time. WAL files (16MB) can be
   shipped easily and cheaply over any distance, whether it be to an
   adjacent system, another system at the same site, or another system on
   the far side of the globe. The bandwidth required for this technique
   varies according to the transaction rate of the primary server.
   Record-based log shipping is more granular and streams WAL changes
   incrementally over a network connection (see <xref
   linkend="streaming-replication">).
-->
あるデータベースサーバから他へ直接WALレコードを移動することは通常、ログシッピングと説明されます。
<productname>PostgreSQL</>はファイルベースのログシッピングを実装します。
つまりWALレコードはある時点で1つのファイル(WALセグメント)として送信されることを意味します。
WALファイル(16MB)は隣り合うシステム、同じサイトの別システム、地球の裏側のシステムなど距離に関わらず、簡単かつ安価に送付することができます。
この技法に必要な帯域幅はプライマリサーバのトランザクションの頻度に応じて変動します。
レコードベースのログシッピングはより粒度を細かくしたもので、ネットワーク接続を介してWALの変更を増分的に流します（<xref linkend="streaming-replication">参照）。
  </para>

  <para>
<!--
   It should be noted that log shipping is asynchronous, i.e., the WAL
   records are shipped after transaction commit. As a result, there is a
   window for data loss should the primary server suffer a catastrophic
   failure; transactions not yet shipped will be lost.  The size of the
   data loss window in file-based log shipping can be limited by use of the
   <varname>archive_timeout</varname> parameter, which can be set as low
   as a few seconds.  However such a low setting will
   substantially increase the bandwidth required for file shipping.
   Streaming replication (see <xref linkend="streaming-replication">)
   allows a much smaller window of data loss.
-->
ログシッピングが非同期であることに注意しなければなりません。
つまり、WALレコードはトランザクションがコミットした後に転送されます。
結果として、プライマリサーバが災害などの致命的な失敗をうけた場合、送信されていないトランザクションが失われますので、データを損失する空白期間があります。
ファイルベースのログシッピングにおけるデータ損失の空白期間量を<varname>archive_timeout</varname>パラメータを用いて制限することができます。
これは数秒程度まで小さく設定することができます。
しかし、低く設定するとファイル転送に必要な帯域幅が増大します。
ストリーミングレプリケーション（<xref linkend="streaming-replication">参照）により、データを損失する期間を非常に小さくすることができます。
  </para>

  <para>
<!--
   Recovery performance is sufficiently good that the standby will
   typically be only moments away from full
   availability once it has been activated. As a result, this is called
   a warm standby configuration which offers high
   availability. Restoring a server from an archived base backup and
   rollforward will take considerably longer, so that technique only
   offers a solution for disaster recovery, not high availability.
   A standby server can also be used for read-only queries, in which case
   it is called a Hot Standby server. See <xref linkend="hot-standby"> for
   more information.
-->
リカバリ処理の性能は十分よく、一度実施されれば、スタンバイサーバが完全な状態から逸脱するのは一時的にしかすぎません。
結果としてこれは、高可用性を提供するウォームスタンバイ構成と呼ばれます。
保管されたベースバックアップからサーバをリストアし、ロールフォワードを行うことはおそらく長時間かかりますので、これは高可用性のための解法とはいえず、災害からのリカバリのための解法です。
スタンバイサーバは読み取り専用の問い合わせに使用することもできます。
この場合ホットスタンバイサーバと呼ばれます。
詳細については<xref linkend="hot-standby">を参照してください。
  </para>

  <indexterm zone="high-availability">
<!--
   <primary>warm standby</primary>
-->
   <primary>ウォームスタンバイ</primary>
  </indexterm>

  <indexterm zone="high-availability">
<!--
   <primary>PITR standby</primary>
-->
   <primary>PITRスタンバイ</primary>
  </indexterm>

  <indexterm zone="high-availability">
<!--
   <primary>standby server</primary>
-->
   <primary>スタンバイサーバ</primary>
  </indexterm>

  <indexterm zone="high-availability">
<!--
   <primary>log shipping</primary>
-->
   <primary>ログシッピング</primary>
  </indexterm>

  <indexterm zone="high-availability">
<!--
   <primary>witness server</primary>
-->
   <primary>証明サーバ</primary>
  </indexterm>

  <indexterm zone="high-availability">
   <primary>STONITH</primary>
  </indexterm>

  <sect2 id="standby-planning">
<!--
   <title>Planning</title>
-->
   <title>計画</title>

   <para>
<!--
    It is usually wise to create the primary and standby servers
    so that they are as similar as possible, at least from the
    perspective of the database server.  In particular, the path names
    associated with tablespaces will be passed across unmodified, so both
    primary and standby servers must have the same mount paths for
    tablespaces if that feature is used.  Keep in mind that if
    <xref linkend="sql-createtablespace">
    is executed on the primary, any new mount point needed for it must
    be created on the primary and all standby servers before the command
    is executed. Hardware need not be exactly the same, but experience shows
    that maintaining two identical systems is easier than maintaining two
    dissimilar ones over the lifetime of the application and system.
    In any case the hardware architecture must be the same &mdash; shipping
    from, say, a 32-bit to a 64-bit system will not work.
-->
プライマリサーバとスタンバイサーバを、少なくともデータベースサーバという見地でできる限り同じになるように作成することを通常勧めます。
具体的には、テーブル空間に関連するパス名はそのまま渡されますので、テーブル空間機能を使用する場合には、プライマリとスタンバイサーバの両方でテーブル空間用のマウントパスを同じにしておかなければなりません。
<xref linkend="sql-createtablespace">をプライマリで実行する場合、そのコマンドを実行する前に必要な新しいマウントポイントをプライマリとすべてのスタンバイサーバで作成しなければならないことに注意してください。
ハードウェアをまったく同じにする必要はありませんが、経験上アプリケーションとシステムの運用期間に渡って2つの同じシステムを管理する方が、異なる2つのシステムを管理するよりも簡単です。
いずれにしてもハードウェアアーキテクチャは必ず同じでなければなりません。
例えば32ビットシステムから64ビットシステムへのシッピングは動作しません。
   </para>

   <para>
<!--
    In general, log shipping between servers running different major
    <productname>PostgreSQL</> release
    levels is not possible. It is the policy of the PostgreSQL Global
    Development Group not to make changes to disk formats during minor release
    upgrades, so it is likely that running different minor release levels
    on primary and standby servers will work successfully. However, no
    formal support for that is offered and you are advised to keep primary
    and standby servers at the same release level as much as possible.
    When updating to a new minor release, the safest policy is to update
    the standby servers first &mdash; a new minor release is more likely
    to be able to read WAL files from a previous minor release than vice
    versa.
-->
マイナーリリースの更新ではディスク書式を変更しないというのがPostgreSQLグローバル開発グループの方針ですので、プライマリサーバとスタンバイサーバとの間でマイナーリリースレベルの違いがあってもうまく動作するはずです。
しかし、この場合、公的なサポートは提供されません。
できる限りプライマリサーバとスタンバイサーバとで同じリリースレベルを使用してください。
新しいマイナーリリースに更新する場合、もっとも安全な方針はスタンバイサーバを先に更新することです。
新しいマイナーリリースは以前のマイナーリリースのWALファイルを読み込むことはできますが、逆はできないかもしれません。
   </para>

  </sect2>

  <sect2 id="standby-server-operation">
<!--
   <title>Standby Server Operation</title>
-->
   <title>スタンバイサーバの動作</title>

   <para>
<!--
    In standby mode, the server continuously applies WAL received from the
    master server. The standby server can read WAL from a WAL archive
    (see <xref linkend="restore-command">) or directly from the master
    over a TCP connection (streaming replication). The standby server will
    also attempt to restore any WAL found in the standby cluster's
    <filename>pg_xlog</> directory. That typically happens after a server
    restart, when the standby replays again WAL that was streamed from the
    master before the restart, but you can also manually copy files to
    <filename>pg_xlog</> at any time to have them replayed.
-->
スタンバイモードでは、サーバは継続的にマスタサーバから受け取ったWALを適用します。
スタンバイサーバはWALアーカイブ(<xref linkend="restore-command">参照)から、または直接TCP接続(ストリーミングレプリケーション)を介してマスタサーバから、WALを読み取ることができます。
またスタンバイサーバはスタンバイクラスタの<filename>pg_xlog</>ディレクトリにあるすべてのWALをリストアしようと試みます。
これはよくサーバの再起動後、スタンバイが再起動前にマスタから流れ込んだWALを再生する時に発生します。
しかしまたファイルを再生する任意の時点で、手作業で<filename>pg_xlog</>にコピーすることもできます。
   </para>

   <para>
<!--
    At startup, the standby begins by restoring all WAL available in the
    archive location, calling <varname>restore_command</>. Once it
    reaches the end of WAL available there and <varname>restore_command</>
    fails, it tries to restore any WAL available in the <filename>pg_xlog</> directory.
    If that fails, and streaming replication has been configured, the
    standby tries to connect to the primary server and start streaming WAL
    from the last valid record found in archive or <filename>pg_xlog</>. If that fails
    or streaming replication is not configured, or if the connection is
    later disconnected, the standby goes back to step 1 and tries to
    restore the file from the archive again. This loop of retries from the
    archive, <filename>pg_xlog</>, and via streaming replication goes on until the server
    is stopped or failover is triggered by a trigger file.
-->
起動時、スタンバイサーバは<varname>restore_command</>を呼び出して、アーカイブ場所にある利用可能なすべてのWALをリストアすることから始めます。
そこで利用可能なWALの終端に達し、<varname>restore_command</>が失敗すると、<filename>pg_xlog</>ディレクトリにある利用可能な任意のWALのリストアを試みます。
ストリーミングレプリケーションが設定されている場合、これに失敗すると、スタンバイはプライマリサーバへの接続を試み、アーカイブまたは<filename>pg_xlog</>内に存在した最終の有効レコードからWALのストリーミングを開始します。
ストリーミングレプリケーションが未設定時にこれに失敗する場合、または、接続が後で切断される場合、スタンバイは最初に戻り、アーカイブからのファイルのリストアを繰り返し行います。
このアーカイブ、<filename>pg_xlog</>、ストリーミングレプリケーションからという再試行の繰り返しはサーバが停止する、あるいはトリガファイルによるフェールオーバが発行されるまで続きます。
   </para>

   <para>
<!--
    Standby mode is exited and the server switches to normal operation
    when <command>pg_ctl promote</> is run or a trigger file is found
    (<varname>trigger_file</>). Before failover,
    any WAL immediately available in the archive or in <filename>pg_xlog</> will be
    restored, but no attempt is made to connect to the master.
-->
<command>pg_ctl promote</>が実行された時またはトリガファイル(<varname>trigger_file</>)が存在する時、スタンバイモードは終了し、サーバは通常の動作に切り替わります。
フェールオーバの前に、アーカイブまたは<filename>pg_xlog</>内の即座に利用可能なWALをすべてリストアします。
しかし、マスタへの接続を行おうとはしません。
   </para>
  </sect2>

  <sect2 id="preparing-master-for-standby">
<!--
   <title>Preparing the Master for Standby Servers</title>
-->
   <title>スタンバイサーバのためのマスタの準備</title>

   <para>
<!--
    Set up continuous archiving on the primary to an archive directory
    accessible from the standby, as described
    in <xref linkend="continuous-archiving">. The archive location should be
    accessible from the standby even when the master is down, i.e. it should
    reside on the standby server itself or another trusted server, not on
    the master server.
-->
<xref linkend="continuous-archiving">で説明したように、スタンバイからアクセス可能なアーカイブディレクトリに対してプライマリで継続的なアーカイブを設定してください。
このアーカイブ場所はマスタが停止した時であってもスタンバイからアクセス可能でなければなりません。
つまり、マスタサーバ上ではなく、スタンバイサーバ自身上に存在するか、または他の高信頼性サーバ上に存在しなければなりません。
   </para>

   <para>
<!--
    If you want to use streaming replication, set up authentication on the
    primary server to allow replication connections from the standby
    server(s); that is, create a role and provide a suitable entry or
    entries in <filename>pg_hba.conf</> with the database field set to
    <literal>replication</>.  Also ensure <varname>max_wal_senders</> is set
    to a sufficiently large value in the configuration file of the primary
    server.If replication slots will be used,
    ensure that <varname>max_replication_slots</varname> is set sufficiently
    high as well.
-->
ストリーミングレプリケーションを使用したい場合、スタンバイサーバ(複数可)からのレプリケーション接続を受け付けるようにプライマリサーバで認証を設定してください。
つまり、ロールを作成し適切な項目を提供、あるいは、そのデータベースフィールドとして<literal>replication</>を持つ項目を<filename>pg_hba.conf</>内に設定してください。
また、プライマリサーバの設定ファイルにおいて<varname>max_wal_senders</>が十分大きな値に設定されていることを確認してください。
レプリケーションスロットを使用している場合は、<varname>max_replication_slots</varname>も十分に設定されているか確認してください。
   </para>

   <para>
<!--
    Take a base backup as described in <xref linkend="backup-base-backup">
    to bootstrap the standby server.
-->
<xref linkend="backup-base-backup">に記述したように、スタンバイサーバの再起動のために、ベースバックアップを取得してください。
   </para>
  </sect2>

  <sect2 id="standby-server-setup">
<!--
   <title>Setting Up a Standby Server</title>
-->
   <title>スタンバイサーバの設定</title>

   <para>
<!--
    To set up the standby server, restore the base backup taken from primary
    server (see <xref linkend="backup-pitr-recovery">). Create a recovery
    command file <filename>recovery.conf</> in the standby's cluster data
    directory, and turn on <varname>standby_mode</>. Set
    <varname>restore_command</> to a simple command to copy files from
    the WAL archive. If you plan to have multiple standby servers for high
    availability purposes, set <varname>recovery_target_timeline</> to
    <literal>latest</>, to make the standby server follow the timeline change
    that occurs at failover to another standby.
-->
スタンバイサーバを設定するためには、プライマリサーバから取得したベースバックアップをリストアしてください(<xref linkend="backup-pitr-recovery">参照)。
スタンバイのクラスタデータディレクトリ内に<filename>recovery.conf</>リカバリコマンドファイルを作成し、<varname>standby_mode</>を有効にしてください。
WALアーカイブからファイルをコピーする簡単なコマンドを<varname>restore_command</>に設定してください。
高可用性のために複数のスタンバイサーバを持たせようとしている場合、<varname>recovery_target_timeline</>を<literal>latest</>に設定し、スタンバイサーバが他のスタンバイにフェールオーバする時に発生するタイムラインの変更に従うようにします。
   </para>

   <note>
     <para>
<!--
     Do not use pg_standby or similar tools with the built-in standby mode
     described here. <varname>restore_command</> should return immediately
     if the file does not exist; the server will retry the command again if
     necessary. See <xref linkend="log-shipping-alternative">
     for using tools like pg_standby.
-->
ここで説明した組込みのスタンバイモードといっしょにpg_standbyや類似ツールを使用しないでください。
<varname>restore_command</>はファイルが存在しない場合に即座に終了しなければなりません。
サーバが必要に応じてそのコマンドを再度実行します。
pg_standbyのようなツールを使用するためには<xref linkend="log-shipping-alternative">を参照してください。
    </para>
   </note>

   <para>
<!--
     If you want to use streaming replication, fill in
     <varname>primary_conninfo</> with a libpq connection string, including
     the host name (or IP address) and any additional details needed to
     connect to the primary server. If the primary needs a password for
     authentication, the password needs to be specified in
     <varname>primary_conninfo</> as well.
-->
ストリーミングレプリケーションを使用したい場合には、ホスト名(またはIPアドレス)とプライマリサーバとの接続に必要な追加情報を含む、libpq接続文字列で<varname>primary_conninfo</>を記述してください。
プライマリで認証用のパスワードが必要な場合は<varname>primary_conninfo</>にそのパスワードも指定する必要があります。
   </para>

   <para>
<!--
    If you're setting up the standby server for high availability purposes,
    set up WAL archiving, connections and authentication like the primary
    server, because the standby server will work as a primary server after
    failover.
-->
スタンバイサーバを高可用性を目的に設定しているのであれば、スタンバイサーバはフェールオーバの後プライマリサーバとして動作しますので、プライマリサーバと同様にWALアーカイブ処理、接続、認証を設定してください。
   </para>

   <para>
<!--
    If you're using a WAL archive, its size can be minimized using the <xref
    linkend="archive-cleanup-command"> parameter to remove files that are no
    longer required by the standby server.
    The <application>pg_archivecleanup</> utility is designed specifically to
    be used with <varname>archive_cleanup_command</> in typical single-standby
    configurations, see <xref linkend="pgarchivecleanup">.
    Note however, that if you're using the archive for backup purposes, you
    need to retain files needed to recover from at least the latest base
    backup, even if they're no longer needed by the standby.
-->
WALアーカイブを使用している場合、<xref linkend="archive-cleanup-command">パラメータを使用してスタンバイサーバで不要となったファイルを削除することで、その容量を最小化することができます。
特に<application>pg_archivecleanup</>ユーティリティは、典型的な単一スタンバイ構成（<xref linkend="pgarchivecleanup">参照）における<varname>archive_cleanup_command</>と共に使用されるように設計されています。
しかし、バックアップを目的にアーカイブを使用している場合には、スタンバイから必要とされなくなったファイルであっても、最新のベースバックアップの時点からリカバリするために必要なファイルを保持しなければならないことに注意してください。
   </para>

   <para>
<!--
    A simple example of a <filename>recovery.conf</> is:
-->
<filename>recovery.conf</>の簡単な例を以下に示します。
<programlisting>
standby_mode = 'on'
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'
restore_command = 'cp /path/to/archive/%f %p'
archive_cleanup_command = 'pg_archivecleanup /path/to/archive %r'
</programlisting>
   </para>

   <para>
<!--
    You can have any number of standby servers, but if you use streaming
    replication, make sure you set <varname>max_wal_senders</> high enough in
    the primary to allow them to be connected simultaneously.
-->
スタンバイサーバの台数に制限はありませんが、ストリーミングレプリケーションを使用するなら、プライマリサーバに同時に接続できるように<varname>max_wal_senders</>を十分な数に設定してください。
   </para>

  </sect2>

  <sect2 id="streaming-replication">
<!--
   <title>Streaming Replication</title>
-->
   <title>ストリーミングレプリケーション</title>

   <indexterm zone="high-availability">
<!--
    <primary>Streaming Replication</primary>
-->
    <primary>ストリーミングレプリケーション</primary>
   </indexterm>

   <para>
<!--
    Streaming replication allows a standby server to stay more up-to-date
    than is possible with file-based log shipping. The standby connects
    to the primary, which streams WAL records to the standby as they're
    generated, without waiting for the WAL file to be filled.
-->
ストリーミングレプリケーションによりスタンバイサーバはファイルベースのログシッピングよりもより最近の状態を維持できるようになります。
スタンバイは、WALレコードが生成された時にWALファイルがいっぱいになるまで待機せずにWALレコードをスタンバイに流し出すプライマリと接続します。
   </para>

   <para>
<!--
    Streaming replication is asynchronous, so there is still a small delay
    between committing a transaction in the primary and for the changes to
    become visible in the standby. The delay is however much smaller than with
    file-based log shipping, typically under one second assuming the standby
    is powerful enough to keep up with the load. With streaming replication,
    <varname>archive_timeout</> is not required to reduce the data loss
    window.

    Streaming replication is asynchronous by default
    (see <xref linkend="synchronous-replication">), in which case there is
    a small delay between committing a transaction in the primary and the
    changes becoming visible in the standby. This delay is however much 
    smaller than with file-based log shipping, typically under one second
    assuming the standby is powerful enough to keep up with the load. With 
    streaming replication, <varname>archive_timeout</> is not required to
    reduce the data loss window.


-->
ストリーミングレプリケーションはデフォルトで非同期で、(<xref linkend="synchronous-replication">参照)
この場合、プライマリでトランザクションがコミットされてから、その変更がスタンバイ側で参照可能になるまでの間にわずかな遅延がまだあります。
しかし、この遅延はファイルベースのログシッピングよりも非常に小さなもので、負荷に追随できる程度の能力があるスタンバイであれば通常は1秒以下です。
ストリーミングレプリケーションでは、データ損失期間を減らすための<varname>archive_timeout</>を必要としません。
   </para>

   <para>
<!--
    If you use streaming replication without file-based continuous
    archiving, the server might recycle old WAL segments before the standby
    has received them.  If this occurs, the standby will need to be
    reinitialized from a new base backup.  You can avoid this by setting
    <varname>wal_keep_segments</> to a value large enough to ensure that
    WAL segments are not recycled too early, or by configuring a replication
    slot for the standby.  If you set up a WAL archive that's accessible from
    the standby, these solutions are not required, since the standby can
    always use the archive to catch up provided it retains enough segments.
-->
ファイルベースの継続的アーカイブのないストリーミングレプリケーションを使用している場合、スタンバイが受け取る前に古いWALセグメントを再利用するかもしれません。
もし、そうなった場合はスタンバイは新しいベースバックアップから再作成しなければならなくなります。
<varname>wal_keep_segments</>を十分に大きくしたり、レプリケーションスロットにスタンバイを設定することでWALセグメントがすぐに再利用されることを防ぎ、これを防ぐことができます。WALアーカイブをスタンバイからアクセスできる位置に設定する場合は、スタンバイが常にWALセグメントを追随することができるため、これらの解決策は要求されません。
   </para>

   <para>
<!--
    To use streaming replication, set up a file-based log-shipping standby
    server as described in <xref linkend="warm-standby">. The step that
    turns a file-based log-shipping standby into streaming replication
    standby is setting <varname>primary_conninfo</> setting in the
    <filename>recovery.conf</> file to point to the primary server. Set
    <xref linkend="guc-listen-addresses"> and authentication options
    (see <filename>pg_hba.conf</>) on the primary so that the standby server
    can connect to the <literal>replication</> pseudo-database on the primary
    server (see <xref linkend="streaming-replication-authentication">).
-->
ストリーミングレプリケーションを使用するためには、<xref linkend="warm-standby">の説明のようにファイルベースのログシッピングを行うスタンバイサーバを設定してください。
ファイルベースのログシッピングを行うスタンバイをストリーミングレプリケーションを行うスタンバイに切り替える手順は、<filename>recovery.conf</>内の<varname>primary_conninfo</>設定をプライマリサーバを指し示すように設定することです。
スタンバイサーバがプライマリサーバ上の<literal>replication</>疑似データベースに接続できる(<xref linkend="streaming-replication-authentication">参照)ように、プライマリで<xref linkend="guc-listen-addresses">と認証オプション(<filename>pg_hba.conf</>参照)を設定してください。
   </para>

   <para>
<!--
    On systems that support the keepalive socket option, setting
    <xref linkend="guc-tcp-keepalives-idle">,
    <xref linkend="guc-tcp-keepalives-interval"> and
    <xref linkend="guc-tcp-keepalives-count"> helps the primary promptly
    notice a broken connection.
-->
キープアライブソケットオプションをサポートするシステムでは、<xref linkend="guc-tcp-keepalives-idle">、<xref linkend="guc-tcp-keepalives-interval">および<xref linkend="guc-tcp-keepalives-count">を設定することで、プライマリの接続切断の即時検知に有用です。
   </para>

   <para>
<!--
    Set the maximum number of concurrent connections from the standby servers
    (see <xref linkend="guc-max-wal-senders"> for details).
-->
スタンバイサーバからの同時接続数の最大値を設定してください（詳細は<xref linkend="guc-max-wal-senders">を参照）。
   </para>

   <para>
<!--
    When the standby is started and <varname>primary_conninfo</> is set
    correctly, the standby will connect to the primary after replaying all
    WAL files available in the archive. If the connection is established
    successfully, you will see a walreceiver process in the standby, and
    a corresponding walsender process in the primary.
-->
スタンバイが起動し、<varname>primary_conninfo</>が正しく設定されると、スタンバイはアーカイブ内で利用可能なWALファイルをすべて再生した後にプライマリと接続します。
接続の確立に成功すると、スタンバイでWAL受信プロセスが存在し、プライマリで対応するWAL送信プロセスが存在します。
   </para>

   <sect3 id="streaming-replication-authentication">
<!--
    <title>Authentication</title>
-->
    <title>認証</title>
    <para>
<!--
     It is very important that the access privileges for replication be set up
     so that only trusted users can read the WAL stream, because it is
     easy to extract privileged information from it.  Standby servers must
     authenticate to the primary as a superuser or an account that has the
     <literal>REPLICATION</> privilege. It is recommended to create a
     dedicated user account with <literal>REPLICATION</> and <literal>LOGIN</>
     privileges for replication. While <literal>REPLICATION</> privilege gives
     very high permissions, it does not allow the user to modify any data on
     the primary system, which the <literal>SUPERUSER</> privilege does.
-->
信頼できるユーザのみがWALストリームを読み取ることができるように、レプリケーション用のアクセス権限を設定することは非常に重要です。
WALから機密情報を取り出すことは簡単だからです。
スタンバイサーバはプライマリに対してプライマリのスーパーユーザか<literal>REPLICATION</>権限を持つアカウントとして認証されなければなりません。
レプリケーションのための<literal>REPLICATION</>権限 と <literal>LOGIN</>権限を持つ専用のユーザを作成することをお勧めします。
<literal>REPLICATION</>権限は非常に強力な権限なので、<literal>SUPERUSER</>のようにプライマリのデータを変更することを許可されていません。

    </para>

    <para>
<!--
     Client authentication for replication is controlled by a
     <filename>pg_hba.conf</> record specifying <literal>replication</> in the
     <replaceable>database</> field. For example, if the standby is running on
     host IP <literal>192.168.1.100</> and the account name for replication
     is <literal>foo</>, the administrator can add the following line to the
     <filename>pg_hba.conf</> file on the primary:
-->
レプリケーション用のクライアント認証は<filename>pg_hba.conf</>内でその<replaceable>database</>フィールドに<literal>replication</>を指定したレコードで制御されます。
例えば、スタンバイがIPアドレス<literal>192.168.1.100</>のホストで稼動し、レプリケーション用のアカウントの名前が<literal>foo</>である場合、管理者はプライマリ上の<filename>pg_hba.conf</>に以下の行を追加することができます。

<programlisting>
<!--
# Allow the user "foo" from host 192.168.1.100 to connect to the primary
# as a replication standby if the user's password is correctly supplied.
#
# TYPE  DATABASE        USER            ADDRESS                 METHOD
host    replication     foo             192.168.1.100/32        md5
-->
# 利用者 foo のホスト 192.168.1.100 からプライマリサーバへのレプリケーションスタンバイとしての接続を
# 利用者のパスワードが正しく入力されたならば許可する
#
# TYPE  DATABASE        USER            ADDRESS                 METHOD
host    replication     foo             192.168.1.100/32        md5
</programlisting>
    </para>
    <para>
<!--
     The host name and port number of the primary, connection user name,
     and password are specified in the <filename>recovery.conf</> file.
     The password can also be set in the <filename>~/.pgpass</> file on the
     standby (specify <literal>replication</> in the <replaceable>database</>
     field).
     For example, if the primary is running on host IP <literal>192.168.1.50</>,
     port <literal>5432</literal>, the account name for replication is
     <literal>foo</>, and the password is <literal>foopass</>, the administrator
     can add the following line to the <filename>recovery.conf</> file on the
     standby:
-->
プライマリサーバのホスト名とポート番号、接続する利用者名およびパスワードは、<filename>recovery.conf</>ファイルで指定します。
パスワードはスタンバイサーバの<filename>~/.pgpass</>ファイルでも設定できます（<replaceable>database</>フィールドの<literal>replication</>を指定します）。
例えば、プライマリサーバが稼動するホストの IP アドレスが<literal>192.168.1.50</>でポート番号が<literal>5432</literal>であり、レプリケーションのアカウント名が<literal>foo</>であり、パスワードが<literal>foopass</>である場合、管理者はスタンバイサーバの<filename>recovery.conf</>ファイルに次行を追加できます。

<programlisting>
<!--
# The standby connects to the primary that is running on host 192.168.1.50
# and port 5432 as the user "foo" whose password is "foopass".
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'
-->
# プライマリサーバが 192.168.1.50 のホストの 5432ポートで稼動し
# 利用者名が foo でパスワードが foopass とする
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'
</programlisting>
    </para>
   </sect3>

   <sect3 id="streaming-replication-monitoring">
<!--
    <title>Monitoring</title>
-->
    <title>監視</title>
    <para>
<!--
     An important health indicator of streaming replication is the amount
     of WAL records generated in the primary, but not yet applied in the
     standby. You can calculate this lag by comparing the current WAL write
     location on the primary with the last WAL location received by the
     standby. They can be retrieved using
     <function>pg_current_xlog_location</> on the primary and the
     <function>pg_last_xlog_receive_location</> on the standby,
     respectively (see <xref linkend="functions-admin-backup-table"> and
     <xref linkend="functions-recovery-info-table"> for details).
     The last WAL receive location in the standby is also displayed in the
     process status of the WAL receiver process, displayed using the
     <command>ps</> command (see <xref linkend="monitoring-ps"> for details).
-->
ストリーミングレプリケーションの重要な健全性尺度は、プライマリサーバで生成されたがスタンバイサーバではまだ適用されていないWALレコードの量です。
プライマリサーバの現在のWAL書き込み位置とスタンバイサーバの受理したWALの最終位置を比較すれば、この遅延を計算できます。
これらの位置は、プライマリサーバでは<function>pg_current_xlog_location</>を、スタンバイサーバでは<function>pg_last_xlog_receive_location</>を使用すれば検索できます（詳細は<xref linkend="functions-admin-backup-table">および<xref linkend="functions-recovery-info-table">を参照）。
スタンバイサーバの最終位置は、<command>ps</>コマンドを使用して WAL受信プロセスの状態としても表示できます（詳細は<xref linkend="monitoring-ps">を参照）。
    </para>
    <para>
<!--
     You can retrieve a list of WAL sender processes via the
     <link linkend="monitoring-stats-views-table">
     <literal>pg_stat_replication</></link> view. Large differences between
     <function>pg_current_xlog_location</> and <literal>sent_location</> field
     might indicate that the master server is under heavy load, while
     differences between <literal>sent_location</> and
     <function>pg_last_xlog_receive_location</> on the standby might indicate
     network delay, or that the standby is under heavy load.
-->
<link linkend="monitoring-stats-views-table"><literal>pg_stat_replication</></link>ビューを介してWAL送信処理プロセスのリストを入手することができます。
<function>pg_current_xlog_location</>と<literal>sent_location</>フィールドとの違いが大きい場合、マスタサーバが高負荷状態であることを示している可能性があります。
一方でスタンバイサーバ上の<literal>sent_location</>と<function>pg_last_xlog_receive_location</>の値の差異は、ネットワーク遅延、またはスタンバイが高負荷状態であることを示す可能性があります。
    </para>
   </sect3>

  </sect2>
  <sect2 id="streaming-replication-slots">
<!--   <title>Replication Slots</title>　-->
   <title>レプリケーションスロット</title>
   <indexterm>
    <primary>replication slot</primary>
    <secondary>streaming replication</secondary>
   </indexterm>
   <para>
<!--
    Replication slots provide an automated way to ensure that the master does
    not remove WAL segments until they have been received by all standbys,
    and that the master does not remove rows which could cause a
    <link linkend="hot-standby-conflict">recovery conflict</> even when the
    standby is disconnected.
-->
レプリケーションスロットはマスターが全てのスタンバイがWALセグメントを受け取るまで削除を防止したり、たとえ、スタンバイが接続していなくとも、マスターが行を削除してしまう<link linkend="hot-standby-conflict">リカバリの競合</>を自動的に防ぐ機能を提供します。
   </para>
   <para>
<!--
    In lieu of using replication slots, it is possible to prevent the removal
    of old WAL segments using <xref linkend="guc-wal-keep-segments">, or by
    storing the segments in an archive using
    <xref linkend="guc-archive-command">.
    However, these methods often result in retaining more WAL segments than
    required, whereas replication slots retain only the number of segments
    known to be needed.  An advantage of these methods is that they bound
    the space requirement for <literal>pg_xlog</>; there is currently no way
    to do this using replication slots.
-->
レプリケーションスロットを使用しない場合、古いWALセグメントの削除を防ぐためには、<xref linkend="guc-wal-keep-segments">を使用するか、アーカイブ<xref linkend="guc-archive-command">を使用します。
しかし、これらの方法は要求される以上のWALを残すことに対し、レプリケーションスロットは必要と判断されたWALのみを残します。
これらの方法のメリットは<literal>pg_xlog</>が要求する領域を抑制することです。現時点でレプリケーションスロットを使用する他の目的はありません。
   </para>
   <para>
<!--
    Similarly, <xref linkend="guc-hot-standby-feedback">
    and <xref linkend="guc-vacuum-defer-cleanup-age"> provide protection against
    relevant rows being removed by vacuum, but the former provides no
    protection during any time period when the standby is not connected,
    and the latter often needs to be set to a high value to provide adequate
    protection.  Replication slots overcome these disadvantages.
-->
同様に、<xref linkend="guc-hot-standby-feedback">と<xref linkend="guc-vacuum-defer-cleanup-age">はまだ使用する行がvacuumにより削除されることを防ぐ機能を提供しますが、スタンバイが接続されていない時間の行は保護出来ず、十分に保護するために高い値を設定することがしばしばあります。レプリケーションスロットにはこのような短所がありません。
   </para>
   <sect3 id="streaming-replication-slots-manipulation">
<!--    <title>Querying and manipulating replication slots</title> -->
    <title>レプリケーションスロットへの問い合わせと操作</title>
    <para>
<!--     Each replication slot has a name, which can contain lower-case letters,
     numbers, and the underscore character.
-->
いずれのレプリケーションスロットにも小文字、数字、アンダースコアを含む名前があります。
    </para>
    <para>
<!--     Existing replication slots and their state can be seen in the
     <link linkend="catalog-pg-replication-slots"><structname>pg_replication_slots</structname></link>
     view.
-->
レプリケーションスロットとその状態は<link linkend="catalog-pg-replication-slots"><structname>pg_replication_slots</structname></link>
ビューより確認できます。

    </para>
    <para>
<!--
     Slots can be created and dropped either via the streaming replication
     protocol (see <xref linkend="protocol-replication">) or via SQL
     functions (see <xref linkend="functions-replication">).
-->

レプリケーションスロットはストリーミングレプリケーションプロトコル( <xref linkend="protocol-replication">参照)もしくはSQLファンクション(<xref linkend="functions-replication">参照)を使用し、作成や削除ができます。
    </para>
   </sect3>
   <sect3 id="streaming-replication-slots-config">
<!--    <title>Configuration Example</title> -->
    <title>設定の例</title>
    <para>
<!--     You can create a replication slot like this:　-->
以下のような方法でレプリケーションを作成できます。


<programlisting>
postgres=# SELECT * FROM pg_create_physical_replication_slot('node_a_slot');
  slot_name  | xlog_position
-------------+---------------
 node_a_slot |

postgres=# SELECT * FROM pg_replication_slots;
  slot_name  | slot_type | datoid | database | active | xmin | restart_lsn
-------------+-----------+--------+----------+--------+------+-------------
 node_a_slot | physical  |        |          | f      |      |
(1 row)
</programlisting>
<!--
     To configure the standby to use this slot, <varname>primary_slot_name</>
     should be configured in the standby's <filename>recovery.conf</>.
     Here is a simple example:
-->
スタンバイのレプリケーションスロットを使用できるように設定するためには、<varname>primary_slot_name</>をスタンバイ側の<filename>recovery.conf</>に設定します。
以下は設定例です。：
<programlisting>
standby_mode = 'on'
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'
primary_slot_name = 'node_a_slot'
</programlisting>
    </para>
   </sect3>
  </sect2>

<!--
  <sect2 id="cascading-replication">
-->
  <sect2 id="cascading-replication">
<!--
   <title>Cascading Replication</title>
-->
   <title>カスケードレプリケーション</title>

<!--
   <indexterm zone="high-availability">
-->
   <indexterm zone="high-availability">
<!--
    <primary>Cascading Replication</primary>
-->
    <primary>カスケードレプリケーション</primary>
   </indexterm>


   <para>
<!--
    The cascading replication feature allows a standby server to accept replication
    connections and stream WAL records to other standbys, acting as a relay.
    This can be used to reduce the number of direct connections to the master
    and also to minimize inter-site bandwidth overheads.
-->
カスケードレプリケーションは、リレーのような振る舞い、つまり、スタンバイサーバから他のスタンバイにレプリケーション接続し、WALレコードを送信することができます。
マスターサーバへ直接の接続を減らしたり、サイト相互の帯域オーバヘッドを最小化するために使用することができます。

   </para>

   <para>
<!--
    A standby acting as both a receiver and a sender is known as a cascading
    standby.  Standbys that are more directly connected to the master are known
    as upstream servers, while those standby servers further away are downstream
    servers.  Cascading replication does not place limits on the number or
    arrangement of downstream servers, though each standby connects to only
    one upstream server which eventually links to a single master/primary
    server.
-->
カスケードスタンバイとして知られているとおり、スタンバイは受け取り手としても送り手としても振る舞うことができます。
よりマスターサーバに近いスタンバイサーバは上流サーバと呼ばれるのに対し、より遠いスタンバイサーバは下流サーバと呼ばれます。
カスケードレプリケーションには下流サーバの数に制限は設定されていません。しかし、どのスタンバイサーバも最終的には1つのマスター/プライマリサーバに繋がる1つの上流サーバに接続します。

   </para>

   <para>
<!--
    A cascading standby sends not only WAL records received from the
    master but also those restored from the archive. So even if the replication
    connection in some upstream connection is terminated, streaming replication
    continues downstream for as long as new WAL records are available.
-->
カスケードスタンバイはマスターから受け取ったWALレコードだけでなく、アーカイブからリストアしたWALアーカイブも送信します。
このため、レプリケーション接続が上流サーバで切断しても、ストリーミングレプリケーションは下流サーバへ新しいWAL
レコードがある限り継続します。
   </para>

   <para>
<!--
    Cascading replication is currently asynchronous. Synchronous replication
    (see <xref linkend="synchronous-replication">) settings have no effect on
    cascading replication at present.
-->
カスケードレプリケーションは現時点では非同期です。同期レプリケーション（参照<xref linkend="synchronous-replication">）の設定は現時点でカスケードレプリケーションへは影響を与えません。
   </para>

   <para>
<!--
    Hot Standby feedback propagates upstream, whatever the cascaded arrangement.
-->
ホットスタンバイがどの様に配置されていても、ホットスタンバイフィードバックは上流に伝播します。
   </para>

   <para>
<!--
    If an upstream standby server is promoted to become new master, downstream
    servers will continue to stream from the new master if
    <varname>recovery_target_timeline</> is set to <literal>'latest'</>. 
-->
上流スタンバイサーバが昇格し、新しいマスターサーバになった場合、<varname>recovery_target_timeline</>が<literal>'latest'</>に設定されていれば、下流サーバは新マスターサーバからのストリーミングレプリケーションを継続します。
   </para>

   <para>
<!--
    To use cascading replication, set up the cascading standby so that it can
    accept replication connections (that is, set
    <xref linkend="guc-max-wal-senders"> and <xref linkend="guc-hot-standby">,
    and configure
    <link linkend="auth-pg-hba-conf">host-based authentication</link>).
    You will also need to set <varname>primary_conninfo</> in the downstream
    standby to point to the cascading standby.
-->
カスケードレプリケーションを使うためには、カスケードスタンバイをセットアップ、つまり、レプリケーション接続を許可してください。(<xref linkend="guc-max-wal-senders">と<xref linkend="guc-hot-standby">および、 <link linkend="auth-pg-hba-conf">クライアント認証</link>を設定してください)
また、下流スタンバイがカスケードスタンバイに接続できるために、下流スタンバイでは<varname>primary_conninfo</>を設定する必要があります。
   </para>
  </sect2>

  <sect2 id="synchronous-replication">
<!--
   <title>Synchronous Replication</title>
-->
   <title>同期レプリケーション</title>

   <indexterm zone="high-availability">
<!--
    <primary>Synchronous Replication</primary>
-->
    <primary>同期レプリケーション</primary>
   </indexterm>

   <para>
<!--
    <productname>PostgreSQL</> streaming replication is asynchronous by
    default. If the primary server
    crashes then some transactions that were committed may not have been
    replicated to the standby server, causing data loss. The amount
    of data loss is proportional to the replication delay at the time of
    failover.
-->
<productname>PostgreSQL</>のストリーミングレプリケーションはデフォルトで非同期です。
プライマリサーバがクラッシュした場合、コミットされた一部のトランザクションがスタンバイサーバに複製されず、データ損失を引き起こす可能性があります。
データ損失量はフェールオーバ時点のレプリケーション遅延に比例します。
   </para>

   <para>
<!--
    Synchronous replication offers the ability to confirm that all changes
    made by a transaction have been transferred to one synchronous standby
    server. This extends the standard level of durability
    offered by a transaction commit. This level of protection is referred
    to as 2-safe replication in computer science theory.
-->
同期レプリケーションは、あるトランザクションでなされた変更はすべて、１つの同期スタンバイサーバに転送されていることを確実にする機能を提供します。
これはトランザクションコミットで提供される永続性の標準レベルを拡張します。
この保護レベルはコンピュータ科学理論では2-safeレプリケーションと呼ばれます。
   </para>

   <para>
<!--
    When requesting synchronous replication, each commit of a
    write transaction will wait until confirmation is
    received that the commit has been written to the transaction log on disk
    of both the primary and standby server. The only possibility that data
    can be lost is if both the primary and the standby suffer crashes at the
    same time. This can provide a much higher level of durability, though only
    if the sysadmin is cautious about the placement and management of the two
    servers.  Waiting for confirmation increases the user's confidence that the
    changes will not be lost in the event of server crashes but it also
    necessarily increases the response time for the requesting transaction.
    The minimum wait time is the roundtrip time between primary to standby.
-->
同期レプリケーションを要求する時、書き込みトランザクションのコミットはそれぞれ、そのコミットがプライマリサーバおよびスタンバイサーバの両方で、ディスク上のトランザクションログに書き込まれたという確認を受けとるまで待機します。
データ損失が起こる可能性は、プライマリサーバとスタンバイサーバが同時にクラッシュしてしまった場合のみです。
これは非常に高い永続性を提供することができますが、それはシステム管理者が２つのサーバの設置と管理に関して注意を払っている場合のみです。
確認のための待機は、サーバがクラッシュした場合でも変更が失われないということでユーザからの信頼性が大きくなりますが、同時に要求するトランザクションの応答時間も必ず大きくなります。
最小待機時間はプライマリとスタンバイの間の往復遅延時間です。
   </para>

   <para>
<!--
    Read only transactions and transaction rollbacks need not wait for
    replies from standby servers. Subtransaction commits do not wait for
    responses from standby servers, only top-level commits. Long
    running actions such as data loading or index building do not wait
    until the very final commit message. All two-phase commit actions
    require commit waits, including both prepare and commit.
-->
読み取り専用のトランザクションおよびトランザクションのロールバックはスタンバイサーバからの応答を待つ必要はありません。
副トランザクションのコミットもスタンバイサーバからの応答を待つことはなく、最上位レベルのコミットのみ待機します。
データロード処理やインデックス構築など長時間実行される操作は、最終コミットメッセージまで待機しません。
準備およびコミットの両方を含め、二相コミット動作はすべてコミット待機を必要とします。
   </para>

   <sect3 id="synchronous-replication-config">
<!--
    <title>Basic Configuration</title>
-->
    <title>基本設定</title>

   <para>
<!--
    Once streaming replication has been configured, configuring synchronous
    replication requires only one additional configuration step:
    <xref linkend="guc-synchronous-standby-names"> must be set to
    a non-empty value.  <varname>synchronous_commit</> must also be set to
    <literal>on</>, but since this is the default value, typically no change is
    required.  (See <xref linkend="runtime-config-wal-settings"> and 
    <xref linkend="runtime-config-replication-master">.)
    This configuration will cause each commit to wait for
    confirmation that the standby has written the commit record to durable
    storage.
    <varname>synchronous_commit</> can be set by individual
    users, so it can be configured in the configuration file, for particular
    users or databases, or dynamically by applications, in order to control
    the durability guarantee on a per-transaction basis.
-->
一度、ストリーミングレプリケーションが設定されている場合、同期レプリケーションの設定には必要な追加設定は１つだけ：<xref linkend="guc-synchronous-standby-names">を空でない値に設定することです。
また<varname>synchronous_commit</>は<literal>on</>に設定されていなければなりませんが、これはデフォルト値ですので、通常は変更する必要はありません。(<xref linkend="runtime-config-wal-settings"> および<xref linkend="runtime-config-replication-master">を参照してください)
この設定によりスタンバイがそのコミットレコードを信頼できるストレージに書き込んだことが確認できるまで、各コミットが待たされるようになります。
<varname>synchronous_replication</>は個々のユーザによって設定することができます。
このため、トランザクション単位を基準とした永続性の保証を制御するために、設定ファイルの中で特定のユーザまたはデータベースについて設定することも、アプリケーションによって動的に設定することもできます。
   </para>

   <para>
<!--
    After a commit record has been written to disk on the primary, the
    WAL record is then sent to the standby. The standby sends reply
    messages each time a new batch of WAL data is written to disk, unless
    <varname>wal_receiver_status_interval</> is set to zero on the standby.
    If the standby is the first matching standby, as specified in
    <varname>synchronous_standby_names</> on the primary, the reply
    messages from that standby will be used to wake users waiting for
    confirmation that the commit record has been received. These parameters
    allow the administrator to specify which standby servers should be
    synchronous standbys. Note that the configuration of synchronous
    replication is mainly on the master. Named standbys must be directly
    connected to the master; the master knows nothing about downstream
    standby servers using cascaded replication.
-->
コミットレコードがプライマリ上のディスクに書き出された後、WALレコードがスタンバイに送信されます。
スタンバイにて<varname>wal_receiver_status_interval</>がゼロに設定されていない限り、スタンバイは新しいWALデータのバッチがディスクに書き出す度にメッセージを返します。
スタンバイが、プライマリ上の<varname>synchronous_standby_names</>で指定したものと最初に一致するスタンバイである場合、そのスタンバイからの応答メッセージがコミットレコードの受領を確認するまでの待機を解除するために使用されます。
これらのパラメータにより管理者はどのスタンバイサーバが同期スタンバイとすべきかを指定することができます。
同期レプリケーションの設定は主にマスタでなされることに注意してください。
指名されたスタンバイは直接マスターサーバに接続される必要があります。つまり、マスターサーバは下流サーバがカスケードレプリケーションで使用されているかについて何も知りません。
   </para>

   <para>
<!--
    Setting <varname>synchronous_commit</> to <literal>remote_write</> will
    cause each commit to wait for confirmation that the standby has received
    the commit record and written it out to its own operating system, but not
    for the data to be flushed to disk on the standby.  This
    setting provides a weaker guarantee of durability than <literal>on</>
    does: the standby could lose the data in the event of an operating system
    crash, though not a <productname>PostgreSQL</> crash.
    However, it's a useful setting in practice
    because it can decrease the response time for the transaction.
    Data loss could only occur if both the primary and the standby crash and
    the database of the primary gets corrupted at the same time.
-->
<varname>synchronous_commit</>を<literal>remote_write</>に設定することで、スタンバイサーバはコミットされたレコードをスタンバイサーバがメモリ上に受け取ったことを確認するまでコミットを待つようになります。しかし、これはスタンバイサーバのディスクへ書きこまれたことを待つわけではありません。
これは、<literal>on</>と設定するより、提供される永続性は弱くなります。具体的には、スタンバイサーバは(<productname>PostgreSQL</> ではなく)オペレーティングシステムがクラッシュした場合にデータを失う可能性があります。
しかし、この設定はトランザクションの応答時間を短くすることができます。データの損失は、プライマリサーバとスタンバイサーバが同時にクラッシュし、かつ、プライマリのデータベースが同時に壊れた場合にのみ発生します。
   </para>

   <para>
<!--
    Users will stop waiting if a fast shutdown is requested.  However, as
    when using asynchronous replication, the server will not fully
    shutdown until all outstanding WAL records are transferred to the currently
    connected standby servers.
-->
高速シャットダウンが要求された場合、ユーザは待機を停止します。
しかし非同期レプリケーションを使用している時、送信中のWALレコードが現在接続しているスタンバイサーバに転送されるまで、サーバは完全に停止しません。
   </para>

   </sect3>

   <sect3 id="synchronous-replication-performance">
<!--
    <title>Planning for Performance</title>
-->
    <title>性能に関する考慮</title>

   <para>
<!--
    Synchronous replication usually requires carefully planned and placed
    standby servers to ensure applications perform acceptably. Waiting
    doesn't utilize system resources, but transaction locks continue to be
    held until the transfer is confirmed. As a result, incautious use of
    synchronous replication will reduce performance for database
    applications because of increased response times and higher contention.
-->
通常、同期レプリケーションは、アプリケーションが満足できる程度に実行されることを確実にするために、注意深くスタンバイサーバを計画し設置しなければなりません。
待機のためにシステムリソースを使用することはありませんが、トランザクションロックは転送が確認されるまで継続して保持されます。
結果として同期レプリケーションを注意せずに使用すると、応答時間が増加する、および競合がより高くなるため、データベースアプリケーションの性能は低下します。
   </para>

   <para>
<!--
    <productname>PostgreSQL</> allows the application developer
    to specify the durability level required via replication. This can be
    specified for the system overall, though it can also be specified for
    specific users or connections, or even individual transactions.
-->
<productname>PostgreSQL</>ではアプリケーション開発者がレプリケーション経由で必要とする永続性レベルを指定することができます。
これをシステム全体に対して指定することができますし、特定のユーザ、接続、個々のトランザクションに対してさえ指定することもできます。
   </para>

   <para>
<!--
    For example, an application workload might consist of:
    10% of changes are important customer details, while
    90% of changes are less important data that the business can more
    easily survive if it is lost, such as chat messages between users.
-->
例えばアプリケーションの作業量が、重要な顧客詳細の変更が10%、ユーザ間のチャットメッセージなど、あまり重要ではなく、失ったとしても業務をより簡単に戻すことができるようなデータの変更が90% という構成を考えてみます。
   </para>

   <para>
<!--
    With synchronous replication options specified at the application level
    (on the primary) we can offer synchronous replication for the most
    important changes, without slowing down the bulk of the total workload.
    Application level options are an important and practical tool for allowing
    the benefits of synchronous replication for high performance applications.
-->
（プライマリ上で）アプリケーションレベルで指定する同期レプリケーションオプションを使用して、作業全体を低速化させることなく、最も重要な変更に対して同期レプリケーションを企てることができます。
アプリケーションレベルのオプションは、高い性能が求められるアプリケーションで同期レプリケーションの利点が得られる、重要かつ現実的な手段です。
   </para>

   <para>
<!--
    You should consider that the network bandwidth must be higher than
    the rate of generation of WAL data.
-->
生成されるWALデータの割合よりネットワーク帯域幅が大きくなければならないことを考慮しなければなりません。
   </para>

   </sect3>

   <sect3 id="synchronous-replication-ha">
<!--
    <title>Planning for High Availability</title>
-->
    <title>高可用性に関する検討</title>

   <para>
<!--
    Commits made when <varname>synchronous_commit</> is set to <literal>on</>
    or <literal>remote_write</> will wait until the synchronous standby responds. The response
    may never occur if the last, or only, standby should crash.
-->
<varname>synchronous_commit</>が<literal>on</>もしくは<literal>remote_write</>に設定された場合、なされたコミットは同期スタンバイの応答まで待機されます。
応答は最後のまたは唯一のスタンバイがクラッシュした場合には決して返されません。
   </para>

   <para>
<!--
    The best solution for avoiding data loss is to ensure you don't lose
    your last remaining synchronous standby. This can be achieved by naming multiple
    potential synchronous standbys using <varname>synchronous_standby_names</>.
    The first named standby will be used as the synchronous standby. Standbys
    listed after this will take over the role of synchronous standby if the
    first one should fail.
-->
データ損失を防止するための最善の解法は、最後に残る同期スタンバイを失わないことを確実にすることです。
<varname>synchronous_standby_names</>を使用して複数の潜在的な同期スタンバイを指名することで実現することができます。
最初に指名されたスタンバイは同期スタンバイとして使用されます。
この後に列挙されたスタンバイは、最初のスタンバイが失敗した場合に同期スタンバイの役割を引き継ぎます。
   </para>

   <para>
<!--
    When a standby first attaches to the primary, it will not yet be properly
    synchronized. This is described as <literal>catchup</> mode. Once
    the lag between standby and primary reaches zero for the first time
    we move to real-time <literal>streaming</> state.
    The catch-up duration may be long immediately after the standby has
    been created. If the standby is shut down, then the catch-up period
    will increase according to the length of time the standby has been down.
    The standby is only able to become a synchronous standby
    once it has reached <literal>streaming</> state.
-->
スタンバイが最初にプライマリに付与された時、それはまだ適切に同期されていません。
これは<literal>catchup</>モードと呼ばれます。
最初にスタンバイとプライマリ間の遅延がゼロになった時に、実時間<literal>streaming</>状態に移ります。
追従（catchup）期間はスタンバイが作成された直後は長くなるかもしれません。
スタンバイが停止している場合、追従期間はスタンバイの停止期間にしたがって長くなります。
スタンバイは、<literal>streaming</>状態に達した後でのみ、同期スタンバイになることができます。
   </para>

   <para>
<!--
    If primary restarts while commits are waiting for acknowledgement, those
    waiting transactions will be marked fully committed once the primary
    database recovers.
    There is no way to be certain that all standbys have received all
    outstanding WAL data at time of the crash of the primary. Some
    transactions may not show as committed on the standby, even though
    they show as committed on the primary. The guarantee we offer is that
    the application will not receive explicit acknowledgement of the
    successful commit of a transaction until the WAL data is known to be
    safely received by the standby.
-->
コミットが受領通知を待機している間にプライマリが再起動した場合、プライマリデータベースが復旧した後、待機中のトランザクションは完全にコミットされたものと記録されます。
すべてのスタンバイがプライマリのクラッシュ時点で送信中のWALデータのすべてを受信したかどうかを確認する方法はありません。
トランザクションの一部は、プライマリではコミットされたものと表示されていたとしても、スタンバイではコミットされていないと表示されるかもしれません。
PostgreSQLは、WALデータをスタンバイが安全に受信したことが分かるまで、アプリケーションは明示的なトランザクションコミットの成功に関する受領通知を受けとらないことを保証しています。
   </para>

   <para>
<!--
    If you really do lose your last standby server then you should disable
    <varname>synchronous_standby_names</> and reload the configuration file
    on the primary server.
-->
最終スタンバイサーバを本当に失った場合、<varname>synchronous_standby_names</>を無効にし、プライマリサーバの設定ファイルを再読み込みしなければなりません。
   </para>

   <para>
<!--
    If the primary is isolated from remaining standby servers you should
    fail over to the best candidate of those other remaining standby servers.
-->
プライマリが既存のスタンバイサーバから切り離された場合は、スタンバイサーバの中から最善と思われる候補にフェールオーバしてください。
   </para>

   <para>
<!--
    If you need to re-create a standby server while transactions are
    waiting, make sure that the commands pg_start_backup() and
    pg_stop_backup() are run in a session with
    <varname>synchronous_commit</> = <literal>off</>, otherwise those
    requests will wait forever for the standby to appear.
-->
トランザクションの待機中にスタンバイサーバを再作成する必要がある場合、pg_start_backup()およびpg_stop_backup()を実行するコマンドを<varname>synchronous_commit</> = <literal>off</>であるセッション内で確実に実行してください。
さもないとこれらの要求はスタンバイに現れるまで永遠に待機します。
   </para>

   </sect3>
  </sect2>
  </sect1>

  <sect1 id="warm-standby-failover">
<!--
   <title>Failover</title>
-->
   <title>フェールオーバ</title>

   <para>
<!--
    If the primary server fails then the standby server should begin
    failover procedures.
-->
プライマリサーバに障害が起こると、スタンバイサーバはフェールオーバ処理を始めなければなりません。
   </para>

   <para>
<!--
    If the standby server fails then no failover need take place. If the
    standby server can be restarted, even some time later, then the recovery
    process can also be restarted immediately, taking advantage of
    restartable recovery. If the standby server cannot be restarted, then a
    full new standby server instance should be created.
-->
スタンバイサーバが故障した場合、フェールオーバは不要です。
多少の時間の後に、スタンバイサーバを再起動できれば、再起動可能なリカバリのため、リカバリ処理も即座に再起動することができます。
スタンバイサーバを再起動できなければ、新しい完全なスタンバイサーバのインスタンスを作成しなければなりません。
   </para>

   <para>
<!--
    If the primary server fails and the standby server becomes the
    new primary, and then the old primary restarts, you must have
    a mechanism for informing the old primary that it is no longer the primary. This is
    sometimes known as <acronym>STONITH</> (Shoot The Other Node In The Head), which is
    necessary to avoid situations where both systems think they are the
    primary, which will lead to confusion and ultimately data loss.
-->
プライマリサーバに障害が起こりスタンバイサーバが新しいプライマリとなり、その後古いプライマリが再起動した場合、もはやプライマリサーバでなくなっていることを古いプライマリに知らせる機構が必要です。
これはSTONITH (Shoot the Other Node In The Head)と一部ではいわれています。
これは、混乱と最悪はデータ損失をもたらしかねない、両方のシステムが自身をプライマリとして認識してしまう状況を防ぐために必要です。
   </para>

   <para>
<!--
    Many failover systems use just two systems, the primary and the standby,
    connected by some kind of heartbeat mechanism to continually verify the
    connectivity between the two and the viability of the primary. It is
    also possible to use a third system (called a witness server) to prevent
    some cases of inappropriate failover, but the additional complexity
    might not be worthwhile unless it is set up with sufficient care and
    rigorous testing.
-->
多くのフェールオーバーシステムではプライマリとスタンバイといった２つのシステムを使用します。
なんらかのハートビート機構でプライマリとスタンバイを接続し、両者の接続性とプライマリの実行能力を継続的に確認します。
また、第３のシステム（証言サーバと呼ばれます）を使用して、不適切なフェールオーバなどの状況を防ぐこともできます。
しかし、さらに複雑になりますので、十分な注意と厳密な検証の元に設定を行わない限り行う意味がありません。
   </para>

   <para>
<!--
    <productname>PostgreSQL</productname> does not provide the system
    software required to identify a failure on the primary and notify
    the standby database server.  Many such tools exist and are well
    integrated with the operating system facilities required for
    successful failover, such as IP address migration.
-->
<productname>PostgreSQL</productname>は、プライマリサーバの障害を識別し、スタンバイデータベースサーバに通知するために必要なシステムソフトウェアを提供しません。
こうしたツールは多く存在し、IPアドレスの移行といったフェールオーバを成功させるために必要な機能をオペレーティングシステムにうまく統合させています。
   </para>

   <para>
<!--
    Once failover to the standby occurs, there is only a
    single server in operation. This is known as a degenerate state.
    The former standby is now the primary, but the former primary is down
    and might stay down.  To return to normal operation, a standby server
    must be recreated,
    either on the former primary system when it comes up, or on a third,
    possibly new, system. Once complete, the primary and standby can be
    considered to have switched roles. Some people choose to use a third
    server to provide backup for the new primary until the new standby
    server is recreated,
    though clearly this complicates the system configuration and
    operational processes.
-->
スタンバイサーバへのフェールオーバが起きた後、運用可能なサーバは1つしかありません。
これは縮退状態と呼ばれます。
以前のスタンバイサーバはプライマリサーバになり、以前のプライマリは停止し、その後も停止し続けるかもしれません。
通常の運用に戻すには、スタンバイサーバを再作成しなければなりません。
以前のプライマリサーバが起動できれば、これを使用しても構いませんし、第三のおそらく新規のシステムを使用しても構いません。
完了すれば、プライマリとスタンバイの役割が切り替わったとみなすことができます。
新しいスタンバイサーバを再作成するまでに第三のサーバを使用して新しいプライマリのバックアップを提供することを選択する人もいますが、これがシステム構成と運用手順を複雑にすることは明らかです。
   </para>

   <para>
<!--
    So, switching from primary to standby server can be fast but requires
    some time to re-prepare the failover cluster. Regular switching from
    primary to standby is useful, since it allows regular downtime on
    each system for maintenance. This also serves as a test of the
    failover mechanism to ensure that it will really work when you need it.
    Written administration procedures are advised.
-->
プライマリサーバからスタンバイサーバへの切り替えは高速ですが、フェールオーバクラスタを再度準備するのに多少時間が必要です。
それぞれのシステムを保守のために定期的に停止することができるので、プライマリからスタンバイへの定期的切り替えは有益です。
これは同時に、必要になった時、フェールオーバ機構が実際に機能するかどうかを確認する試験としても役立ちます。
管理手順の文書化を勧めます。
   </para>

   <para>
<!--
    To trigger failover of a log-shipping standby server,
    run <command>pg_ctl promote</> or create a trigger
    file with the file name and path specified by the <varname>trigger_file</>
    setting in <filename>recovery.conf</>. If you're planning to use
    <command>pg_ctl promote</> to fail over, <varname>trigger_file</> is
    not required. If you're setting up the reporting servers that are
    only used to offload read-only queries from the primary, not for high
    availability purposes, you don't need to promote it.
-->
ログシッピングを行うスタンバイサーバのフェールオーバを発生させるためには、<command>pg_ctl promote</>を実行する、あるいは、<filename>recovery.conf</>内の<varname>trigger_file</>設定によって指定されるファイル名とパスを持つトリガファイルを作成してください。
フェールオーバのために<command>pg_ctl promote</>を使用するつもりならば、<varname>trigger_file</>は必要ありません。
プライマリから読み取り専用の問い合わせによる負荷を軽減させるためだけに使用し、高可用性を目的としていない、報告処理用サーバを構築する場合は、昇格させる必要はありません。
   </para>
  </sect1>

  <sect1 id="log-shipping-alternative">
<!--
   <title>Alternative Method for Log Shipping</title>
-->
   <title>この他のログシッピングの方法</title>

   <para>
<!--
    An alternative to the built-in standby mode described in the previous
    sections is to use a <varname>restore_command</> that polls the archive location.
    This was the only option available in versions 8.4 and below. In this
    setup, set <varname>standby_mode</> off, because you are implementing
    the polling required for standby operation yourself. See the
    <xref linkend="pgstandby"> module for a reference
    implementation of this.
-->
これまでの節で説明した組込みのスタンバイモードの他の方法として、アーカイブ場所を順次問い合わせる<varname>restore_command</>を使用する方法があります。
これはバージョン8.4以前では唯一の利用可能な選択肢でした。
この設定では、スタンバイ操作で必要とするポーリングを自身で実施しますので、<varname>standby_mode</>を無効にします。
このリファレンス実装として<xref linkend="pgstandby">を参照してください。
   </para>

   <para>
<!--
    Note that in this mode, the server will apply WAL one file at a
    time, so if you use the standby server for queries (see Hot Standby),
    there is a delay between an action in the master and when the
    action becomes visible in the standby, corresponding the time it takes
    to fill up the WAL file. <varname>archive_timeout</> can be used to make that delay
    shorter. Also note that you can't combine streaming replication with
    this method.
-->
このモードでは、サーバは1度に1つのWALファイルを適用することに注意してください。
このため問い合わせ用にスタンバイサーバを使用する場合(ホットスタンバイを参照)、マスタにおける動作とそれがスタンバイで可視になるまでの間に、WALファイルをみたすために必要とする時間に相当する、遅延が存在します。
<varname>archive_timeout</>を使用して遅延を短くすることができます。
また、この方法とストリーミングレプリケーションと組み合わせることができないことにも注意してください。
   </para>

   <para>
<!--
    The operations that occur on both primary and standby servers are
    normal continuous archiving and recovery tasks. The only point of
    contact between the two database servers is the archive of WAL files
    that both share: primary writing to the archive, standby reading from
    the archive. Care must be taken to ensure that WAL archives from separate
    primary servers do not become mixed together or confused. The archive
    need not be large if it is only required for standby operation.
-->
プライマリおよびスタンバイサーバの両方で発生する操作は通常の継続的なアーカイブ処理とリカバリ処理です。
2つのデータベースサーバが連携する唯一の点は、両者が共有するWALファイルのアーカイブです。
プライマリがアーカイブに書き出し、スタンバイがアーカイブから読み取ります。
注意して他のプライマリサーバ由来のWALアーカイブが混在しないことを確実にしなければなりません。
さもないと混乱が発生します。
スタンバイ操作でのみ必要なものですので、アーカイブは必ずしも巨大になりません。
   </para>

   <para>
<!--
    The magic that makes the two loosely coupled servers work together is
    simply a <varname>restore_command</> used on the standby that,
    when asked for the next WAL file, waits for it to become available from
    the primary. The <varname>restore_command</> is specified in the
    <filename>recovery.conf</> file on the standby server. Normal recovery
    processing would request a file from the WAL archive, reporting failure
    if the file was unavailable.  For standby processing it is normal for
    the next WAL file to be unavailable, so the standby must wait for
    it to appear. For files ending in <literal>.backup</> or
    <literal>.history</> there is no need to wait, and a non-zero return
    code must be returned. A waiting <varname>restore_command</> can be
    written as a custom script that loops after polling for the existence of
    the next WAL file. There must also be some way to trigger failover, which
    should interrupt the <varname>restore_command</>, break the loop and
    return a file-not-found error to the standby server. This ends recovery
    and the standby will then come up as a normal server.
-->
2つの疎結合サーバを協調させる秘訣は簡単で、スタンバイサーバにて使用される<varname>restore_command</>です。
これは次のWALファイルを問い合わせ、それをプライマリから利用可能になるまで待機します。
この<varname>restore_command</>はスタンバイサーバの<filename>recovery.conf</>ファイルで指定されます。
通常のリカバリ処理はWALアーカイブからファイルを要求し、ファイルが利用できなければ失敗を報告します。
スタンバイ処理では、次のWALファイルを入手できないことは異常ではありませんので、スタンバイは利用可能になるまで待機しなければなりません。
<literal>.backup</>または<literal>.history</>で終わるファイルについては、待機する必要はなく、非ゼロの終了コードを返さなければなりません。
<varname>restore_command</>を待機させるには、次のWALファイルの存在を確認した後にループする独自のスクリプトを作成することで実現できます。
また、<varname>restore_command</>に割り込み、ループを終了させ、ファイルが存在しないというエラーをスタンバイサーバに返す、フェールオーバを発生させる何らかの方法がなければなりません。
これがリカバリ処理を停止しますので、スタンバイサーバは通常のサーバになります。
   </para>

   <para>
<!--
    Pseudocode for a suitable <varname>restore_command</> is:
-->
<varname>restore_command</>の擬似コードの一例は以下です。
<programlisting>
triggered = false;
while (!NextWALFileReady() &amp;&amp; !triggered)
{
    sleep(100000L);         /* wait for ~0.1 sec */
    if (CheckForExternalTrigger())
        triggered = true;
}
if (!triggered)
        CopyWALFileForRecovery();
</programlisting>
   </para>

   <para>
<!--
    A working example of a waiting <varname>restore_command</> is provided
    in the <xref linkend="pgstandby"> module. It
    should be used as a reference on how to correctly implement the logic
    described above. It can also be extended as needed to support specific
    configurations and environments.
-->
待機を行う<varname>restore_command</>の実例は<xref linkend="pgstandby">モジュール内で提供されています。
これは上記のロジックをどのように正確に実装するかについての参照として使用すべきです。
また、これを特定の設定または環境をサポートするため必要に応じて拡張することができます。
   </para>

   <para>
<!--
    The method for triggering failover is an important part of planning
    and design. One potential option is the <varname>restore_command</>
    command.  It is executed once for each WAL file, but the process
    running the <varname>restore_command</> is created and dies for
    each file, so there is no daemon or server process, and
    signals or a signal handler cannot be used. Therefore, the
    <varname>restore_command</> is not suitable to trigger failover.
    It is possible to use a simple timeout facility, especially if
    used in conjunction with a known <varname>archive_timeout</>
    setting on the primary. However, this is somewhat error prone
    since a network problem or busy primary server might be sufficient
    to initiate failover. A notification mechanism such as the explicit
    creation of a trigger file is ideal, if this can be arranged.
-->
フェールオーバを通知する手段は計画・設計段階で重要な部分です。
考えられる選択肢の1つは<varname>restore_command</>です。
これは各WALファイルに対して1度実行されるものですが、<varname>restore_command</>を実行するプロセスは各ファイルに対して起動・終了します。
このようにデーモンやサーバプロセスはありませんので、シグナルやシグナルハンドラを使用することはできません。
したがって、<varname>restore_command</>はフェールオーバの通知には適していません。
特にプライマリサーバ上の既知の<varname>archive_timeout</>設定と連係して使用できるならば、単純なタイムアウト機能を使用することができます。
しかし、これはネットワーク障害や高負荷なプライマリサーバによりフェールオーバが始まってしまうため、どちらかというとエラーになりやすいものです。
実現可能ならば、明示的な通知用ファイルの作成などの通知機構の方が理想的です。
   </para>

  <sect2 id="warm-standby-config">
<!--
   <title>Implementation</title>
-->
   <title>実装</title>

   <para>
<!--
    The short procedure for configuring a standby server using this alternative
    method is as follows. For
    full details of each step, refer to previous sections as noted.
-->
この代替方式を使用してスタンバイサーバを構築する短めの手順を以下に示します。
各段階の詳細については、注記していますので、前の節を参照してください。
    <orderedlist>
     <listitem>
      <para>
<!--
       Set up primary and standby systems as nearly identical as
       possible, including two identical copies of
       <productname>PostgreSQL</> at the same release level.
-->
できる限り同じようにプライマリシステムとスタンバイシステムを設定してください。
同じリリースレベルの<productname>PostgreSQL</>の同一コピーの導入も含みます。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Set up continuous archiving from the primary to a WAL archive
       directory on the standby server. Ensure that
       <xref linkend="guc-archive-mode">,
       <xref linkend="guc-archive-command"> and
       <xref linkend="guc-archive-timeout">
       are set appropriately on the primary
       (see <xref linkend="backup-archiving-wal">).
-->
プライマリサーバで、継続的アーカイブをスタンバイサーバ上のディレクトリ上にWALをアーカイブするように設定してください。
プライマリサーバで、<xref linkend="guc-archive-mode">、<xref linkend="guc-archive-command">および<xref linkend="guc-archive-timeout">が適切に設定されていることを確認してください（<xref linkend="backup-archiving-wal">を参照してください）。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Make a base backup of the primary server (see <xref
       linkend="backup-base-backup">), and load this data onto the standby.
-->
プライマリサーバでベースバックアップを作成（<xref linkend="backup-base-backup">を参照してください）し、スタンバイサーバでこのデータをロードしてください。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Begin recovery on the standby server from the local WAL
       archive, using a <filename>recovery.conf</> that specifies a
       <varname>restore_command</> that waits as described
       previously (see <xref linkend="backup-pitr-recovery">).
-->
スタンバイサーバで、上記の通り待機を行う<varname>restore_command</>を指定した<filename>recovery.conf</>を使用して、ローカルなWALアーカイブからリカバリ処理を実行してください（<xref linkend="backup-pitr-recovery">を参照してください）。
      </para>
     </listitem>
    </orderedlist>
   </para>

   <para>
<!--
    Recovery treats the WAL archive as read-only, so once a WAL file has
    been copied to the standby system it can be copied to tape at the same
    time as it is being read by the standby database server.
    Thus, running a standby server for high availability can be performed at
    the same time as files are stored for longer term disaster recovery
    purposes.
-->
リカバリ処理はWALアーカイブを読み取り専用として扱います。
このため、WALファイルがスタンバイシステムにコピーされた後、スタンバイデータベースサーバによる読み取りと同時にWALファイルをテープにコピーすることができます。
このように、高可用性スタンバイサーバの実行を、災害からのリカバリを目的とした長期的な保管と同時に行うことができます。
   </para>

   <para>
<!--
    For testing purposes, it is possible to run both primary and standby
    servers on the same system. This does not provide any worthwhile
    improvement in server robustness, nor would it be described as HA.
-->
試験のためにプライマリサーバとスタンバイサーバを同じシステムで稼動させることができます。
これによりサーバ堅牢性が向上することも、高可用性と呼べることもありません。
   </para>
  </sect2>

  <sect2 id="warm-standby-record">
<!--
   <title>Record-based Log Shipping</title>
-->
   <title>レコードベースのログシッピング</title>

   <para>
<!--
    It is also possible to implement record-based log shipping using this
    alternative method, though this requires custom development, and changes
    will still only become visible to hot standby queries after a full WAL
    file has been shipped.
-->
この代替手法を用いたレコード単位のログシッピングの実装も可能ですが、利用者側の開発が必要です。
さらに、完全なWALファイルが転送された後のみで、変更がホットスタンバイ問い合わせで可視になります。
   </para>

   <para>
<!--
    An external program can call the <function>pg_xlogfile_name_offset()</>
    function (see <xref linkend="functions-admin">)
    to find out the file name and the exact byte offset within it of
    the current end of WAL.  It can then access the WAL file directly
    and copy the data from the last known end of WAL through the current end
    over to the standby servers.  With this approach, the window for data
    loss is the polling cycle time of the copying program, which can be very
    small, and there is no wasted bandwidth from forcing partially-used
    segment files to be archived.  Note that the standby servers'
    <varname>restore_command</> scripts can only deal with whole WAL files,
    so the incrementally copied data is not ordinarily made available to
    the standby servers.  It is of use only when the primary dies &mdash;
    then the last partial WAL file is fed to the standby before allowing
    it to come up.  The correct implementation of this process requires
    cooperation of the <varname>restore_command</> script with the data
    copying program.
-->
外部プログラムから、WALの現在の終了点のファイル名と正確なバイトオフセットを見つけ出す<function>pg_xlogfile_name_offset()</>関数（<xref linkend="functions-admin">を参照）を呼び出すことができます。
そして、WALファイルに直接アクセスし、直前の既知のWAL終了点から現在の終了点までのデータをスタンバイサーバにコピーすることができます。
この方法では、データ損失期間はコピー処理プログラムの実行周期となります。
非常に短くすることができますし、部分的に使用されたセグメントファイルを強制的にアーカイブするため無駄な帯域もありません。
スタンバイサーバの<varname>restore_command</>スクリプトがWALファイル全体しか扱うことができないことに注意してください。
このため、逐次的にコピーしたデータは通常はスタンバイサーバで利用することができません。
プライマリサーバが停止した時のみこれを使用します。
その場合、プライマリサーバが立ち上がる前に、最後の部分的なWALファイルがセカンダリサーバに渡されます。
この処理の正しい実装では、データコピープログラムと<varname>restore_command</>スクリプトとの連係が必要です。
   </para>

   <para>
<!--
    Starting with <productname>PostgreSQL</> version 9.0, you can use
    streaming replication (see <xref linkend="streaming-replication">) to
    achieve the same benefits with less effort.
-->
<productname>PostgreSQL</>バージョン9.0から、同じ利点をより少ない設定で実現できるストリーミングレプリケーション(<xref linkend="streaming-replication">参照)を使用することができます。
   </para>
  </sect2>
 </sect1>

 <sect1 id="hot-standby">
<!--
  <title>Hot Standby</title>
-->
  <title>ホットスタンバイ</title>

  <indexterm zone="high-availability">
<!--
   <primary>Hot Standby</primary>
-->
   <primary>ホットスタンバイ</primary>
  </indexterm>

   <para>
<!--
    Hot Standby is the term used to describe the ability to connect to
    the server and run read-only queries while the server is in archive
    recovery or standby mode. This
    is useful both for replication purposes and for restoring a backup
    to a desired state with great precision.
    The term Hot Standby also refers to the ability of the server to move
    from recovery through to normal operation while users continue running
    queries and/or keep their connections open.
-->
ホットスタンバイという単語は、サーバがアーカイブリカバリを実行している最中にサーバに接続し読み取り専用の問い合わせを実行することができる機能を説明するために使われます。
これは、レプリケーションという目的およびバックアップからのリストアの両方で高い精度で好ましい状態にするために有用です。
ホットスタンバイという単語はまた、ユーザが問い合わせを実行しながら、または、開いている接続を維持しながら、またはその両方で、サーバをリカバリ状態から通常の動作に移すことができる機能も示すものです。
   </para>

   <para>
<!--
    Running queries in hot standby mode is similar to normal query operation,
    though there are several usage and administrative differences
    explained below.
-->
ホットスタンバイモードにおける問い合わせは、通常の問い合わせに類似していますが、利用上および管理上の差異が多少あり、以下に説明します。
   </para>

  <sect2 id="hot-standby-users">
<!--
   <title>User's Overview</title>
-->
   <title>ユーザのための概説</title>

   <para>
<!--
    When the <xref linkend="guc-hot-standby"> parameter is set to true on a
    standby server, it will begin accepting connections once the recovery has
    brought the system to a consistent state.  All such connections are
    strictly read-only; not even temporary tables may be written.
-->
スタンバイサーバで<xref linkend="guc-hot-standby">パラメータが真に設定されている場合、リカバリによりシステムが一貫性を持つようになった後接続を受け付け始めます。
こうした接続はすべて読み取り専用に限定されます。
一時テーブルであっても書き込むことはできません。
   </para>

   <para>
<!--
    The data on the standby takes some time to arrive from the primary server
    so there will be a measurable delay between primary and standby. Running the
    same query nearly simultaneously on both primary and standby might therefore
    return differing results. We say that data on the standby is
    <firstterm>eventually consistent</firstterm> with the primary.  Once the
    commit record for a transaction is replayed on the standby, the changes
    made by that transaction will be visible to any new snapshots taken on
    the standby.  Snapshots may be taken at the start of each query or at the
    start of each transaction, depending on the current transaction isolation
    level.  For more details, see <xref linkend="transaction-iso">.
-->
スタンバイ上のデータはプライマリサーバから届くまでに多少の時間がかかります。
このため、プライマリとスタンバイの間にはある程度の遅延があります。
したがって、同じ問い合わせをほとんど同時にプライマリとスタンバイに対して実行すると、異なる結果が返る可能性があります。
スタンバイ上のデータはプライマリに対して<firstterm>最後には一貫性を持つ</firstterm>といいます。
あるトランザクションのコミットレコードがスタンバイ上で再生されると、そのトランザクションでなされた変更はスタンバイで獲得されるすべての新規スナップショットで可視になります。
現在のトランザクション隔離レベルに応じて、スナップショットは各問い合わせの開始時または各トランザクションの開始時に獲得されます。
詳細については<xref linkend="transaction-iso">を参照してください。
   </para>

   <para>
<!--
    Transactions started during hot standby may issue the following commands:
-->
ホットスタンバイ中に開始されたトランザクションは以下のコマンドを発行することができます。

    <itemizedlist>
     <listitem>
      <para>
<!--
       Query access - <command>SELECT</>, <command>COPY TO</>
-->
問い合わせによるアクセス - <command>SELECT</>および<command>COPY TO</>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Cursor commands - <command>DECLARE</>, <command>FETCH</>, <command>CLOSE</>
-->
カーソルコマンド - <command>DECLARE</>と<command>FETCH</>と<command>CLOSE</>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Parameters - <command>SHOW</>, <command>SET</>, <command>RESET</>
-->
パラメータの操作 - <command>SHOW</>と<command>SET</>と<command>RESET</>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Transaction management commands
-->
トランザクション管理コマンド
        <itemizedlist>
         <listitem>
          <para>
<!--
           <command>BEGIN</>, <command>END</>, <command>ABORT</>, <command>START TRANSACTION</>
-->
<command>BEGIN</>と<command>END</>と<command>ABORT</>と<command>START TRANSACTION</>
          </para>
         </listitem>
         <listitem>
          <para>
<!--
           <command>SAVEPOINT</>, <command>RELEASE</>, <command>ROLLBACK TO SAVEPOINT</>
-->
<command>SAVEPOINT</>と<command>RELEASE</>と<command>ROLLBACK TO SAVEPOINT</>
          </para>
         </listitem>
         <listitem>
          <para>
<!--
           <command>EXCEPTION</> blocks and other internal subtransactions
-->
<command>EXCEPTION</>ブロックおよびこの他の内部サブトランザクション
          </para>
         </listitem>
        </itemizedlist>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       <command>LOCK TABLE</>, though only when explicitly in one of these modes:
       <literal>ACCESS SHARE</>, <literal>ROW SHARE</> or <literal>ROW EXCLUSIVE</>.
-->
<command>LOCK TABLE</>。
なお、以下のモードが明示された場合に限ります。
<literal>ACCESS SHARE</>または<literal>ROW SHARE</>または<literal>ROW EXCLUSIVE</>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Plans and resources - <command>PREPARE</>, <command>EXECUTE</>,
       <command>DEALLOCATE</>, <command>DISCARD</>
-->
計画と資源 - <command>PREPARE</>と<command>EXECUTE</>と<command>DEALLOCATE</>と<command>DISCARD</>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Plugins and extensions - <command>LOAD</>
-->
プラグインと拡張 - <command>LOAD</>
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
<!--
    Transactions started during hot standby will never be assigned a
    transaction ID and cannot write to the system write-ahead log.
    Therefore, the following actions will produce error messages:
-->
ホットスタンバイ中に開始したトランザクションではトランザクションIDを割り当てられません。
また、システムのログ先行書き込みに書き出すことができません。
このため、以下の動作はエラーメッセージを生成します。

    <itemizedlist>
     <listitem>
      <para>
<!--
       Data Manipulation Language (DML) - <command>INSERT</>,
       <command>UPDATE</>, <command>DELETE</>, <command>COPY FROM</>,
       <command>TRUNCATE</>.
       Note that there are no allowed actions that result in a trigger
       being executed during recovery.  This restriction applies even to
       temporary tables, because table rows cannot be read or written without
       assigning a transaction ID, which is currently not possible in a
       Hot Standby environment.
-->
データ操作言語（DML）。
<command>INSERT</>、<command>UPDATE</>、<command>DELETE</>、<command>COPY FROM</>および<command>TRUNCATE</>。
リカバリ中にトリガ内で実行されてしまう場合でも許されていない動作であることに注意してください。
現在のホットスタンバイ環境では行うことができないトランザクションIDの割り当てを行うことなく、テーブル行の読み書きを行うことができませんので、この制限は一時テーブルであっても適用されます。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Data Definition Language (DDL) - <command>CREATE</>,
       <command>DROP</>, <command>ALTER</>, <command>COMMENT</>.
       This restriction applies even to temporary tables, because carrying
       out these operations would require updating the system catalog tables.
-->
データ定義言語（DDL）。
<command>CREATE</>、<command>DROP</>、<command>ALTER</>および<command>COMMENT</>。
この制約は一時テーブルに対しても適用されます。
これらの操作の実行がシステムカタログテーブルの更新を必要とするためです。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       <command>SELECT ... FOR SHARE | UPDATE</>, because row locks cannot be
       taken without updating the underlying data files.
-->
<command>SELECT ... FOR SHARE | UPDATE</>。
背後のデータファイルを更新することなく行ロックを獲得することはできないためです。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Rules on <command>SELECT</> statements that generate DML commands.
-->
データ操作言語のコマンドを生成する<command>SELECT</>文のルール
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       <command>LOCK</> that explicitly requests a mode higher than <literal>ROW EXCLUSIVE MODE</>.
-->
<literal>ROW EXCLUSIVE MODE</>より高いモードを明示的に要求する<command>LOCK</>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       <command>LOCK</> in short default form, since it requests <literal>ACCESS EXCLUSIVE MODE</>.
-->
短いデフォルト構文の<command>LOCK</>。
これは<literal>ACCESS EXCLUSIVE MODE</>を要求するためです。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Transaction management commands that explicitly set non-read-only state:
-->
読み取り専用でない状態を明示的に設定するトランザクション処理コマンド
        <itemizedlist>
         <listitem>
          <para>
<!--
            <command>BEGIN READ WRITE</>,
            <command>START TRANSACTION READ WRITE</>
-->
<command>BEGIN READ WRITE</>と<command>START TRANSACTION READ WRITE</>
          </para>
         </listitem>
         <listitem>
          <para>
<!--
            <command>SET TRANSACTION READ WRITE</>,
            <command>SET SESSION CHARACTERISTICS AS TRANSACTION READ WRITE</>
-->
<command>SET TRANSACTION READ WRITE</>と<command>SET SESSION CHARACTERISTICS AS TRANSACTION READ WRITE</>
          </para>
         </listitem>
         <listitem>
          <para>
<!--
           <command>SET transaction_read_only = off</>
-->
<command>SET transaction_read_only = off</>
          </para>
         </listitem>
        </itemizedlist>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Two-phase commit commands - <command>PREPARE TRANSACTION</>,
       <command>COMMIT PREPARED</>, <command>ROLLBACK PREPARED</>
       because even read-only transactions need to write WAL in the
       prepare phase (the first phase of two phase commit).
-->
二相コミットコマンド - <command>PREPARE TRANSACTION</>、<command>COMMIT PREPARED</>および<command>ROLLBACK PREPARED</>。
読み取り専用トランザクションでも、プリペア相（二相コミットの第1相）においてWALの書き込みが必要だからです。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Sequence updates - <function>nextval()</>, <function>setval()</>
-->
シーケンス更新の関数 - <function>nextval()</>と<function>setval()</>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       <command>LISTEN</>, <command>UNLISTEN</>, <command>NOTIFY</>
-->
<command>LISTEN</>、<command>UNLISTEN</>および<command>NOTIFY</>
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
<!--
    In normal operation, <quote>read-only</> transactions are allowed to
    update sequences and to use <command>LISTEN</>, <command>UNLISTEN</>, and
    <command>NOTIFY</>, so Hot Standby sessions operate under slightly tighter
    restrictions than ordinary read-only sessions.  It is possible that some
    of these restrictions might be loosened in a future release.
-->
通常の操作では、<quote>読み取り専用</>トランザクションにはシーケンスの更新および<command>LISTEN</>と<command>UNLISTEN</>と<command>NOTIFY</>の使用が許可されています。
ホットスタンバイセッションの操作では、通常の読み取り専用セッションよりも少し厳しい制約を受けます。
将来のリリースではこの制約の一部が緩和されるかもしれません。
   </para>

   <para>
<!--
    During hot standby, the parameter <varname>transaction_read_only</> is always
    true and may not be changed.  But as long as no attempt is made to modify
    the database, connections during hot standby will act much like any other
    database connection.  If failover or switchover occurs, the database will
    switch to normal processing mode.  Sessions will remain connected while the
    server changes mode.  Once hot standby finishes, it will be possible to
    initiate read-write transactions (even from a session begun during
    hot standby).
-->
ホットスタンバイ中は、<varname>transaction_read_only</>パラメータは常に真であり、変更することはできません。
しかし、データベースを変更するような試行がない限り、ホットスタンバイ中の接続は他のデータベース接続とほとんど同じように動作します。
もし、フェールオーバまたはスイッチオーバが発生すると、データベースは通常処理モードに切り替わります。
サーバのモードが変わってもセッションは接続を保持します。
ホットスタンバイが完了すると、読み書き可能なトランザクションを（ホットスタンバイ中に始まったセッションからであっても）始められるようになります。
   </para>

   <para>
<!--
    Users will be able to tell whether their session is read-only by
    issuing <command>SHOW transaction_read_only</>.  In addition, a set of
    functions (<xref linkend="functions-recovery-info-table">) allow users to
    access information about the standby server. These allow you to write
    programs that are aware of the current state of the database. These
    can be used to monitor the progress of recovery, or to allow you to
    write complex programs that restore the database to particular states.
-->
ユーザは<command>SHOW transaction_read_only</>を発行することで、そのセッションが読み取り専用かどうかを調べることができます。
さらに、ユーザがスタンバイサーバに関する情報にアクセスできる関数群(<xref linkend="functions-recovery-info-table">)があります。
これらによりデータベースの現状認識を行うプログラムを作成することができます。
これらを使用して、リカバリの進行状況を監視するために使用したり、データベースを特定の状態にリストアする複雑なプログラムを作成したりすることができます。
   </para>
  </sect2>

  <sect2 id="hot-standby-conflict">
<!--
   <title>Handling Query Conflicts</title>
-->
   <title>問い合わせコンフリクトの処理</title>

   <para>
<!--
    The primary and standby servers are in many ways loosely connected. Actions
    on the primary will have an effect on the standby. As a result, there is
    potential for negative interactions or conflicts between them. The easiest
    conflict to understand is performance: if a huge data load is taking place
    on the primary then this will generate a similar stream of WAL records on the
    standby, so standby queries may contend for system resources, such as I/O.
-->
プライマリサーバとスタンバイサーバは、多方面でゆるく結合しています。
プライマリサーバの動作はスタンバイサーバに影響します。
その結果、負の相互作用またはコンフリクトの可能性があります。
最も分かりやすいコンフリクトは性能です。
プライマリサーバで巨大なデータがロードされた場合、スタンバイサーバにおいて同様に巨大なWALレコードが生成されるので、スタンバイサーバにおける問い合わせは互いにI/Oなどのシステム資源を奪い合います。
   </para>

   <para>
<!--
    There are also additional types of conflict that can occur with Hot Standby.
    These conflicts are <emphasis>hard conflicts</> in the sense that queries
    might need to be canceled and, in some cases, sessions disconnected to resolve them.
    The user is provided with several ways to handle these
    conflicts. Conflict cases include:
-->
ホットスタンバイで発生する可能性があるコンフリクトの種類には他にもあります。
これらのコンフリクトは、問い合わせをキャンセルしなければならない可能性があり、解消させるためにはセッションの接続を閉ざすことになる場合もあるため、<emphasis>致命的なコンフリクト</>です。
ユーザにはこうしたコンフリクトを扱うための複数の方法が提供されます。
コンフリクトする状況には以下があります。

      <itemizedlist>
       <listitem>
        <para>
<!--
         Access Exclusive locks taken on the primary server, including both
         explicit <command>LOCK</> commands and various <acronym>DDL</>
         actions, conflict with table accesses in standby queries.
-->
プライマリサーバで獲得されたアクセス排他ロックは、スタンバイの問い合わせにおけるテーブルアクセスとコンフリクトします。
明示的な<command>LOCK</>コマンドおよび各種<acronym>DDL</>操作を含みます。
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Dropping a tablespace on the primary conflicts with standby queries
         using that tablespace for temporary work files.
-->
プライマリでテーブル空間を削除することは、一時作業ファイル用にそのテーブル空間を使用するスタンバイ側の問い合わせとコンフリクトします。
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Dropping a database on the primary conflicts with sessions connected
         to that database on the standby.
-->
プライマリでデータベースを削除することは、スタンバイ側でそのデータベースに接続するセッションとコンフリクトします。
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Application of a vacuum cleanup record from WAL conflicts with
         standby transactions whose snapshots can still <quote>see</> any of
         the rows to be removed.
-->
WALのバキュームクリーンアップレコードの適用は、その適用により削除さ
れるすべての行を<quote>見る</>ことができるスナップショットを持つスタン
バイでのトランザクションとコンフリクトします。
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Application of a vacuum cleanup record from WAL conflicts with
         queries accessing the target page on the standby, whether or not
         the data to be removed is visible.
-->
WALからレコードを消去するバキュームクリーンアップレコードは、消去されるデータが可視か否かに関係なく、スタンバイで対象ページにアクセスする問い合わせとコンフリクトします。
        </para>
       </listitem>
      </itemizedlist>
   </para>

   <para>
<!--
    On the primary server, these cases simply result in waiting; and the
    user might choose to cancel either of the conflicting actions.  However,
    on the standby there is no choice: the WAL-logged action already occurred
    on the primary so the standby must not fail to apply it.  Furthermore,
    allowing WAL application to wait indefinitely may be very undesirable,
    because the standby's state will become increasingly far behind the
    primary's.  Therefore, a mechanism is provided to forcibly cancel standby
    queries that conflict with to-be-applied WAL records.
-->
プライマリサーバでは、こうした状況は単に待たされるだけです。
ユーザはコンフリクトする操作をキャンセルすることを選ぶことができます。
しかし、スタンバイ側には選択肢がありません。
WALに記録された操作はすでにプライマリで発生したものですので、スタンバイではその適用に失敗してはなりません。
さらに、適用したいWALを無制限に待機させることを許すことは、まったく望まない結果になってしまうかもしれません。
なぜなら、スタンバイの状態がプライマリの状態とだんだんとかけ離れてしまうからです。
したがって適用すべきWALレコードとコンフリクトするスタンバイの問い合わせを強制的に取り消す仕組みが用意されています。
   </para>

   <para>
<!--
    An example of the problem situation is an administrator on the primary
    server running <command>DROP TABLE</> on a table that is currently being
    queried on the standby server.  Clearly the standby query cannot continue
    if the <command>DROP TABLE</> is applied on the standby. If this situation
    occurred on the primary, the <command>DROP TABLE</> would wait until the
    other query had finished. But when <command>DROP TABLE</> is run on the
    primary, the primary doesn't have information about what queries are
    running on the standby, so it will not wait for any such standby
    queries. The WAL change records come through to the standby while the
    standby query is still running, causing a conflict.  The standby server
    must either delay application of the WAL records (and everything after
    them, too) or else cancel the conflicting query so that the <command>DROP
    TABLE</> can be applied.
-->
この問題の例として、スタンバイサーバで現在問い合わせ対象となっているテーブルをプライマリサーバで<command>DROP TABLE</>を行う管理者を考えてみます。
スタンバイで<command>DROP TABLE</>が適用されたら問い合わせを継続できないことは明確です。
プライマリ上でこうした状況が発生した場合は、他の問い合わせが終わるまで<command>DROP TABLE</>は待機させられます。
しかし、<command>DROP TABLE</>がプライマリで実行された時、プライマリ側でスタンバイで稼動する問い合わせに関する情報がありませんので、スタンバイ側のこうした問い合わせを待機させることはできません。
スタンバイ側で問い合わせが実行している時にWALの変更レコードがスタンバイに届けば、コンフリクトが発生します。
スタンバイサーバはWALレコードの適用を遅延させる（およびその後の適用すべても遅延させる）か、<command>DROP TABLE</>を適用できるようにコンフリクトする問い合わせを取り消すかのいずれかを行わなければなりません。
   </para>

   <para>
<!--
    When a conflicting query is short, it's typically desirable to allow it to
    complete by delaying WAL application for a little bit; but a long delay in
    WAL application is usually not desirable.  So the cancel mechanism has
    parameters, <xref linkend="guc-max-standby-archive-delay"> and <xref
    linkend="guc-max-standby-streaming-delay">, that define the maximum
    allowed delay in WAL application.  Conflicting queries will be canceled
    once it has taken longer than the relevant delay setting to apply any
    newly-received WAL data.  There are two parameters so that different delay
    values can be specified for the case of reading WAL data from an archive
    (i.e., initial recovery from a base backup or <quote>catching up</> a
    standby server that has fallen far behind) versus reading WAL data via
    streaming replication.
-->
コンフリクトする問い合わせが短ければ、適用したいWALを多少遅延させることで、問い合わせを完了させることが通常望まれます。
しかし、WALの適用が長く遅延することはたいていは望まれません。
したがって、取り消し機能は<xref linkend="guc-max-standby-archive-delay">と<xref linkend="guc-max-standby-streaming-delay">というパラメータを持ちます。
これらはWAL適用に許される遅延を定義するものです。
コンフリクトする問い合わせは、何らかの新しく受信したWALデータを適用するための各種遅延設定を超えたら取り消されます。
アーカイブからWALデータを読み取る場合（つまりベースバックアップからの初期リカバリや大きく遅延したスタンバイサーバの<quote>追従</>）とストリーミングレプリケーションとで異なる遅延値を指定することができるように2つのパラメータが存在します。
   </para>

   <para>
<!--
    In a standby server that exists primarily for high availability, it's
    best to set the delay parameters relatively short, so that the server
    cannot fall far behind the primary due to delays caused by standby
    queries.  However, if the standby server is meant for executing
    long-running queries, then a high or even infinite delay value may be
    preferable.  Keep in mind however that a long-running query could
    cause other sessions on the standby server to not see recent changes
    on the primary, if it delays application of WAL records.
-->
主に高可用性のために存在するスタンバイサーバでは、スタンバイ側の問い合わせによって発生する遅延のためにプライマリと大きく遅延が発生することがないように、遅延パラメータを相対的に短く設定することが最善です。
しかし、スタンバイサーバが長時間かかる問い合わせを実行するためのものであれば、長い遅延もしくは制限を設けないことが好まれるかもしれません。
しかし、長時間かかる問い合わせがWALレコードの適用を遅延させてしまう場合、スタンバイサーバ上の他のセッションがプライマリにおける最近の変更を参照することができなくなることは覚えておいてください。
   </para>

   <para>
<!--
    Once the delay specified by <varname>max_standby_archive_delay</> or
    <varname>max_standby_streaming_delay</> has been exceeded, conflicting
    queries will be canceled.  This usually results just in a cancellation
    error, although in the case of replaying a <command>DROP DATABASE</>
    the entire conflicting session will be terminated.  Also, if the conflict
    is over a lock held by an idle transaction, the conflicting session is
    terminated (this behavior might change in the future).
-->
<varname>max_standby_archive_delay</>または<varname>max_standby_streaming_delay</>で指定した遅延を超えると、コンフリクトする問い合わせは取り消されます。
通常これは単なる取り消しエラーという結果となりますが、<command>DROP DATABASE</>を再生する場合では、コンフリクトするセッション全体が終了します。
また、コンフリクトが待機中のトランザクションで保持されるロックについてのものであれば、そのコンフリクトするセッションが終了します（この動作は将来変更されるかもしれません）。
   </para>

   <para>
<!--
    Canceled queries may be retried immediately (after beginning a new
    transaction, of course).  Since query cancellation depends on
    the nature of the WAL records being replayed, a query that was
    canceled may well succeed if it is executed again.
-->
ユーザは取り消された問い合わせをすぐに再試行するかもしれません（もちろん新規のトランザクション開始後に）。
問い合わせの取り消しは、再生されるWALレコードの性質に依存するので、取り消された問い合わせが再度実行された場合には正常に動作するかもしれません。
   </para>

   <para>
<!--
    Keep in mind that the delay parameters are compared to the elapsed time
    since the WAL data was received by the standby server.  Thus, the grace
    period allowed to any one query on the standby is never more than the
    delay parameter, and could be considerably less if the standby has already
    fallen behind as a result of waiting for previous queries to complete, or
    as a result of being unable to keep up with a heavy update load.
-->
遅延パラメータはスタンバイサーバでWALデータを受信してからの経過時間と比べられることに注意してください。
したがって、スタンバイ上で任意の問い合わせに許される猶予期間は、この遅延パラメータよりも大きくなることは決してありません。
これまでの問い合わせを完了させるために待機した結果、あるいは、大量の更新負荷に追従することができなくなった結果、スタンバイがすでに遅延している場合は相当小さくなります。
   </para>

   <para>
<!--
    The most common reason for conflict between standby queries and WAL replay
    is <quote>early cleanup</>.  Normally, <productname>PostgreSQL</> allows
    cleanup of old row versions when there are no transactions that need to
    see them to ensure correct visibility of data according to MVCC rules.
    However, this rule can only be applied for transactions executing on the
    master.  So it is possible that cleanup on the master will remove row
    versions that are still visible to a transaction on the standby.
-->
スタンバイ側の問い合わせとWAL再生の間でもっともよくあるコンフリクト理由は<quote>早すぎる消去</>です。
通常<productname>PostgreSQL</>はMVCC規則にしたがって正確なデータの可視性を確実にするために、古い行バージョンを参照するトランザクションが存在しない場合それらを消去することが許されています。
しかし、この規則はマスタ上で実行するトランザクションのみに適用させることができます。
したがって、スタンバイ上のトランザクションでまだ可視である行バージョンを、マスタ上の消去処理が削除してしまう可能性があります。
   </para>

   <para>
<!--
    Experienced users should note that both row version cleanup and row version
    freezing will potentially conflict with standby queries. Running a manual
    <command>VACUUM FREEZE</> is likely to cause conflicts even on tables with
    no updated or deleted rows.
-->
熟練したユーザは、行バージョンの消去と行バージョンの凍結の両方ともスタンバイ側の問い合わせとコンフリクトする可能性があることに気づくはずです。
手作業での<command>VACUUM FREEZE</>は、更新または削除された行がないテーブルであったとしてもコンフリクトを発生し易いものです。
   </para>

   <para>
<!--
    Users should be clear that tables that are regularly and heavily updated
    on the primary server will quickly cause cancellation of longer running
    queries on the standby. In such cases the setting of a finite value for
    <varname>max_standby_archive_delay</> or
    <varname>max_standby_streaming_delay</> can be considered similar to
    setting <varname>statement_timeout</>.
-->
プライマリサーバにおいて規則的かつ頻繁に更新されるテーブルは、スタンバイサーバにおける問い合わせの取り消しの原因になりやすいことを利用者は理解するべきです。
そのような場合、<varname>max_standby_archive_delay</>または<varname>max_standby_streaming_delay</>の設定値は<varname>statement_timeout</>の設定と同様に考えることができます。
   </para>

   <para>
<!--
    Remedial possibilities exist if the number of standby-query cancellations
    is found to be unacceptable.  The first option is to set the parameter
    <varname>hot_standby_feedback</>, which prevents <command>VACUUM</> from
    removing recently-dead rows and so cleanup conflicts do not occur.
    If you do this, you
    should note that this will delay cleanup of dead rows on the primary,
    which may result in undesirable table bloat. However, the cleanup
    situation will be no worse than if the standby queries were running
    directly on the primary server, and you are still getting the benefit of
    off-loading execution onto the standby.
    If standby servers connect and disconnect frequently, you
    might want to make adjustments to handle the period when
    <varname>hot_standby_feedback</> feedback is not being provided.
    For example, consider increasing <varname>max_standby_archive_delay</>
    so that queries are not rapidly canceled by conflicts in WAL archive
    files during disconnected periods.  You should also consider increasing
    <varname>max_standby_streaming_delay</> to avoid rapid cancellations
    by newly-arrived streaming WAL entries after reconnection.
-->
スタンバイのクエリが中断される受け入れがたいほど多い場合、この問題を解決する方法が用意されています。
１つ目の選択肢は、<varname>hot_standby_feedback</>パラメータを設定することです。
これは<command>VACUUM</>による最近不要になった行の削除を防止しますので、消去によるコンフリクトが発生しません。
これを行う場合、プライマリで不要になった行の消去が遅延することに注意が必要です。望まないテーブルの膨張が発生してしまうかもしれません。
しかし、スタンバイ側で行うべき問い合わせをプライマリサーバ上で直接実行することと比べ、こうした消去に関する問題を優先する価値はありません。
また、スタンバイに実行負荷を分散できるという利点があります。
スタンバイサーバが接続、切断を頻繁に繰り返す場合、<varname>hot_standby_feedback</>によるフィードバックが提供されていなければ、その値を調整したいと思うでしょう。
例えば、<varname>max_standby_archive_delay</>が増大し、切断している期間WALアーカイブのコンフリクト発生による問い合わせの中断が速やかに行われないことを考えてみてください。また、再接続後に速やかに問い合わせが中断されることを避けるために<varname>max_standby_streaming_delay</>を大きくすることを考えてみてください。

   </para>

   <para>
<!--
    Another option is to increase <xref linkend="guc-vacuum-defer-cleanup-age">
    on the primary server, so that dead rows will not be cleaned up as quickly
    as they normally would be.  This will allow more time for queries to
    execute before they are canceled on the standby, without having to set
    a high <varname>max_standby_streaming_delay</>.  However it is
    difficult to guarantee any specific execution-time window with this
    approach, since <varname>vacuum_defer_cleanup_age</> is measured in
    transactions executed on the primary server.
-->
他の選択肢は、不要になった行が通常よりも早く消去されないようにプライマリサーバで<xref linkend="guc-vacuum-defer-cleanup-age">を増やすことです。
これにより、<varname>max_standby_streaming_delay</>を長くすることなく、スタンバイでキャンセルが起こるようになる前により多くの時間、問い合わせを実行することができます。
しかし、<varname>vacuum_defer_cleanup_age</>はプライマリサーバ上で実行されたトランザクションを単位に測定されますので、この方法では特定の実行期間を保証することは困難です。
   </para>

   <para>
<!--
    The number of query cancels and the reason for them can be viewed using
    the <structname>pg_stat_database_conflicts</> system view on the standby
    server. The <structname>pg_stat_database</> system view also contains
    summary information.
-->
問い合わせキャンセルの個数とその原因はスタンバイサーバ上の<structname>pg_stat_database_conflicts</>システムビューを用いて参照することができます。
また<structname>pg_stat_database</>システムビューには要約された情報が含まれます。
   </para>
  </sect2>

  <sect2 id="hot-standby-admin">
<!--
   <title>Administrator's Overview</title>
-->
   <title>管理者のための概説</title>

   <para>
<!--
    If <varname>hot_standby</> is turned <literal>on</> in
    <filename>postgresql.conf</> and there is a <filename>recovery.conf</>
    file present, the server will run in Hot Standby mode.
    However, it may take some time for Hot Standby connections to be allowed,
    because the server will not accept connections until it has completed
    sufficient recovery to provide a consistent state against which queries
    can run.  During this period,
    clients that attempt to connect will be refused with an error message.
    To confirm the server has come up, either loop trying to connect from
    the application, or look for these messages in the server logs:
-->
<filename>postgresql.conf</>において<varname>hot_standby</>が<literal>on</>に設定されかつ<filename>recovery.conf</>が存在すれば、サーバはホットスタンバイモードで稼動します。
しかし、サーバはまず問い合わせが実行できる程度の一貫性を持つ状態を提供するために十分なリカバリを完了させなければなりませんので、ホットスタンバイでの接続が有効になるまでに多少の時間がかかるかもしれません。
サーバの準備ができたことを確認するために、アプリケーションで接続試行を繰り返すか、サーバログに以下のメッセージがあるかどうかを確認します。

<programlisting>
LOG:  entering standby mode

<!--
... then some time later ...
-->
... 多少時間が経過して ...

LOG:  consistent recovery state reached
LOG:  database system is ready to accept read only connections
</programlisting>

<!--
    Consistency information is recorded once per checkpoint on the primary.
    It is not possible to enable hot standby when reading WAL
    written during a period when <varname>wal_level</> was not set to
    <literal>hot_standby</> or <literal>logical</> on the primary.  Reaching
    a consistent state can also be delayed in the presence of both of these
    conditions:

-->
一貫性に関する情報はプライマリでチェックポイント毎に一度記録されます。
プライマリで<varname>wal_level</>が<literal>hot_standby</>もしくは<literal>logical</>に設定されていない間に書き込まれたWALを読み取っている時、ホットスタンバイを有効にすることはできません。
また、一貫性のある状態への到達は、以下の両方が存在する間遅延することがあります。

      <itemizedlist>
       <listitem>
        <para>
<!--
         A write transaction has more than 64 subtransactions
-->
サブトランザクション数が64を超える書き込みトランザクション
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Very long-lived write transactions
-->
非常に長く実行される書き込みトランザクション
        </para>
       </listitem>
      </itemizedlist>
<!--
    If you are running file-based log shipping ("warm standby"), you might need
    to wait until the next WAL file arrives, which could be as long as the
    <varname>archive_timeout</> setting on the primary.
-->
ファイルベースのログシッピング(「ウォームスタンバイ」)を実行しているのであれば、次のWALファイルが届く、長くともプライマリの<varname>archive_timeout</>設定まで待機しなければなりません。
   </para>

   <para>
<!--
    The setting of some parameters on the standby will need reconfiguration
    if they have been changed on the primary. For these parameters,
    the value on the standby must
    be equal to or greater than the value on the primary. If these parameters
    are not set high enough then the standby will refuse to start.
    Higher values can then be supplied and the server
    restarted to begin recovery again.  These parameters are:
-->
プライマリサーバにおける設定値が変更した場合、スタンバイサーバにおいて数個のパラメータの再設定が必要です。
スタンバイサーバにおける設定値は、プライマリサーバにおける設定値以上でなければなりません。
所定値未満の設定の場合、スタンバイは起動を取りやめます。
所定値以上の設定により、スタンバイサーバは再起動してリカバリが再び開始されます。
このパラメータは以下です。

      <itemizedlist>
       <listitem>
        <para>
         <varname>max_connections</>
        </para>
       </listitem>
       <listitem>
        <para>
         <varname>max_prepared_transactions</>
        </para>
       </listitem>
       <listitem>
        <para>
         <varname>max_locks_per_transaction</>
        </para>
       </listitem>
      </itemizedlist>
   </para>

   <para>
<!--
    It is important that the administrator select appropriate settings for
    <xref linkend="guc-max-standby-archive-delay"> and <xref
    linkend="guc-max-standby-streaming-delay">.  The best choices vary
    depending on business priorities.  For example if the server is primarily
    tasked as a High Availability server, then you will want low delay
    settings, perhaps even zero, though that is a very aggressive setting. If
    the standby server is tasked as an additional server for decision support
    queries then it might be acceptable to set the maximum delay values to
    many hours, or even -1 which means wait forever for queries to complete.
-->
<xref linkend="guc-max-standby-archive-delay">および<xref linkend="guc-max-standby-streaming-delay">の値が適切であるように管理者が選択することが重要です。
最善の選択は業務上の優先順位によって変化します。
例えば、サーバが主に高可用性を目的としたサーバとして作業するものであれば、短い遅延を設定したいでしょう。
非常に積極的な設定ですが、ゼロにしたいかもしれません。
スタンバイサーバが意思決定支援のための問い合わせ用の追加サーバとして作業するものであれば、数時間程度の最大の遅延値の設定、あるいは問い合わせの完了を永遠に待つことを意味する-1という設定でさえ、許容範囲であるかもしれません。
   </para>

   <para>
<!--
    Transaction status "hint bits" written on the primary are not WAL-logged,
    so data on the standby will likely re-write the hints again on the standby.
    Thus, the standby server will still perform disk writes even though
    all users are read-only; no changes occur to the data values
    themselves.  Users will still write large sort temporary files and
    re-generate relcache info files, so no part of the database
    is truly read-only during hot standby mode.
    Note also that writes to remote databases using
    <application>dblink</application> module, and other operations outside the
    database using PL functions will still be possible, even though the
    transaction is read-only locally.
-->
プライマリ側で「ヒントビット」として書き出されたトランザクション状態はWALに記録されません。
このためスタンバイ側のデータはスタンバイ側でヒントを再度書き出すことになります。
ユーザは大規模なソート用の一時ファイルを書き出し、relcache情報ファイルを再作成します。
したがって、ホットスタンバイモードではデータベースのすべてが本当に読み取り専用ではありません。
また、ローカルでは読み取り専用のトランザクションであっても<application>dblink</application>モジュールを使用したリモートデータベースへの書き出しや、その他のPL関数を使用したデータベース外部への操作が可能であることに注意してください。
   </para>

   <para>
<!--
    The following types of administration commands are not accepted
    during recovery mode:
-->
リカバリモードの間、下記の管理者用コマンドは受理されません。

      <itemizedlist>
       <listitem>
        <para>
<!--
         Data Definition Language (DDL) - e.g. <command>CREATE INDEX</>
-->
データ定義言語、例えば<command>CREATE INDEX</>
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Privilege and Ownership - <command>GRANT</>, <command>REVOKE</>,
         <command>REASSIGN</>
-->
権限および所有権 - <command>GRANT</>と<command>REVOKE</>と<command>REASSIGN</>
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Maintenance commands - <command>ANALYZE</>, <command>VACUUM</>,
         <command>CLUSTER</>, <command>REINDEX</>
-->
保守コマンド - <command>ANALYZE</>と<command>VACUUM</>と<command>CLUSTER</>と<command>REINDEX</>
        </para>
       </listitem>
      </itemizedlist>
   </para>

   <para>
<!--
    Again, note that some of these commands are actually allowed during
    "read only" mode transactions on the primary.
-->
繰り返しますが、これらのコマンドの一部は、プライマリサーバにおける「読み取り専用」モードのトランザクションで実際に許可されていることに注意してください。
   </para>

   <para>
<!--
    As a result, you cannot create additional indexes that exist solely
    on the standby, nor statistics that exist solely on the standby.
    If these administration commands are needed, they should be executed
    on the primary, and eventually those changes will propagate to the
    standby.
-->
その結果、スタンバイ側にのみ存在する追加のインデックスやスタンバイ側にのみ存在する統計情報を作成することはできません。
これらの管理者用コマンドが必要な場合、プライマリ側で実行しなければなりません。
最終的にこの変更はスタンバイ側に伝播します。
   </para>

   <para>
<!--
    <function>pg_cancel_backend()</>
    and <function>pg_terminate_backend()</> will work on user backends,
    but not the Startup process, which performs
    recovery. <structname>pg_stat_activity</structname> does not show an
    entry for the Startup process, nor do recovering transactions show
    as active. As a result, <structname>pg_prepared_xacts</structname>
    is always empty during recovery. If you wish to resolve in-doubt
    prepared transactions, view <literal>pg_prepared_xacts</> on the
    primary and issue commands to resolve transactions there.
-->
<function>pg_cancel_backend()</>と<function>pg_terminate_backend()</>は利用者のバックエンドでは実行できますが、リカバリを実行する起動プロセスでは実行できません。
<structname>pg_stat_activity</structname>は起動プロセスのエントリを表示しないし、リカバリトランザクションが実行中かどうかも表示しません。
その結果、リカバリの間<structname>pg_prepared_xacts</structname>は常に空となります。
準備した確信のもてないトランザクションの状態を解明したい場合、プライマリサーバにおいて<literal>pg_prepared_xacts</>を表示するビューを作成し、ビューに解明のためのコマンドを発行してください。
   </para>

   <para>
<!--
    <structname>pg_locks</structname> will show locks held by backends,
    as normal. <structname>pg_locks</structname> also shows
    a virtual transaction managed by the Startup process that owns all
    <literal>AccessExclusiveLocks</> held by transactions being replayed by recovery.
    Note that the Startup process does not acquire locks to
    make database changes, and thus locks other than <literal>AccessExclusiveLocks</>
    do not show in <structname>pg_locks</structname> for the Startup
    process; they are just presumed to exist.
-->
<structname>pg_locks</structname>は通常通りバックエンドで保持されるロックを示します。
<structname>pg_locks</structname>はまた、リカバリによって再生されているトランザクションで保持される<literal>AccessExclusiveLocks</>のすべてを所有する、起動プロセスで管理される仮想トランザクションも表示します。
起動プロセスはデータベースの変更を行うためのロックを獲得しません。
このため起動プロセスにおいて<literal>AccessExclusiveLocks</>以外のロックは<structname>pg_locks</structname>では表示されません。
これらは存在することを想定されているだけです。
   </para>

   <para>
<!--
    The <productname>Nagios</> plugin <productname>check_pgsql</> will
    work, because the simple information it checks for exists.
    The <productname>check_postgres</> monitoring script will also work,
    though some reported values could give different or confusing results.
    For example, last vacuum time will not be maintained, since no
    vacuum occurs on the standby.  Vacuums running on the primary
    do still send their changes to the standby.
-->
存在を検知する情報が単純なので、<productname>Nagios</>プラグインは稼動します。
一部の報告値が異なった、混乱を招く結果となりますが、<productname>check_postgres</>の監視スクリプトも動作します。
それでも、プライマリで行われるバキュームはその変更をスタンバイに送信します。
   </para>

   <para>
<!--
    WAL file control commands will not work during recovery,
    e.g. <function>pg_start_backup</>, <function>pg_switch_xlog</> etc.
-->
リカバリの間WALの制御コマンドは稼動しません。
例えば、<function>pg_start_backup</>や<function>pg_switch_xlog</>などです。
   </para>

   <para>
<!--
    Dynamically loadable modules work, including <structname>pg_stat_statements</>.
-->
<structname>pg_stat_statements</>も含み、動的に読み込み可能なモジュールは稼動します。
   </para>

   <para>
<!--
    Advisory locks work normally in recovery, including deadlock detection.
    Note that advisory locks are never WAL logged, so it is impossible for
    an advisory lock on either the primary or the standby to conflict with WAL
    replay. Nor is it possible to acquire an advisory lock on the primary
    and have it initiate a similar advisory lock on the standby. Advisory
    locks relate only to the server on which they are acquired.
訳者注、advisory lockはアドバイザリロックとした
-->
デッドロック検出を含むアドバイザリロックは、通常リカバリにおいて稼動します。
アドバイザリロックはWALに決して記録されないので、プライマリサーバでもスタンバイサーバでもWALの再実行においてコンフリクトが起こらないことに注意してください。
プライマリサーバでアドバイザリロックを取得して、スタンバイサーバで同様のアドバイザリロックを掛けることはできません。
アドバイザリロックは取得したサーバだけに関係するものです。
   </para>

   <para>
<!--
    Trigger-based replication systems such as <productname>Slony</>,
    <productname>Londiste</> and <productname>Bucardo</> won't run on the
    standby at all, though they will run happily on the primary server as
    long as the changes are not sent to standby servers to be applied.
    WAL replay is not trigger-based so you cannot relay from the
    standby to any system that requires additional database writes or
    relies on the use of triggers.
-->
<productname>Slony</>や<productname>Londiste</>や<productname>Bucardo</>のようにトリガに基づいたレプリケーションシステムは、スタンバイサーバで全く稼動しません。
しかし、それによる変更がスタンバイサーバに送られるまでは、プライマリサーバにおいて問題なく稼動します。
WALの再実行はトリガに基づいたものではありません。
したがって、データベースへの付加的な書き込みを必要とするか、トリガの使用に依存するものを、スタンバイサーバを中継して他のシステムへ送ることはできません。
   </para>

   <para>
<!--
    New OIDs cannot be assigned, though some <acronym>UUID</> generators may still
    work as long as they do not rely on writing new status to the database.
-->
一部の<acronym>UUID</>ジェネレータは、データベースに新しい状態を書き出すことに依存していない限り動作可能ですが、新しいOIDを割り当てることはできません。
   </para>

   <para>
<!--
    Currently, temporary table creation is not allowed during read only
    transactions, so in some cases existing scripts will not run correctly.
    This restriction might be relaxed in a later release. This is
    both a SQL Standard compliance issue and a technical issue.
-->
現時点では、読み取り専用のトランザクションでは一時テーブルの作成は許されません。
このため既存のスクリプトが正しく動作しない場合があります。
この制限は将来のリリースで緩和されるかもしれません。
これは、標準SQLとの互換性の問題でもあり、技術的な問題でもあります。
   </para>

   <para>
<!--
    <command>DROP TABLESPACE</> can only succeed if the tablespace is empty.
    Some standby users may be actively using the tablespace via their
    <varname>temp_tablespaces</> parameter. If there are temporary files in the
    tablespace, all active queries are canceled to ensure that temporary
    files are removed, so the tablespace can be removed and WAL replay
    can continue.
-->
テーブル空間が空の場合だけ、<command>DROP TABLESPACE</>が成功します。
一部のスタンバイ側のユーザは<varname>temp_tablespaces</>パラメータを介してテーブル空間を活発に使用しているかもしれません。
テーブル空間に一時ファイルが存在する場合、一時ファイルを確実に削除するためすべての問い合わせが取り消されます。
このため、WAL再生を続けながらテーブル空間を削除することができます。
   </para>

   <para>
<!--
    Running <command>DROP DATABASE</> or <command>ALTER DATABASE ... SET
    TABLESPACE</> on the primary
    will generate a WAL entry that will cause all users connected to that
    database on the standby to be forcibly disconnected. This action occurs
    immediately, whatever the setting of
    <varname>max_standby_streaming_delay</>. Note that
    <command>ALTER DATABASE ... RENAME</> does not disconnect users, which
    in most cases will go unnoticed, though might in some cases cause a
    program confusion if it depends in some way upon database name.
-->
プライマリサーバにおける<command>DROP DATABASE</>または<command>ALTER DATABASE ... SET TABLESPACE</>の実行により、スタンバイサーバのデータベースに接続するすべてのユーザを強制的に接続を切断させることになるWALエントリを生成します。
これは<varname>max_standby_streaming_delay</>の設定にかかわらず、直ちに起こります。
<command>ALTER DATABASE ... RENAME</>はユーザを切断しないので大部分の場合は気がつきませんが、プログラムがデータベースの名称に依存するときは混乱の原因となることに注意してください。
   </para>

   <para>
<!--
    In normal (non-recovery) mode, if you issue <command>DROP USER</> or <command>DROP ROLE</>
    for a role with login capability while that user is still connected then
    nothing happens to the connected user - they remain connected. The user cannot
    reconnect however. This behavior applies in recovery also, so a
    <command>DROP USER</> on the primary does not disconnect that user on the standby.
-->
通常の(リカバリ以外の)モードで、ログイン権限を持つロールが接続している間にそのロールに<command>DROP USER</>または<command>DROP ROLE</>を発行した場合、接続中のユーザには何も起こらず、接続し続けます。
しかし、そのユーザは再接続できません。
この振舞いはリカバリモードでも適用されます。
このためプライマリ側で<command>DROP USER</>されたとしても、スタンバイ側のユーザの接続は切断されません。
   </para>

   <para>
<!--
    The statistics collector is active during recovery. All scans, reads, blocks,
    index usage, etc., will be recorded normally on the standby. Replayed
    actions will not duplicate their effects on primary, so replaying an
    insert will not increment the Inserts column of pg_stat_user_tables.
    The stats file is deleted at the start of recovery, so stats from primary
    and standby will differ; this is considered a feature, not a bug.
-->
リカバリの間も統計情報は収集されます。
すべてのスキャン、読み取り、ブロック、インデックスの使用などは、スタンバイサーバにおいて正常に記録されます。
再実行によりプライマリサーバの結果が重複して収集されることはないので、行の挿入によりpg_stat_user_tablesの挿入列の値は増加しません。
リカバリの開始時点で統計情報ファイルが削除されるので、プライマリサーバとスタンバイサーバで統計情報は異なります。
これは将来どうするか検討中であり、バグではありません。
   </para>

   <para>
<!--
    Autovacuum is not active during recovery.  It will start normally at the
    end of recovery.
-->
リカバリの間は自動バキュームは稼動しません。
リカバリが終わると正常に起動します。
   </para>

   <para>
<!--
    The background writer is active during recovery and will perform
    restartpoints (similar to checkpoints on the primary) and normal block
    cleaning activities. This can include updates of the hint bit
    information stored on the standby server.
    The <command>CHECKPOINT</> command is accepted during recovery,
    though it performs a restartpoint rather than a new checkpoint.
-->
リカバリの間バックグラウンドライタは稼動して（プライマリサーバにおけるチェックポイントに類似した）リスタートポイントを設定し、通常のブロック消去を行います。
これはスタンバイサーバに保存されるヒントビット情報の更新を含むことができます。
リカバリの間<command>CHECKPOINT</>コマンドは受理されますが、新規のチェックポイントではなくてリスタートポイントが設定されます。
   </para>
  </sect2>

  <sect2 id="hot-standby-parameters">
<!--
   <title>Hot Standby Parameter Reference</title>
-->
   <title>ホットスタンバイパラメータリファレンス</title>

   <para>
<!--
    Various parameters have been mentioned above in
    <xref linkend="hot-standby-conflict"> and
    <xref linkend="hot-standby-admin">.
-->
種々のパラメータが上記<xref linkend="hot-standby-conflict">および<xref linkend="hot-standby-admin">で述べられています。
   </para>

   <para>
<!--
    On the primary, parameters <xref linkend="guc-wal-level"> and
    <xref linkend="guc-vacuum-defer-cleanup-age"> can be used.
    <xref linkend="guc-max-standby-archive-delay"> and
    <xref linkend="guc-max-standby-streaming-delay"> have no effect if set on
    the primary.
-->
プライマリサーバでは、<xref linkend="guc-wal-level">および<xref linkend="guc-vacuum-defer-cleanup-age">のパラメータを使用できます。
プライマリサーバに<xref linkend="guc-max-standby-archive-delay">および<xref linkend="guc-max-standby-streaming-delay">を設定しても無効です。
   </para>

   <para>
<!--
    On the standby, parameters <xref linkend="guc-hot-standby">,
    <xref linkend="guc-max-standby-archive-delay"> and
    <xref linkend="guc-max-standby-streaming-delay"> can be used.
    <xref linkend="guc-vacuum-defer-cleanup-age"> has no effect
    as long as the server remains in standby mode, though it will
    become relevant if the standby becomes primary.
-->
スタンバイサーバでは<xref linkend="guc-hot-standby">と<xref linkend="guc-max-standby-archive-delay">と<xref linkend="guc-max-standby-streaming-delay">のパラメータを使用できます。
サーバがスタンバイモードの間<xref linkend="guc-vacuum-defer-cleanup-age">を設定しても無効です。
しかし、スタンバイサーバがプライマリサーバになった場合、意味を持つようになります。
   </para>
  </sect2>

  <sect2 id="hot-standby-caveats">
<!--
   <title>Caveats</title>
-->
   <title>警告</title>

   <para>
<!--
    There are several limitations of Hot Standby.
    These can and probably will be fixed in future releases:
-->
ホットスタンバイには幾つかの制限があります。
将来のリリースでは改善されると思われます。

  <itemizedlist>
   <listitem>
    <para>
<!--
     Operations on hash indexes are not presently WAL-logged, so
     replay will not update these indexes.
-->
現在ハッシュインデックスに対する操作はWALに記録されません。
このため再生してもこれらのインデックスは更新されません。
    </para>
   </listitem>
   <listitem>
    <para>
<!--
     Full knowledge of running transactions is required before snapshots
     can be taken. Transactions that use large numbers of subtransactions
     (currently greater than 64) will delay the start of read only
     connections until the completion of the longest running write transaction.
     If this situation occurs, explanatory messages will be sent to the server log.
-->
スナップショットを取ることができるようになる前に、実行中のトランザクションについての完全な知識が要求されます。
(現時点では64を超える)多くのサブトランザクションを使用するトランザクションでは、実行中の最長の書き込みトランザクションが完了するまで、読み取り専用の接続の開始は遅延されます。
この状況が起こると、それを説明するメッセージがサーバログに記録されます。
    </para>
   </listitem>
   <listitem>
    <para>
<!--
     Valid starting points for standby queries are generated at each
     checkpoint on the master. If the standby is shut down while the master
     is in a shutdown state, it might not be possible to re-enter Hot Standby
     until the primary is started up, so that it generates further starting
     points in the WAL logs.  This situation isn't a problem in the most
     common situations where it might happen. Generally, if the primary is
     shut down and not available anymore, that's likely due to a serious
     failure that requires the standby being converted to operate as
     the new primary anyway.  And in situations where the primary is
     being intentionally taken down, coordinating to make sure the standby
     becomes the new primary smoothly is also standard procedure.
-->
スタンバイ問い合わせ用の有効な起動ポイントは、マスタにおけるチェックポイント毎に生成されます。
マスタが停止状態にある時にスタンバイが停止した場合、プライマリが起動し、さらに起動ポイントをWALログに生成するまで再度ホットスタンバイになることができないことがあります。
この状況は、通常考えられる状態では問題ではありません。
一般的に、プライマリが停止し利用できなくなった場合、それはスタンバイに対して新しいプライマリに切り替わることを要求するような深刻な失敗が原因であることが多いはずです。
また、プライマリを意図的に停止させるような状況では、それに伴いスタンバイが新しいプライマリになめらかに切り替わることも普通の手順です。
    </para>
   </listitem>
   <listitem>
    <para>
<!--
     At the end of recovery, <literal>AccessExclusiveLocks</> held by prepared transactions
     will require twice the normal number of lock table entries. If you plan
     on running either a large number of concurrent prepared transactions
     that normally take <literal>AccessExclusiveLocks</>, or you plan on having one
     large transaction that takes many <literal>AccessExclusiveLocks</>, you are
     advised to select a larger value of <varname>max_locks_per_transaction</>,
     perhaps as much as twice the value of the parameter on
     the primary server. You need not consider this at all if
     your setting of <varname>max_prepared_transactions</> is 0.
-->
リカバリの終了において、準備されたトランザクションが保持する<literal>AccessExclusiveLocks</>には、通常の2倍のロックテーブルへのエントリ数が必要です。
通常<literal>AccessExclusiveLocks</>を取るプリペアドトランザクションを大量に同時実行させる、または、多くの<literal>AccessExclusiveLocks</>を取る大規模なトランザクションを1つ実行させることを考えている場合、<varname>max_locks_per_transaction</>の値を、おそらくプライマリサーバのパラメータ値の倍程度に大きくすることを勧めます。
<varname>max_prepared_transactions</>の設定が0ならば、これを検討する必要はまったくありません。
    </para>
   </listitem>
   <listitem>
    <para>
<!--
     The Serializable transaction isolation level is not yet available in hot
     standby.  (See <xref linkend="xact-serializable"> and
     <xref linkend="serializable-consistency"> for details.)
     An attempt to set a transaction to the serializable isolation level in
     hot standby mode will generate an error.
-->
シリアライザブルトランザクション隔離レベルはまだホットスタンバイでは利用できません。
（<xref linkend="xact-serializable">および<xref linkend="serializable-consistency">参照）
ホットスタンバイにおいてトランザクションをシリアライザブルトランザクション隔離レベルに設定しようとすると、エラーになります。
    </para>
   </listitem>
  </itemizedlist>

   </para>
  </sect2>

 </sect1>

<!--
v.181でこのsect1の英文は削除
念のためコメントアウトし、本当の削除を保留
  <sect1 id="backup-incremental-updated">

   <title>Incrementally Updated Backups</title>

   <title>増分更新バックアップ</title>

  <indexterm zone="high-availability">
   <primary>incrementally updated backups</primary>
  </indexterm>

  <indexterm zone="high-availability">
   <primary>change accumulation</primary>
  </indexterm>

   <para>

    In a standby configuration, it is possible to offload the expense of
    taking periodic base backups from the primary server; instead base backups
    can be made by backing
    up a standby server's files.  This concept is generally known as
    incrementally updated backups, log change accumulation, or more simply,
    change accumulation.

スタンバイ設定では、プライマリサーバから定期的なベースバックアップを取るための必要コストを軽減することができます。
代わりにベースバックアップはスタンバイサーバのファイルをバックアップすることで作成することができます。
通常この概念は、増分更新バックアップ、ログ変更蓄積、または単に変更蓄積として知られています。
   </para>

   <para>

    If we take a file system backup of the standby server's data
    directory while it is processing
    logs shipped from the primary, we will be able to reload that backup and
    restart the standby's recovery process from the last restart point.
    We no longer need to keep WAL files from before the standby's restart point.
    If recovery is needed, it will be faster to recover from the incrementally
    updated backup than from the original base backup.

プライマリから転送されるログを処理しつつスタンバイサーバのデータディレクトリのファイルシステムバックアップを取得する場合、バックアップを再ロードし、スタンバイのリカバリ処理を最終リスタートポイントから再起動させることができます。
リスタートポイント以前の WAL ファイルは、もはや保存しなくてかまいません。
リカバリが必要な場合、増分更新バックアップからの復旧は、元のベースバックアップからの復旧より早くなります。
   </para>

   <para>

    The procedure for taking a file system backup of the standby server's
    data directory while it's processing logs shipped from the primary is:

プライマリサーバから転送されるログを処理しつつスタンバイサーバのデータディレクトリのファイルシステムバックアップを取得する手順は以下です。
   <orderedlist>
    <listitem>
     <para>

      Perform the backup, without using <function>pg_start_backup</> and
      <function>pg_stop_backup</>. Note that the <filename>pg_control</>
      file must be backed up <emphasis>first</>, as in:

<function>pg_start_backup</>と<function>pg_stop_backup</>を使用しないでバックアップを行います。
下記のように、<filename>pg_control</>を<emphasis>最初に</>バックアップしなければならないことに注意してください。
<programlisting>
cp /var/lib/pgsql/data/global/pg_control /tmp
cp -r /var/lib/pgsql/data /path/to/backup
mv /tmp/pg_control /path/to/backup/data/global
</programlisting>

      <filename>pg_control</> contains the location where WAL replay will
      begin after restoring from the backup; backing it up first ensures
      that it points to the last restartpoint when the backup started, not
      some later restartpoint that happened while files were copied to the
      backup.

<filename>pg_control</>には、バックアップからリストアした後に再生を始めるWAL位置が含まれています。
まずこのファイルをバックアップすることで、ファイルをコピーしている間に発生する多少遅れたリスタートポイントではなく、バックアップを始めた時の最終リスタートポイントを指し示していることを確実にします。
     </para>
    </listitem>
    <listitem>
     <para>

      Make note of the backup ending WAL location by calling the <function>
      pg_last_xlog_replay_location</> function at the end of the backup,
      and keep it with the backup.

バックアップの終了時に<function>pg_last_xlog_replay_location</>関数を呼び出すことにより、バックアップ終了時点のWAL位置を採取して保存してください。
<programlisting>
psql -c "select pg_last_xlog_replay_location();" &gt; /path/to/backup/end_location
</programlisting>

      When recovering from the incrementally updated backup, the server
      can begin accepting connections and complete the recovery successfully
      before the database has become consistent. To avoid that, you must
      ensure the database is consistent before users try to connect to the
      server and when the recovery ends. You can do that by comparing the
      progress of the recovery with the stored backup ending WAL location:
      the server is not consistent until recovery has reached the backup end
      location. The progress of the recovery can also be observed with the
      <function>pg_last_xlog_replay_location</> function, but that required
      connecting to the server while it might not be consistent yet, so
      care should be taken with that method.

増分更新バックアップからリカバリする場合、一貫性を持つデータベースになる前に、サーバは接続を受け付けることも、リカバリを正常に完了することもあり得ます。
これを防止するためには、ユーザがサーバに接続しようとする前、および、リカバリが終わった時に整合性を持つデータベースであることを確実にしなければなりません。
リカバリの進行と保管されたバックアップ終了時のWAL位置とを比較することで、これを実現できます。
リカバリがバックアップ終了時のWAL位置に達するまで、サーバは整合性を持ちません。
リカバリの進行は<function>pg_last_xlog_replay_location</>関数を用いて確認することができます。
しかし、これには、まだ整合性を持たないかもしれないデータベースに接続しなければなりません。
このためこの方法を行う時には注意しなければなりません。
     <para>
     </para>
    </listitem>
   </orderedlist>
   </para>

   <para>

    Since the standby server is not <quote>live</>, it is not possible to
    use <function>pg_start_backup()</> and <function>pg_stop_backup()</>
    to manage the backup process; it will be up to you to determine how
    far back you need to keep WAL segment files to have a recoverable
    backup. That is determined by the last restartpoint when the backup
    was taken, any WAL older than that can be deleted from the archive
    once the backup is complete. You can determine the last restartpoint
    by running <application>pg_controldata</> on the standby server before
    taking the backup, or by using the <varname>log_checkpoints</> option
    to print values to the standby's server log.

スタンバイサーバは<quote>活動中</>ではありませんので、<function>pg_start_backup()</>と<function>pg_stop_backup()</>を使用してバックアップ処理を管理することはできません。
リカバリ可能なバックアップを持つためにWALセグメントをどれだけ維持しなければならないか決定することは管理者の責任です。
バックアップを取得した時点の最終リスタートポイントによって決定されます。
これより古いWALはバックアップが完了した後にアーカイブから削除することができます。
バックアップを取得する前にスタンバイサーバで<application>pg_controldata</>を実行すること、または、スタンバイサーバのログに値を出力する<varname>log_checkpoints</>オプションを使用することにより、最終リスタートポイントを決定することができます。
   </para>
  </sect1>
コメントアウト終わり
-->

</chapter>

