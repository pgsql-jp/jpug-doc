<!-- doc/src/sgml/high-availability.sgml -->

<chapter id="high-availability">
<!--
 <title>High Availability, Load Balancing, and Replication</title>
-->
 <title>高可用性、負荷分散およびレプリケーション</title>

<!--
 <indexterm><primary>high availability</primary></indexterm>
 <indexterm><primary>failover</primary></indexterm>
 <indexterm><primary>replication</primary></indexterm>
 <indexterm><primary>load balancing</primary></indexterm>
 <indexterm><primary>clustering</primary></indexterm>
 <indexterm><primary>data partitioning</primary></indexterm>
-->
 <indexterm><primary>高可用性</primary></indexterm>
 <indexterm><primary>フェイルオーバー</primary></indexterm>
 <indexterm><primary>レプリケーション</primary></indexterm>
 <indexterm><primary>負荷分散</primary></indexterm>
 <indexterm><primary>クラスタ化</primary></indexterm>
 <indexterm><primary>データの分割</primary></indexterm>

 <para>
<!--
  Database servers can work together to allow a second server to
  take over quickly if the primary server fails (high
  availability), or to allow several computers to serve the same
  data (load balancing).  Ideally, database servers could work
  together seamlessly.  Web servers serving static web pages can
  be combined quite easily by merely load-balancing web requests
  to multiple machines.  In fact, read-only database servers can
  be combined relatively easily too.  Unfortunately, most database
  servers have a read/write mix of requests, and read/write servers
  are much harder to combine.  This is because though read-only
  data needs to be placed on each server only once, a write to any
  server has to be propagated to all servers so that future read
  requests to those servers return consistent results.
-->
データベースサーバは共同して稼動できます。
その目的は、最初のサーバが故障したとき次のサーバへ速やかに引き継ぎができること（高可用性）および複数のコンピュータが同一のデータを処理できること（負荷分散）です。
データベースサーバがシームレスに共同稼動できれば理想的です。
静的なウェブページを提供するウェブサーバは、ウェブからの要求で生ずる負荷を複数のマシンに分散するだけで、簡単に結合できます。
実際、読み取り専用のデータベースサーバの結合は、同じようにかなり容易です。
しかし、大部分のデータベースサーバは、読み書きの混在した要求を受け取り、読み書き両用のサーバの結合はとても困難です。
なぜなら、読み取り要求だけの場合、全サーバへのデータの配布は1回で終わります。
しかし、書き込み後の読み取り要求に対して一貫性のある結果を返すためには、書き込み要求を受けたサーバだけでなく、他の全サーバにおいてもデータに書き込まなければなりません。
 </para>

 <para>
<!--
  This synchronization problem is the fundamental difficulty for
  servers working together.  Because there is no single solution
  that eliminates the impact of the sync problem for all use cases,
  there are multiple solutions.  Each solution addresses this
  problem in a different way, and minimizes its impact for a specific
  workload.
-->
この同時性を持たせるという問題は、共同して稼動するサーバにおいて根本的に困難なものです。
すべての使用状況において、単一の解法を用いて同時性の問題の影響を軽減できないため、複数の解法が存在します。
各々の解法はこの問題に異なったやり方を適用し、固有の作業負荷に対する影響を最小化します。
 </para>

 <para>
<!--
  Some solutions deal with synchronization by allowing only one
  server to modify the data.  Servers that can modify data are
  called read/write, <firstterm>master</firstterm> or <firstterm>primary</firstterm> servers.
  Servers that track changes in the primary are called <firstterm>standby</firstterm>
  or <firstterm>secondary</firstterm> servers. A standby server that cannot be connected
  to until it is promoted to a primary server is called a <firstterm>warm
  standby</firstterm> server, and one that can accept connections and serves read-only
  queries is called a <firstterm>hot standby</firstterm> server.
-->
幾つかの解法では、1つのサーバだけにデータの更新を許可することにより、同時性を持たせています。
データの更新ができるサーバを、読み書きサーバ、<firstterm>マスタ</firstterm>サーバまたは<firstterm>プライマリ</firstterm>サーバといいます。
マスタの変更を追跡するサーバを、<firstterm>スタンバイ</firstterm>サーバまたは<firstterm>セカンダリ</firstterm>サーバといいます。
マスタサーバに昇格するまで接続できないスタンバイサーバを<firstterm>ウォームスタンバイ</firstterm>サーバといいます。
接続を受理できて読み取り専用の問い合わせを処理できるスタンバイサーバを<firstterm>ホットスタンバイ</firstterm>サーバといいます。
 </para>

 <para>
<!--
  Some solutions are synchronous,
  meaning that a data-modifying transaction is not considered
  committed until all servers have committed the transaction.  This
  guarantees that a failover will not lose any data and that all
  load-balanced servers will return consistent results no matter
  which server is queried. In contrast, asynchronous solutions allow some
  delay between the time of a commit and its propagation to the other servers,
  opening the possibility that some transactions might be lost in
  the switch to a backup server, and that load balanced servers
  might return slightly stale results.  Asynchronous communication
  is used when synchronous would be too slow.
-->
いくつかの同期の解法が提供されています。
すなわち、データに書き込むトランザクションでは、全サーバがコミットするまでトランザクションはコミットされません。
これによって、フェイルオーバーにおいてデータの消失がないことが保証されます。
また、どのサーバが問い合わせを受理したかに関係なく、全ての負荷分散サーバが一貫した結果を返すことが保証されます。
それに対して非同期の解法では、コミット時刻と他サーバへの伝達時刻に時間差がありうるため、バックアップサーバへ交代する時にトランザクションが消失する可能性があります。
また、負荷分散サーバにおいては、最新でない結果を応答する可能性があります。
サーバ間の非同期の通信は、同期が非常に低速な場合に使用されます。
 </para>

 <para>
<!--
  Solutions can also be categorized by their granularity.  Some solutions
  can deal only with an entire database server, while others allow control
  at the per-table or per-database level.
-->
解法は粒度によって分類することもできます。
ある解法ではデータベースサーバ全体だけを範囲として処理しますが、他の解法では各テーブルまたは各データベースを範囲として管理できます。
 </para>

 <para>
<!--
  Performance must be considered in any choice.  There is usually a
  trade-off between functionality and
  performance.  For example, a fully synchronous solution over a slow
  network might cut performance by more than half, while an asynchronous
  one might have a minimal performance impact.
-->
すべての選択において、作業効率を考えなければなりません。
通常、作業効率と機能性は相反する関係にあります。
例えば、遅いネットワークの場合、完全同期の解法を使えば作業効率は半分以下となりますが、非同期の解法を使えば作業効率への影響が最小となります。
 </para>

 <para>
<!--
  The remainder of this section outlines various failover, replication,
  and load balancing solutions.
-->
本節では、フェイルオーバーとレプリケーションと負荷分散における種々の解法を説明します。
 </para>

 <sect1 id="different-replication-solutions">
<!--
 <title>Comparison of Different Solutions</title>
-->
 <title>様々な解法の比較</title>

 <variablelist>

  <varlistentry>
<!--
   <term>Shared Disk Failover</term>
-->
   <term>共有ディスクを用いたフェイルオーバー</term>
   <listitem>

    <para>
<!--
     Shared disk failover avoids synchronization overhead by having only one
     copy of the database.  It uses a single disk array that is shared by
     multiple servers.  If the main database server fails, the standby server
     is able to mount and start the database as though it were recovering from
     a database crash.  This allows rapid failover with no data loss.
-->
データベースのコピーを 1つだけ保有すればよいため、共有ディスクを用いたフェイルオーバーは同期によるオーバーヘッドを回避できます。
本解法では、複数のサーバが単一のディスクアレイを共有します。
主データベースサーバが故障したとき、まるでデータベースの破損から復旧したように、スタンバイサーバが元のデータベースを実装して稼動できます。
これはデータの消失がない高速なフェイルオーバーを行うことができます。
    </para>

    <para>
<!--
     Shared hardware functionality is common in network storage devices.
     Using a network file system is also possible, though care must be
     taken that the file system has full <acronym>POSIX</acronym> behavior (see <xref
     linkend="creating-cluster-nfs"/>).  One significant limitation of this
     method is that if the shared disk array fails or becomes corrupt, the
     primary and standby servers are both nonfunctional.  Another issue is
     that the standby server should never access the shared storage while
     the primary server is running.
-->
ハードウェアを共有するという機能は、ネットワーク上の記憶装置では一般的です。
ネットワークファイルシステムの利用も可能ですが、そのファイルシステムが<acronym>POSIX</acronym>仕様を満たしているか注意してください。
（ <xref linkend="creating-cluster-nfs"/>を見てください）。
本解法には重大な制約があり、共有ディスクアレイが故障または破損したとき、プライマリサーバもスタンバイサーバも機能しなくなります。
また、プライマリサーバが稼動している間は、スタンバイサーバが共有記憶装置にアクセスしてはなりません。
    </para>

   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>File System (Block Device) Replication</term>
-->
   <term>ファイルシステム（ブロックデバイス）レプリケーション</term>
   <listitem>

    <para>
<!--
     A modified version of shared hardware functionality is file system
     replication, where all changes to a file system are mirrored to a file
     system residing on another computer.  The only restriction is that
     the mirroring must be done in a way that ensures the standby server
     has a consistent copy of the file system &mdash; specifically, writes
     to the standby must be done in the same order as those on the primary.
     <productname>DRBD</productname> is a popular file system replication solution
     for Linux.
-->
ハードウェア共有機能の改善の一つとしてファイルシステムのレプリケーションをあげることができます。
それは、あるファイルシステムに対して行われたすべての変更を他のコンピュータに存在するファイルシステムにミラーリングします。
制約はただ一つであり、スタンバイサーバがファイルシステムの一貫したコピーを自身の領域に持つようにミラーリングしなければなりません。具体的には、スタンバイサーバへの書き込みがマスタサーバへの書き込みと同じ順序でおこなわれなければなりません。
Linuxにおける<productname>DRBD</productname>は、ファイルシステムレプリケーションで広く受けいれられている手法です。
    </para>

<!--
原文におけるコメントアウト
https://forge.continuent.org/pipermail/sequoia/2006-November/004070.html

Oracle RAC is a shared disk approach and just send cache invalidations
to other nodes but not actual data. As the disk is shared, data is
only committed once to disk and there is a distributed locking
protocol to make nodes agree on a serializable transactional order.
コメントアウト終了
-->

   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>Write-Ahead Log Shipping</term>
-->
   <term>先行書き込みログシッピング</term>
   <listitem>

    <para>
<!--
     Warm and hot standby servers can be kept current by reading a
     stream of write-ahead log (<acronym>WAL</acronym>)
     records.  If the main server fails, the standby contains
     almost all of the data of the main server, and can be quickly
     made the new primary database server.  This can be synchronous or
     asynchronous and can only be done for the entire database server.
-->
ウォームスタンバイおよびホットスタンバイサーバは、ログ先行書き込み（<acronym>WAL</acronym>）のレコードを解読して最新の状態を保持できます。
プライマリサーバが故障したとき、スタンバイサーバがプライマリサーバのほぼすべてのデータを保存して、速やかに新しい主データベースを稼動できます。
本解法は同期、非同期で行うことができ、データベース全体だけを範囲として処理できます。
    </para>
    <para>
<!--
     A standby server can be implemented using file-based log shipping
     (<xref linkend="warm-standby"/>) or streaming replication (see
     <xref linkend="streaming-replication"/>), or a combination of both. For
     information on hot standby, see <xref linkend="hot-standby"/>.
-->
スタンバイサーバは、ファイル単位のログシッピング（<xref linkend="warm-standby"/>参照）またはストリーミングレプリケーション（<xref linkend="streaming-replication"/>参照）または両者の併用を使用して実装できます。
ホットスタンバイの情報は <xref linkend="hot-standby"/> を参照してください。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>Logical Replication</term>
-->
   <term>論理レプリケーション</term>
   <listitem>
    <para>
<!--
     Logical replication allows a database server to send a stream of data
     modifications to another server.  <productname>PostgreSQL</productname>
     logical replication constructs a stream of logical data modifications
     from the WAL.  Logical replication allows replication of data changes on
     a per-table basis.  In addition, a server that is publishing its own
     changes can also subscribe to changes from another server, allowing data
     to flow in multiple directions.  For more information on logical
     replication, see <xref linkend="logical-replication"/>.  Through the
     logical decoding interface (<xref linkend="logicaldecoding"/>),
     third-party extensions can also provide similar functionality.
-->
論理レプリケーションにより、データベースサーバが他のサーバに、データ更新のストリームを送ることができます。
<productname>PostgreSQL</productname>の論理レプリケーションは、WALから論理的なデータ更新のストリームを構築します。
論理レプリケーションでは、個々のテーブルの変更を複製することができます。
論理レプリケーションにおいては、特定のサーバをマスターあるいはレプリカに割り当てる必要なしに、複数の方向にデータを流すことができます。
論理レプリケーションの更なる情報については、<xref linkend="logical-replication"/>をご覧ください。
ロジカルデコーディングインタフェース(<xref linkend="logicaldecoding"/>)を使って、サードパーティー拡張は同様の機能を提供できます。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>Trigger-Based Primary-Standby Replication</term>
-->
   <term>トリガベースのマスタ・スタンバイレプリケーション</term>
   <listitem>

    <para>
     A trigger-based replication setup typically funnels data modification
     queries to a designated primary server. Operating on a per-table basis,
     the primary server sends data changes (typically) asynchronously to the
     standby servers.  Standby servers can answer queries while the primary is
     running, and may allow some local data changes or write activity.  This
     form of replication is often used for offloading large analytical or data
     warehouse queries.
    </para>

    <para>
<!--
     <productname>Slony-I</productname> is an example of this type of
     replication, with per-table granularity, and support for multiple standby
     servers.  Because it updates the standby server asynchronously (in
     batches), there is possible data loss during fail over.
-->
この種類のレプリケーションの一例は<productname>Slony-I</productname>であり、テーブル単位の粒度を持ち、複数のスタンバイサーバが稼動できます。
（バッチ処理によって）スタンバイサーバのデータを非同期で更新するため、フェイルオーバーにおけるデータ消失の可能性があります。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>SQL-Based Replication Middleware</term>
-->
   <term>SQLに基づいたレプリケーションのミドルウェア</term>
   <listitem>

    <para>
<!--
     With SQL-based replication middleware, a program intercepts
     every SQL query and sends it to one or all servers.  Each server
     operates independently.  Read-write queries must be sent to all servers,
     so that every server receives any changes.  But read-only queries can be
     sent to just one server, allowing the read workload to be distributed
     among them.
-->
SQLに基づいたレプリケーションのミドルウェアでは、プログラムがすべてのSQL問い合わせを採取して、1つまたはすべてのサーバに送付します。
なお、各々のサーバは独立して稼動します。
読み書き問い合わせは、すべてのサーバがすべての変更を受け取るように全サーバに送付されなければなりません。
しかし、読み取り専用の問い合わせはサーバ全体の読み取り負荷を分散させるために、1つのサーバだけに送付することができます。
    </para>

    <para>
<!--
     If queries are simply broadcast unmodified, functions like
     <function>random()</function>, <function>CURRENT_TIMESTAMP</function>, and
     sequences can have different values on different servers.
     This is because each server operates independently, and because
     SQL queries are broadcast rather than actual data changes.  If
     this is unacceptable, either the middleware or the application
     must determine such values from a single source and then use those
     values in write queries.  Care must also be taken that all
     transactions either commit or abort on all servers, perhaps
     using two-phase commit (<xref linkend="sql-prepare-transaction"/>
     and <xref linkend="sql-commit-prepared"/>).
     <productname>Pgpool-II</productname> and <productname>Continuent Tungsten</productname>
     are examples of this type of replication.
-->
問い合わせを修正しないで送付した場合、<function>random()</function>関数による乱数値と<function>CURRENT_TIMESTAMP</function>関数による現在時刻およびシーケンス値が、サーバごとに異なることがあります。
その理由は、各サーバが独立して稼動しているため、および、SQL問い合わせの送付では実際に更新した行の識別値を取得できないためです。
これが許容できない場合は、ミドルウェアかアプリケーションにおいて1つのサーバにこのような問い合わせを送付し、その結果を書き込み問い合わせで使用しなければなりません。
その他の選択肢は従来のマスタとスタンバイによるレプリケーションのオプションを使用するものです。
すなわち、データ更新の問い合わせをマスタサーバだけに送付し、ミドルウェアによるレプリケーションを使わずにマスタとスタンバイによるレプリケーションを介してスタンバイサーバに伝達します。
トランザクションをコミットするか中断するかについても、全サーバが同一となるよう注意しなければなりません。
これには2相コミット（<xref linkend="sql-prepare-transaction"/> および <xref linkend="sql-commit-prepared"/>）を使用することになるでしょう。
<productname>Pgpool-II</productname>と<productname>Continuent Tungsten</productname>がこのレプリケーションの一例です。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>Asynchronous Multimaster Replication</term>
-->
   <term>非同期マルチマスタレプリケーション</term>
   <listitem>

    <para>
<!--
     For servers that are not regularly connected or have slow
     communication links, like laptops or
     remote servers, keeping data consistent among servers is a
     challenge.  Using asynchronous multimaster replication, each
     server works independently, and periodically communicates with
     the other servers to identify conflicting transactions.  The
     conflicts can be resolved by users or conflict resolution rules.
     Bucardo is an example of this type of replication.
-->
ラップトップやリモートマシンのように、通常は接続されていない、あるいは遅い通信リンクで接続されているサーバ間において、データの一貫性を保持することは挑戦的な課題です。
非同期マルチマスタレプリケーションの使用により、全サーバの独立した稼動、およびトランザクションの衝突を識別するための定期的な通信を実現します。
トランザクションの衝突は、利用者および衝突回避法によって解決できるでしょう。
Bucardoはこの種のレプリケーションの一例です。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>Synchronous Multimaster Replication</term>
-->
   <term>同期マルチマスタレプリケーション</term>
   <listitem>

    <para>
<!--
     In synchronous multimaster replication, each server can accept
     write requests, and modified data is transmitted from the
     original server to every other server before each transaction
     commits.  Heavy write activity can cause excessive locking and
     commit delays, leading to poor performance.  Read requests can
     be sent to any server.  Some implementations use shared disk
     to reduce the communication overhead.  Synchronous multimaster
     replication is best for mostly read workloads, though its big
     advantage is that any server can accept write requests &mdash;
     there is no need to partition workloads between primary and
     standby servers, and because the data changes are sent from one
     server to another, there is no problem with non-deterministic
     functions like <function>random()</function>.
-->
同期マルチマスタレプリケーションでは全てのサーバが書き込み要求を受理できます。
受理したサーバは更新したデータを、トランザクションをコミットする前に、他の全サーバへ配布します。
書き込み負荷が重いとき、ロックの掛かり過ぎやコミットの遅延による作業効率の低下の原因となりえます。
読み取り要求はどのサーバにも送付できます。
通信による負荷を減らすには、共有ディスクが実装されます。
同期マルチマスタレプリケーションは、主に読み取り作業負荷の低減に最適ですが、全てのサーバが書き込み要求を受理できることも大きな利点です。
その利点とは、マスタとスタンバイ間で作業負荷を分けなくてよいこと、および更新データが1つのサーバから他のサーバに送付されるため、出力が確定しない<function>random()</function>関数などによる問題が起こらないことです。
    </para>

    <para>
<!--
     <productname>PostgreSQL</productname> does not offer this type of replication,
     though <productname>PostgreSQL</productname> two-phase commit (<xref
     linkend="sql-prepare-transaction"/> and <xref
     linkend="sql-commit-prepared"/>)
     can be used to implement this in application code or middleware.
-->
<productname>PostgreSQL</productname> では、この種類のレプリケーションを提供しません。
しかし、<productname>PostgreSQL</productname> の 2相コミット（<xref linkend="sql-prepare-transaction"/>および<xref linkend="sql-commit-prepared"/>）を使用すれば、アプリケーションのコードまたはミドルウェアにおいて本解法を実装できます。
    </para>
   </listitem>
  </varlistentry>

 </variablelist>

 <para>
<!--
  <xref linkend="high-availability-matrix"/> summarizes
  the capabilities of the various solutions listed above.
-->
<xref linkend="high-availability-matrix"/>は上述した種々の解法の機能を要約したものです。
 </para>

 <table id="high-availability-matrix">
<!--
  <title>High Availability, Load Balancing, and Replication Feature Matrix</title>
-->
  <title>高可用性、負荷分散およびレプリケーションの特徴</title>
  <tgroup cols="9">
   <colspec colname="col1" colwidth="1.1*"/>
   <colspec colname="col2" colwidth="1*"/>
   <colspec colname="col3" colwidth="1*"/>
   <colspec colname="col4" colwidth="1*"/>
   <colspec colname="col5" colwidth="1*"/>
   <colspec colname="col6" colwidth="1*"/>
   <colspec colname="col7" colwidth="1*"/>
   <colspec colname="col8" colwidth="1*"/>
   <colspec colname="col9" colwidth="1*"/>
   <thead>
    <row>
<!--
     <entry>Feature</entry>
     <entry>Shared Disk</entry>
     <entry>File System Repl.</entry>
     <entry>Write-Ahead Log Shipping</entry>
     <entry>Logical Repl.</entry>
     <entry>Trigger-&zwsp;Based Repl.</entry>
     <entry>SQL Repl. Middle-ware</entry>
     <entry>Async. MM Repl.</entry>
     <entry>Sync. MM Repl.</entry>
-->
     <entry>特徴</entry>
     <entry>共有ディスク</entry>
     <entry>ファイルシステムのレプリケーション</entry>
     <entry>先行書き込みログシッピング</entry>
     <entry>論理レプリケーション</entry>
     <entry>トリガに基づいたレプリケーション</entry>
     <entry>SQLに基づいたレプリケーションのミドルウェア</entry>
     <entry>非同期マルチマスタレプリケーション</entry>
     <entry>同期マルチマスタレプリケーション</entry>
    </row>
   </thead>

   <tbody>

    <row>
<!--
     <entry>Popular examples</entry>
     <entry align="center">NAS</entry>
     <entry align="center">DRBD</entry>
     <entry align="center">built-in streaming repl.</entry>
     <entry align="center">built-in logical repl., pglogical</entry>
     <entry align="center">Londiste, Slony</entry>
     <entry align="center">pgpool-II</entry>
     <entry align="center">Bucardo</entry>
     <entry align="center"></entry>
-->
     <entry>一般的な例</entry>
     <entry align="center">NAS</entry>
     <entry align="center">DRBD</entry>
     <entry align="center">組み込みストリーミングレプリケーション</entry>
     <entry align="center">組み込み論理レプリケーション、pglogical</entry>
     <entry align="center">Londiste、Slony</entry>
     <entry align="center">pgpool-II</entry>
     <entry align="center">Bucardo</entry>
     <entry align="center"></entry>
    </row>

    <row>
<!--
     <entry>Comm. method</entry>
     <entry align="center">shared disk</entry>
     <entry align="center">disk blocks</entry>
     <entry align="center">WAL</entry>
     <entry align="center">logical decoding</entry>
     <entry align="center">table rows</entry>
     <entry align="center">SQL</entry>
     <entry align="center">table rows</entry>
     <entry align="center">table rows and row locks</entry>
-->
     <entry>通信方法</entry>
     <entry align="center">共有ディスク</entry>
     <entry align="center">ディスクブロック</entry>
     <entry align="center">WAL</entry>
     <entry align="center">ロジカルデコーディング</entry>
     <entry align="center">テーブル行</entry>
     <entry align="center">SQL</entry>
     <entry align="center">テーブル行</entry>
     <entry align="center">テーブル行および行ロック</entry>
    </row>

    <row>
<!--
     <entry>No special hardware required</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
-->
     <entry>特別なハードウェアが不要</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
    </row>

    <row>
<!--
     <entry>Allows multiple primary servers</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
-->
     <entry>複数のマスタサーバが可能</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
    </row>

    <row>
<!--
     <entry>No overhead on primary</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
-->
     <entry>マスタサーバにオーバヘッドがない</entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
    </row>

    <row>
<!--
     <entry>No waiting for multiple servers</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">with sync off</entry>
     <entry align="center">with sync off</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
-->
     <entry>複数のスレーブサーバを待たない</entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">同期が無効の場合</entry>
     <entry align="center">同期が無効の場合</entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
    </row>

    <row>
<!--
     <entry>Primary failure will never lose data</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">with sync on</entry>
     <entry align="center">with sync on</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
-->
     <entry>マスタの故障によるデータ損失がない</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">同期が有効の場合</entry>
     <entry align="center">同期が有効の場合</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
    </row>

    <row>
<!--
     <entry>Replicas accept read-only queries</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">with hot standby</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
-->
     <entry>レプリカは読み取り専用問い合わせを受理可能</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">ホットスタンバイ使用時</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
    </row>

    <row>
<!--
     <entry>Per-table granularity</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
-->
     <entry>テーブルごとの粒度</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
    </row>

    <row>
<!--
     <entry>No conflict resolution necessary</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
     <entry align="center">&bull;</entry>
     <entry align="center"></entry>
     <entry align="center">&bull;</entry>
-->
     <entry>コンフリクトの回避が不要</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
     <entry align="center"></entry>
     <entry align="center"></entry>
     <entry align="center">○</entry>
    </row>

   </tbody>
  </tgroup>
 </table>

 <para>
<!--
  There are a few solutions that do not fit into the above categories:
-->
上の分類に該当しない解法もあります。
 </para>

 <variablelist>

  <varlistentry>
<!--
   <term>Data Partitioning</term>
-->
   <term>データの分割</term>
   <listitem>

    <para>
<!--
     Data partitioning splits tables into data sets.  Each set can
     be modified by only one server.  For example, data can be
     partitioned by offices, e.g., London and Paris, with a server
     in each office.  If queries combining London and Paris data
     are necessary, an application can query both servers, or
     primary/standby replication can be used to keep a read-only copy
     of the other office's data on each server.
-->
データの分割とは、同じテーブルのデータを複数部分に分けることです。
各部分に書き込むことができるのは、1つのサーバだけです。
例えば、データをロンドンとパリの営業所用に分割でき、サーバをロンドンとパリのどちらにも設置できた状態を考えます。
問い合わせにロンドンとパリのデータが混在した場合、アプリケーションは両方のサーバに問い合わせることができます。
または、マスタスタンバイレプリケーションを使用して、他の営業所のデータを読み取り専用コピーとして保持できます。
    </para>
   </listitem>
  </varlistentry>

  <varlistentry>
<!--
   <term>Multiple-Server Parallel Query Execution</term>
-->
   <term>複数サーバによる問い合わせの並列実行</term>
   <listitem>

    <para>
<!--
     Many of the above solutions allow multiple servers to handle multiple
     queries, but none allow a single query to use multiple servers to
     complete faster.  This solution allows multiple servers to work
     concurrently on a single query.  It is usually accomplished by
     splitting the data among servers and having each server execute its
     part of the query and return results to a central server where they
     are combined and returned to the user. This can be implemented using the
     <productname>PL/Proxy</productname> tool set.
-->
上述した多くの解法は、複数のサーバが複数の問い合わせを処理するものです。
処理速度の向上のために、単一の問い合わせに複数のサーバを使用するものはありません。
本解法は複数のサーバが単一の問い合わせを共同して実行するものです。
その方法は、データをサーバ間で分割し、各サーバが部分的に問い合わせを実行し、各々の結果をプライマリサーバに送付し、プライマリサーバが合体して利用者に返送するものです。
これは<productname>PL/Proxy</productname>ツールセットを使用して実装できます。
    </para>

   </listitem>
  </varlistentry>

 </variablelist>

  <para>
<!--
   It should also be noted that because <productname>PostgreSQL</productname>
   is open source and easily extended, a number of companies have
   taken <productname>PostgreSQL</productname> and created commercial
   closed-source solutions with unique failover, replication, and load
   balancing capabilities.  These are not discussed here.
-->
また、<productname>PostgreSQL</productname>はオープンソースで、容易に拡張できるので、多くの企業が<productname>PostgreSQL</productname>をもとにして、独自のフェイルオーバー、レプリケーション、負荷分散機能を備えたクローズドソースの製品を開発していることに注意してください。
これらについては、ここでは議論しません。
  </para>

 </sect1>


 <sect1 id="warm-standby">
<!--
 <title>Log-Shipping Standby Servers</title>
-->
 <title>ログシッピングスタンバイサーバ</title>


  <para>
<!--
   Continuous archiving can be used to create a <firstterm>high
   availability</firstterm> (HA) cluster configuration with one or more
   <firstterm>standby servers</firstterm> ready to take over operations if the
   primary server fails. This capability is widely referred to as
   <firstterm>warm standby</firstterm> or <firstterm>log shipping</firstterm>.
-->
継続的なアーカイブ処理を使用して、プライマリサーバが失敗した場合に操作を引き継ぐ準備がなされた、1つ以上の<firstterm>スタンバイサーバ</firstterm>を持つ<firstterm>高可用性</firstterm>(HA)クラスタ構成を作成することができます。
この機能は<firstterm>ウォームスタンバイ</firstterm>または<firstterm>ログシッピング</firstterm>として広く知られています。
  </para>

  <para>
<!--
   The primary and standby server work together to provide this capability,
   though the servers are only loosely coupled. The primary server operates
   in continuous archiving mode, while each standby server operates in
   continuous recovery mode, reading the WAL files from the primary. No
   changes to the database tables are required to enable this capability,
   so it offers low administration overhead compared to some other
   replication solutions. This configuration also has relatively low
   performance impact on the primary server.
-->
プライマリサーバとスタンバイサーバは、この機能を提供するために共同して稼動しますが、サーバとサーバはゆるく結合しています。
プライマリサーバは継続的アーカイブモードで動作し、各スタンバイサーバはプライマリからWALファイルを読み取る、継続的リカバリモードで動作します。
この機能を可能にするために、データベースのテーブル変更は不要です。
したがって、他のレプリケーションの解法に比べて、管理にかかるオーバーヘッドが減少します。
この構成はプライマリサーバの性能への影響も相対的に減少させます。
  </para>

  <para>
<!--
   Directly moving WAL records from one database server to another
   is typically described as log shipping. <productname>PostgreSQL</productname>
   implements file-based log shipping by transferring WAL records
   one file (WAL segment) at a time. WAL files (16MB) can be
   shipped easily and cheaply over any distance, whether it be to an
   adjacent system, another system at the same site, or another system on
   the far side of the globe. The bandwidth required for this technique
   varies according to the transaction rate of the primary server.
   Record-based log shipping is more granular and streams WAL changes
   incrementally over a network connection (see <xref
   linkend="streaming-replication"/>).
-->
あるデータベースサーバから他へ直接WALレコードを移動することは通常、ログシッピングと説明されます。
<productname>PostgreSQL</productname>はファイルベースのログシッピングを実装します。
つまりWALレコードはある時点で1つのファイル(WALセグメント)として送信されることを意味します。
WALファイル(16MB)は隣り合うシステム、同じサイトの別システム、地球の裏側のシステムなど距離に関わらず、簡単かつ安価に送付することができます。
この技法に必要な帯域幅はプライマリサーバのトランザクションの頻度に応じて変動します。
レコードベースのログシッピングはより粒度を細かくしたもので、ネットワーク接続を介してWALの変更を増分的に流します（<xref linkend="streaming-replication"/>参照）。
  </para>

  <para>
<!--
   It should be noted that log shipping is asynchronous, i.e., the WAL
   records are shipped after transaction commit. As a result, there is a
   window for data loss should the primary server suffer a catastrophic
   failure; transactions not yet shipped will be lost.  The size of the
   data loss window in file-based log shipping can be limited by use of the
   <varname>archive_timeout</varname> parameter, which can be set as low
   as a few seconds.  However such a low setting will
   substantially increase the bandwidth required for file shipping.
   Streaming replication (see <xref linkend="streaming-replication"/>)
   allows a much smaller window of data loss.
-->
ログシッピングが非同期であることに注意しなければなりません。
つまり、WALレコードはトランザクションがコミットした後に転送されます。
結果として、プライマリサーバが災害などの致命的な失敗をうけた場合、送信されていないトランザクションが失われますので、データを損失する空白期間があります。
ファイルベースのログシッピングにおけるデータ損失の空白期間量を<varname>archive_timeout</varname>パラメータを用いて制限することができます。
これは数秒程度まで小さく設定することができます。
しかし、低く設定するとファイル転送に必要な帯域幅が増大します。
ストリーミングレプリケーション（<xref linkend="streaming-replication"/>参照）により、データを損失する期間を非常に小さくすることができます。
  </para>

  <para>
<!--
   Recovery performance is sufficiently good that the standby will
   typically be only moments away from full
   availability once it has been activated. As a result, this is called
   a warm standby configuration which offers high
   availability. Restoring a server from an archived base backup and
   rollforward will take considerably longer, so that technique only
   offers a solution for disaster recovery, not high availability.
   A standby server can also be used for read-only queries, in which case
   it is called a Hot Standby server. See <xref linkend="hot-standby"/> for
   more information.
-->
リカバリ処理の性能は十分よく、一度実施されれば、スタンバイサーバが完全な状態から逸脱するのは一時的にしかすぎません。
結果としてこれは、高可用性を提供するウォームスタンバイ構成と呼ばれます。
保管されたベースバックアップからサーバをリストアし、ロールフォワードを行うことはおそらく長時間かかりますので、これは高可用性のための解法とはいえず、災害からのリカバリのための解法です。
スタンバイサーバは読み取り専用の問い合わせに使用することもできます。
この場合ホットスタンバイサーバと呼ばれます。
詳細については<xref linkend="hot-standby"/>を参照してください。
  </para>

  <indexterm zone="high-availability">
<!--
   <primary>warm standby</primary>
-->
   <primary>ウォームスタンバイ</primary>
  </indexterm>

  <indexterm zone="high-availability">
<!--
   <primary>PITR standby</primary>
-->
   <primary>PITRスタンバイ</primary>
  </indexterm>

  <indexterm zone="high-availability">
<!--
   <primary>standby server</primary>
-->
   <primary>スタンバイサーバ</primary>
  </indexterm>

  <indexterm zone="high-availability">
<!--
   <primary>log shipping</primary>
-->
   <primary>ログシッピング</primary>
  </indexterm>

  <indexterm zone="high-availability">
<!--
   <primary>witness server</primary>
-->
   <primary>証明サーバ</primary>
  </indexterm>

  <indexterm zone="high-availability">
   <primary>STONITH</primary>
  </indexterm>

  <sect2 id="standby-planning">
<!--
   <title>Planning</title>
-->
   <title>計画</title>

   <para>
<!--
    It is usually wise to create the primary and standby servers
    so that they are as similar as possible, at least from the
    perspective of the database server.  In particular, the path names
    associated with tablespaces will be passed across unmodified, so both
    primary and standby servers must have the same mount paths for
    tablespaces if that feature is used.  Keep in mind that if
    <xref linkend="sql-createtablespace"/>
    is executed on the primary, any new mount point needed for it must
    be created on the primary and all standby servers before the command
    is executed. Hardware need not be exactly the same, but experience shows
    that maintaining two identical systems is easier than maintaining two
    dissimilar ones over the lifetime of the application and system.
    In any case the hardware architecture must be the same &mdash; shipping
    from, say, a 32-bit to a 64-bit system will not work.
-->
プライマリサーバとスタンバイサーバを、少なくともデータベースサーバという見地でできる限り同じになるように作成することを通常勧めます。
具体的には、テーブル空間に関連するパス名はそのまま渡されますので、テーブル空間機能を使用する場合には、プライマリとスタンバイサーバの両方でテーブル空間用のマウントパスを同じにしておかなければなりません。
<xref linkend="sql-createtablespace"/>をプライマリで実行する場合、そのコマンドを実行する前に必要な新しいマウントポイントをプライマリとすべてのスタンバイサーバで作成しなければならないことに注意してください。
ハードウェアをまったく同じにする必要はありませんが、経験上アプリケーションとシステムの運用期間に渡って2つの同じシステムを管理する方が、異なる2つのシステムを管理するよりも簡単です。
いずれにしてもハードウェアアーキテクチャは必ず同じでなければなりません。
例えば32ビットシステムから64ビットシステムへのシッピングは動作しません。
   </para>

   <para>
<!--
    In general, log shipping between servers running different major
    <productname>PostgreSQL</productname> release
    levels is not possible. It is the policy of the PostgreSQL Global
    Development Group not to make changes to disk formats during minor release
    upgrades, so it is likely that running different minor release levels
    on primary and standby servers will work successfully. However, no
    formal support for that is offered and you are advised to keep primary
    and standby servers at the same release level as much as possible.
    When updating to a new minor release, the safest policy is to update
    the standby servers first &mdash; a new minor release is more likely
    to be able to read WAL files from a previous minor release than vice
    versa.
-->
一般的に、異なるメジャーリリースレベルの<productname>PostgreSQL</productname>間でログシッピングはできません。
マイナーリリースの更新ではディスク書式を変更しないというのがPostgreSQLグローバル開発グループの方針ですので、プライマリサーバとスタンバイサーバとの間でマイナーリリースレベルの違いがあってもうまく動作するはずです。
しかし、この場合、公的なサポートは提供されません。
できる限りプライマリサーバとスタンバイサーバとで同じリリースレベルを使用してください。
新しいマイナーリリースに更新する場合、もっとも安全な方針はスタンバイサーバを先に更新することです。
新しいマイナーリリースは以前のマイナーリリースのWALファイルを読み込むことはできますが、逆はできないかもしれません。
   </para>

  </sect2>

  <sect2 id="standby-server-operation" xreflabel="Standby Server Operation">
<!--
   <title>Standby Server Operation</title>
-->
   <title>スタンバイサーバの動作</title>

   <para>
    A server enters standby mode if a
    <anchor id="file-standby-signal" xreflabel="standby.signal"/>
    <filename>standby.signal</filename>
    <indexterm><primary><filename>standby.signal</filename></primary></indexterm>
    file exists in the data directory when the server is started.
   </para>

   <para>
<!--
    In standby mode, the server continuously applies WAL received from the
    primary server. The standby server can read WAL from a WAL archive
    (see <xref linkend="guc-restore-command"/>) or directly from the primary
    over a TCP connection (streaming replication). The standby server will
    also attempt to restore any WAL found in the standby cluster's
    <filename>pg_wal</filename> directory. That typically happens after a server
    restart, when the standby replays again WAL that was streamed from the
    primary before the restart, but you can also manually copy files to
    <filename>pg_wal</filename> at any time to have them replayed.
-->
スタンバイモードでは、サーバは継続的にマスタサーバから受け取ったWALを適用します。
スタンバイサーバはWALアーカイブ(<xref linkend="guc-restore-command"/>参照)から、または直接TCP接続(ストリーミングレプリケーション)を介してマスタサーバから、WALを読み取ることができます。
またスタンバイサーバはスタンバイクラスタの<filename>pg_wal</filename>ディレクトリにあるすべてのWALをリストアしようと試みます。
これはよくサーバの再起動後、スタンバイが再起動前にマスタから流れ込んだWALを再生する時に発生します。
しかしまたファイルを再生する任意の時点で、手作業で<filename>pg_wal</filename>にコピーすることもできます。
   </para>

   <para>
<!--
    At startup, the standby begins by restoring all WAL available in the
    archive location, calling <varname>restore_command</varname>. Once it
    reaches the end of WAL available there and <varname>restore_command</varname>
    fails, it tries to restore any WAL available in the <filename>pg_wal</filename> directory.
    If that fails, and streaming replication has been configured, the
    standby tries to connect to the primary server and start streaming WAL
    from the last valid record found in archive or <filename>pg_wal</filename>. If that fails
    or streaming replication is not configured, or if the connection is
    later disconnected, the standby goes back to step 1 and tries to
    restore the file from the archive again. This loop of retries from the
    archive, <filename>pg_wal</filename>, and via streaming replication goes on until the server
    is stopped or failover is triggered by a trigger file.
-->
起動時、スタンバイサーバは<varname>restore_command</varname>を呼び出して、アーカイブ場所にある利用可能なすべてのWALをリストアすることから始めます。
そこで利用可能なWALの終端に達し、<varname>restore_command</varname>が失敗すると、<filename>pg_wal</filename>ディレクトリにある利用可能な任意のWALのリストアを試みます。
ストリーミングレプリケーションが設定されている場合、これに失敗すると、スタンバイはプライマリサーバへの接続を試み、アーカイブまたは<filename>pg_wal</filename>内に存在した最終の有効レコードからWALのストリーミングを開始します。
ストリーミングレプリケーションが未設定時にこれに失敗する場合、または、接続が後で切断される場合、スタンバイは最初に戻り、アーカイブからのファイルのリストアを繰り返し行います。
このアーカイブ、<filename>pg_wal</filename>、ストリーミングレプリケーションからという再試行の繰り返しはサーバが停止する、あるいはトリガファイルによるフェイルオーバーが発行されるまで続きます。
   </para>

   <para>
<!--
    Standby mode is exited and the server switches to normal operation
    when <command>pg_ctl promote</command> is run,
    <function>pg_promote()</function> is called, or a trigger file is found
    (<varname>promote_trigger_file</varname>). Before failover,
    any WAL immediately available in the archive or in <filename>pg_wal</filename> will be
    restored, but no attempt is made to connect to the primary.
-->
<command>pg_ctl promote</command>が実行された時、<function>pg_promote()</function>が呼び出された時、またはトリガファイル(<varname>promote_trigger_file</varname>)が存在する時、スタンバイモードは終了し、サーバは通常の動作に切り替わります。
フェイルオーバーの前に、アーカイブまたは<filename>pg_wal</filename>内の即座に利用可能なWALをすべてリストアします。
しかし、マスタへの接続を行おうとはしません。
   </para>
  </sect2>

  <sect2 id="preparing-primary-for-standby">
<!--
   <title>Preparing the Primary for Standby Servers</title>
-->
   <title>スタンバイサーバのためのマスタの準備</title>

   <para>
<!--
    Set up continuous archiving on the primary to an archive directory
    accessible from the standby, as described
    in <xref linkend="continuous-archiving"/>. The archive location should be
    accessible from the standby even when the primary is down, i.e., it should
    reside on the standby server itself or another trusted server, not on
    the primary server.
-->
<xref linkend="continuous-archiving"/>で説明したように、スタンバイからアクセス可能なアーカイブディレクトリに対してプライマリで継続的なアーカイブを設定してください。
このアーカイブ場所はマスタが停止した時であってもスタンバイからアクセス可能でなければなりません。
つまり、マスタサーバ上ではなく、スタンバイサーバ自身上に存在するか、または他の高信頼性サーバ上に存在しなければなりません。
   </para>

   <para>
<!--
    If you want to use streaming replication, set up authentication on the
    primary server to allow replication connections from the standby
    server(s); that is, create a role and provide a suitable entry or
    entries in <filename>pg_hba.conf</filename> with the database field set to
    <literal>replication</literal>.  Also ensure <varname>max_wal_senders</varname> is set
    to a sufficiently large value in the configuration file of the primary
    server. If replication slots will be used,
    ensure that <varname>max_replication_slots</varname> is set sufficiently
    high as well.
-->
ストリーミングレプリケーションを使用したい場合、スタンバイサーバ(複数可)からのレプリケーション接続を受け付けるようにプライマリサーバで認証を設定してください。
つまり、ロールを作成し適切な項目を提供、あるいは、そのデータベースフィールドとして<literal>replication</literal>を持つ項目を<filename>pg_hba.conf</filename>内に設定してください。
また、プライマリサーバの設定ファイルにおいて<varname>max_wal_senders</varname>が十分大きな値に設定されていることを確認してください。
レプリケーションスロットを使用している場合は、<varname>max_replication_slots</varname>も十分に設定されているか確認してください。
   </para>

   <para>
<!--
    Take a base backup as described in <xref linkend="backup-base-backup"/>
    to bootstrap the standby server.
-->
<xref linkend="backup-base-backup"/>に記述したように、スタンバイサーバの再起動のために、ベースバックアップを取得してください。
   </para>
  </sect2>

  <sect2 id="standby-server-setup">
<!--
   <title>Setting Up a Standby Server</title>
-->
   <title>スタンバイサーバの設定</title>

   <para>
<!--
    To set up the standby server, restore the base backup taken from primary
    server (see <xref linkend="backup-pitr-recovery"/>). Create a file
    <link linkend="file-standby-signal"><filename>standby.signal</filename></link><indexterm><primary>standby.signal</primary></indexterm>
    in the standby's cluster data
    directory. Set <xref linkend="guc-restore-command"/> to a simple command to copy files from
    the WAL archive. If you plan to have multiple standby servers for high
    availability purposes, make sure that <varname>recovery_target_timeline</varname> is set to
    <literal>latest</literal> (the default), to make the standby server follow the timeline change
    that occurs at failover to another standby.
-->
スタンバイサーバを設定するためには、プライマリサーバから取得したベースバックアップをリストアしてください(<xref linkend="backup-pitr-recovery"/>参照)。
スタンバイのクラスタデータディレクトリ内に<filename>standby.signal</filename>ファイルを作成し、<varname>standby_mode</varname>を有効にしてください。
WALアーカイブからファイルをコピーする簡単なコマンドを<xref linkend="guc-restore-command"/>に設定してください。
高可用性のために複数のスタンバイサーバを持たせようとしている場合、<varname>recovery_target_timeline</varname>を<literal>latest</literal>に設定し（デフォルト）、スタンバイサーバが他のスタンバイにフェイルオーバーする時に発生するタイムラインの変更に従うようにします。
   </para>

   <note>
     <para>
     <xref linkend="guc-restore-command"/> should return immediately
     if the file does not exist; the server will retry the command again if
     necessary.
    </para>
   </note>

   <para>
<!--
     If you want to use streaming replication, fill in
     <xref linkend="guc-primary-conninfo"/> with a libpq connection string, including
     the host name (or IP address) and any additional details needed to
     connect to the primary server. If the primary needs a password for
     authentication, the password needs to be specified in
     <xref linkend="guc-primary-conninfo"/> as well.
-->
ストリーミングレプリケーションを使用したい場合には、ホスト名(またはIPアドレス)とプライマリサーバとの接続に必要な追加情報を含む、libpq接続文字列で<xref linkend="guc-primary-conninfo"/>を記述してください。
プライマリで認証用のパスワードが必要な場合は<xref linkend="guc-primary-conninfo"/>にそのパスワードも指定する必要があります。
   </para>

   <para>
<!--
    If you're setting up the standby server for high availability purposes,
    set up WAL archiving, connections and authentication like the primary
    server, because the standby server will work as a primary server after
    failover.
-->
スタンバイサーバを高可用性を目的に設定しているのであれば、スタンバイサーバはフェイルオーバーの後プライマリサーバとして動作しますので、プライマリサーバと同様にWALアーカイブ処理、接続、認証を設定してください。
   </para>

   <para>
<!--
    If you're using a WAL archive, its size can be minimized using the <xref
    linkend="guc-archive-cleanup-command"/> parameter to remove files that are no
    longer required by the standby server.
    The <application>pg_archivecleanup</application> utility is designed specifically to
    be used with <varname>archive_cleanup_command</varname> in typical single-standby
    configurations, see <xref linkend="pgarchivecleanup"/>.
    Note however, that if you're using the archive for backup purposes, you
    need to retain files needed to recover from at least the latest base
    backup, even if they're no longer needed by the standby.
-->
WALアーカイブを使用している場合、<xref linkend="guc-archive-cleanup-command"/>パラメータを使用してスタンバイサーバで不要となったファイルを削除することで、その容量を最小化することができます。
特に<application>pg_archivecleanup</application>ユーティリティは、典型的な単一スタンバイ構成（<xref linkend="pgarchivecleanup"/>参照）における<varname>archive_cleanup_command</varname>と共に使用されるように設計されています。
しかし、バックアップを目的にアーカイブを使用している場合には、スタンバイから必要とされなくなったファイルであっても、最新のベースバックアップの時点からリカバリするために必要なファイルを保持しなければならないことに注意してください。
   </para>

   <para>
<!--
    A simple example of configuration is:
-->
簡単な設定例を以下に示します。
<programlisting>
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass options=''-c wal_sender_timeout=5000'''
restore_command = 'cp /path/to/archive/%f %p'
archive_cleanup_command = 'pg_archivecleanup /path/to/archive %r'
</programlisting>
   </para>

   <para>
<!--
    You can have any number of standby servers, but if you use streaming
    replication, make sure you set <varname>max_wal_senders</varname> high enough in
    the primary to allow them to be connected simultaneously.
-->
スタンバイサーバの台数に制限はありませんが、ストリーミングレプリケーションを使用するなら、プライマリサーバに同時に接続できるように<varname>max_wal_senders</varname>を十分な数に設定してください。
   </para>

  </sect2>

  <sect2 id="streaming-replication">
<!--
   <title>Streaming Replication</title>
-->
   <title>ストリーミングレプリケーション</title>

   <indexterm zone="high-availability">
<!--
    <primary>Streaming Replication</primary>
-->
    <primary>ストリーミングレプリケーション</primary>
   </indexterm>

   <para>
<!--
    Streaming replication allows a standby server to stay more up-to-date
    than is possible with file-based log shipping. The standby connects
    to the primary, which streams WAL records to the standby as they're
    generated, without waiting for the WAL file to be filled.
-->
ストリーミングレプリケーションによりスタンバイサーバはファイルベースのログシッピングよりもより最近の状態を維持できるようになります。
スタンバイは、WALレコードが生成された時にWALファイルがいっぱいになるまで待機せずにWALレコードをスタンバイに流し出すプライマリと接続します。
   </para>

   <para>
<!--
    Streaming replication is asynchronous by default
    (see <xref linkend="synchronous-replication"/>), in which case there is
    a small delay between committing a transaction in the primary and the
    changes becoming visible in the standby. This delay is however much
    smaller than with file-based log shipping, typically under one second
    assuming the standby is powerful enough to keep up with the load. With
    streaming replication, <varname>archive_timeout</varname> is not required to
    reduce the data loss window.
-->
ストリーミングレプリケーションはデフォルトで非同期で、(<xref linkend="synchronous-replication"/>参照)
この場合、プライマリでトランザクションがコミットされてから、その変更がスタンバイ側で参照可能になるまでの間にわずかな遅延がまだあります。
しかし、この遅延はファイルベースのログシッピングよりも非常に小さなもので、負荷に追随できる程度の能力があるスタンバイであれば通常は1秒以下です。
ストリーミングレプリケーションでは、データ損失期間を減らすための<varname>archive_timeout</varname>を必要としません。
   </para>

   <para>
<!--
    If you use streaming replication without file-based continuous
    archiving, the server might recycle old WAL segments before the standby
    has received them.  If this occurs, the standby will need to be
    reinitialized from a new base backup.  You can avoid this by setting
    <varname>wal_keep_size</varname> to a value large enough to ensure that
    WAL segments are not recycled too early, or by configuring a replication
    slot for the standby.  If you set up a WAL archive that's accessible from
    the standby, these solutions are not required, since the standby can
    always use the archive to catch up provided it retains enough segments.
-->
ファイルベースの継続的アーカイブのないストリーミングレプリケーションを使用している場合、スタンバイが受け取る前に古いWALセグメントを再利用するかもしれません。
もし、そうなった場合はスタンバイは新しいベースバックアップから再作成しなければならなくなります。
<varname>wal_keep_size</varname>を十分に大きくしたり、レプリケーションスロットにスタンバイを設定することでWALセグメントがすぐに再利用されることを防ぎ、これを防ぐことができます。WALアーカイブをスタンバイからアクセスできる位置に設定する場合は、スタンバイが常にWALセグメントを追随することができるため、これらの解決策は要求されません。
   </para>

   <para>
<!--
    To use streaming replication, set up a file-based log-shipping standby
    server as described in <xref linkend="warm-standby"/>. The step that
    turns a file-based log-shipping standby into streaming replication
    standby is setting the <varname>primary_conninfo</varname> setting
    to point to the primary server. Set
    <xref linkend="guc-listen-addresses"/> and authentication options
    (see <filename>pg_hba.conf</filename>) on the primary so that the standby server
    can connect to the <literal>replication</literal> pseudo-database on the primary
    server (see <xref linkend="streaming-replication-authentication"/>).
-->
ストリーミングレプリケーションを使用するためには、<xref linkend="warm-standby"/>の説明のようにファイルベースのログシッピングを行うスタンバイサーバを設定してください。
ファイルベースのログシッピングを行うスタンバイをストリーミングレプリケーションを行うスタンバイに切り替える手順は、<varname>primary_conninfo</varname>設定をプライマリサーバを指し示すように設定することです。
スタンバイサーバがプライマリサーバ上の<literal>replication</literal>疑似データベースに接続できる(<xref linkend="streaming-replication-authentication"/>参照)ように、プライマリで<xref linkend="guc-listen-addresses"/>と認証オプション(<filename>pg_hba.conf</filename>参照)を設定してください。
   </para>

   <para>
<!--
    On systems that support the keepalive socket option, setting
    <xref linkend="guc-tcp-keepalives-idle"/>,
    <xref linkend="guc-tcp-keepalives-interval"/> and
    <xref linkend="guc-tcp-keepalives-count"/> helps the primary promptly
    notice a broken connection.
-->
キープアライブソケットオプションをサポートするシステムでは、<xref linkend="guc-tcp-keepalives-idle"/>、<xref linkend="guc-tcp-keepalives-interval"/>および<xref linkend="guc-tcp-keepalives-count"/>を設定することで、プライマリの接続切断の即時検知に有用です。
   </para>

   <para>
<!--
    Set the maximum number of concurrent connections from the standby servers
    (see <xref linkend="guc-max-wal-senders"/> for details).
-->
スタンバイサーバからの同時接続数の最大値を設定してください（詳細は<xref linkend="guc-max-wal-senders"/>を参照）。
   </para>

   <para>
<!--
    When the standby is started and <varname>primary_conninfo</varname> is set
    correctly, the standby will connect to the primary after replaying all
    WAL files available in the archive. If the connection is established
    successfully, you will see a <literal>walreceiver</literal> in the standby, and
    a corresponding <literal>walsender</literal> process in the primary.
-->
スタンバイが起動し、<varname>primary_conninfo</varname>が正しく設定されると、スタンバイはアーカイブ内で利用可能なWALファイルをすべて再生した後にプライマリと接続します。
接続の確立に成功すると、スタンバイで<literal>walreceiver</literal>が存在し、プライマリで対応する<literal>walsender</literal>が存在します。
   </para>

   <sect3 id="streaming-replication-authentication">
<!--
    <title>Authentication</title>
-->
    <title>認証</title>
    <para>
<!--
     It is very important that the access privileges for replication be set up
     so that only trusted users can read the WAL stream, because it is
     easy to extract privileged information from it.  Standby servers must
     authenticate to the primary as an account that has the
     <literal>REPLICATION</literal> privilege or a superuser. It is
     recommended to create a dedicated user account with
     <literal>REPLICATION</literal> and <literal>LOGIN</literal>
     privileges for replication. While <literal>REPLICATION</literal>
     privilege gives very high permissions, it does not allow the user to
     modify any data on the primary system, which the
     <literal>SUPERUSER</literal> privilege does.
-->
信頼できるユーザのみがWALストリームを読み取ることができるように、レプリケーション用のアクセス権限を設定することは非常に重要です。
WALから機密情報を取り出すことは簡単だからです。
スタンバイサーバはプライマリに対してプライマリの<literal>REPLICATION</literal>権限を持つアカウントか、スーパーユーザとして認証されなければなりません。
レプリケーションのための<literal>REPLICATION</literal>権限 と <literal>LOGIN</literal>権限を持つ専用のユーザを作成することをお勧めします。
<literal>REPLICATION</literal>権限は非常に強力な権限なので、<literal>SUPERUSER</literal>のようにプライマリのデータを変更することを許可されていません。
    </para>

    <para>
<!--
     Client authentication for replication is controlled by a
     <filename>pg_hba.conf</filename> record specifying <literal>replication</literal> in the
     <replaceable>database</replaceable> field. For example, if the standby is running on
     host IP <literal>192.168.1.100</literal> and the account name for replication
     is <literal>foo</literal>, the administrator can add the following line to the
     <filename>pg_hba.conf</filename> file on the primary:
-->
レプリケーション用のクライアント認証は<filename>pg_hba.conf</filename>内でその<replaceable>database</replaceable>フィールドに<literal>replication</literal>を指定したレコードで制御されます。
例えば、スタンバイがIPアドレス<literal>192.168.1.100</literal>のホストで稼動し、レプリケーション用のアカウントの名前が<literal>foo</literal>である場合、管理者はプライマリ上の<filename>pg_hba.conf</filename>に以下の行を追加することができます。

<programlisting>
<!--
# Allow the user "foo" from host 192.168.1.100 to connect to the primary
# as a replication standby if the user's password is correctly supplied.
-->
# 利用者 foo のホスト 192.168.1.100 からプライマリサーバへのレプリケーションスタンバイとしての接続を
# 利用者のパスワードが正しく入力されたならば許可する
#
# TYPE  DATABASE        USER            ADDRESS                 METHOD
host    replication     foo             192.168.1.100/32        md5
</programlisting>
    </para>
    <para>
<!--
     The host name and port number of the primary, connection user name,
     and password are specified in the <xref linkend="guc-primary-conninfo"/>.
     The password can also be set in the <filename>~/.pgpass</filename> file on the
     standby (specify <literal>replication</literal> in the <replaceable>database</replaceable>
     field).
     For example, if the primary is running on host IP <literal>192.168.1.50</literal>,
     port <literal>5432</literal>, the account name for replication is
     <literal>foo</literal>, and the password is <literal>foopass</literal>, the administrator
     can add the following line to the <filename>postgresql.conf</filename> file on the
     standby:
-->
プライマリサーバのホスト名とポート番号、接続する利用者名およびパスワードは、<xref linkend="guc-primary-conninfo"/>で指定します。
パスワードはスタンバイサーバの<filename>~/.pgpass</filename>ファイルでも設定できます（<replaceable>database</replaceable>フィールドの<literal>replication</literal>を指定します）。
例えば、プライマリサーバが稼動するホストの IP アドレスが<literal>192.168.1.50</literal>でポート番号が<literal>5432</literal>であり、レプリケーションのアカウント名が<literal>foo</literal>であり、パスワードが<literal>foopass</literal>である場合、管理者はスタンバイサーバの<filename>postgresql.conf</filename>ファイルに次行を追加できます。

<programlisting>
<!--
# The standby connects to the primary that is running on host 192.168.1.50
# and port 5432 as the user "foo" whose password is "foopass".
-->
# プライマリサーバが 192.168.1.50 のホストの 5432ポートで稼動し
# 利用者名が foo でパスワードが foopass とする
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'
</programlisting>
    </para>
   </sect3>

   <sect3 id="streaming-replication-monitoring">
<!--
    <title>Monitoring</title>
-->
    <title>監視</title>
    <para>
<!--
     An important health indicator of streaming replication is the amount
     of WAL records generated in the primary, but not yet applied in the
     standby. You can calculate this lag by comparing the current WAL write
     location on the primary with the last WAL location received by the
     standby. These locations can be retrieved using
     <function>pg_current_wal_lsn</function> on the primary and
     <function>pg_last_wal_receive_lsn</function> on the standby,
     respectively (see <xref linkend="functions-admin-backup-table"/> and
     <xref linkend="functions-recovery-info-table"/> for details).
     The last WAL receive location in the standby is also displayed in the
     process status of the WAL receiver process, displayed using the
     <command>ps</command> command (see <xref linkend="monitoring-ps"/> for details).
-->
ストリーミングレプリケーションの重要な健全性尺度は、プライマリサーバで生成されたがスタンバイサーバではまだ適用されていないWALレコードの量です。
プライマリサーバの現在のWAL書き込み位置とスタンバイサーバの受理したWALの最終位置を比較すれば、この遅延を計算できます。
これらの位置は、プライマリサーバでは<function>pg_current_wal_lsn</function>を、スタンバイサーバでは<function>pg_last_wal_receive_lsn</function>を使用すれば検索できます（詳細は<xref linkend="functions-admin-backup-table"/>および<xref linkend="functions-recovery-info-table"/>を参照）。
スタンバイサーバの最終位置は、<command>ps</command>コマンドを使用して WAL受信プロセスの状態としても表示できます（詳細は<xref linkend="monitoring-ps"/>を参照）。
    </para>
    <para>
<!--
     You can retrieve a list of WAL sender processes via the
     <link linkend="monitoring-pg-stat-replication-view"><structname>
     pg_stat_replication</structname></link> view. Large differences between
     <function>pg_current_wal_lsn</function> and the view's <literal>sent_lsn</literal> field
     might indicate that the primary server is under heavy load, while
     differences between <literal>sent_lsn</literal> and
     <function>pg_last_wal_receive_lsn</function> on the standby might indicate
     network delay, or that the standby is under heavy load.
-->
<link linkend="monitoring-pg-stat-replication-view"><structname>pg_stat_replication</structname></link>ビューを介してWAL送信処理プロセスのリストを入手することができます。
<function>pg_current_wal_lsn</function>とビューの<literal>sent_lsn</literal>フィールドとの違いが大きい場合、マスタサーバが高負荷状態であることを示している可能性があります。
一方でスタンバイサーバ上の<literal>sent_lsn</literal>と<function>pg_last_wal_receive_lsn</function>の値の差異は、ネットワーク遅延、またはスタンバイが高負荷状態であることを示す可能性があります。
    </para>
    <para>
<!--
     On a hot standby, the status of the WAL receiver process can be retrieved
     via the <link linkend="monitoring-pg-stat-wal-receiver-view">
     <structname>pg_stat_wal_receiver</structname></link> view.  A large
     difference between <function>pg_last_wal_replay_lsn</function> and the
     view's <literal>flushed_lsn</literal> indicates that WAL is being
     received faster than it can be replayed.
-->
ホットスタンバイ上では、WAL受信プロセスの状態は、<link linkend="monitoring-pg-stat-wal-receiver-view"><structname>pg_stat_wal_receiver</structname></link>ビューを通じて入手することができます。
<function>pg_last_wal_replay_lsn</function>とビューの<literal>received_lsn</literal>との違いが大きい場合、WALのリプレイを上回る速さでWALが受信されていることを示しています。
    </para>
   </sect3>
  </sect2>

  <sect2 id="streaming-replication-slots">
<!--
   <title>Replication Slots</title>
-->
   <title>レプリケーションスロット</title>
   <indexterm>
<!--
    <primary>replication slot</primary>
    <secondary>streaming replication</secondary>
-->
    <primary>レプリケーションスロット</primary>
    <secondary>ストリーミングレプリケーション</secondary>
   </indexterm>
   <para>
<!--
    Replication slots provide an automated way to ensure that the primary does
    not remove WAL segments until they have been received by all standbys,
    and that the primary does not remove rows which could cause a
    <link linkend="hot-standby-conflict">recovery conflict</link> even when the
    standby is disconnected.
-->
レプリケーションスロットは、以下のことを保証する自動的な方法を提供します。
全てのスタンバイがWALセグメントを受け取るまでは、マスターがWALセグメントを削除しないこと、また、スタンバイが接続していない際にも、<link linkend="hot-standby-conflict">リカバリの競合</link>が発生する可能性がある行をマスターが削除しないこと、です。
   </para>
   <para>
<!--
    In lieu of using replication slots, it is possible to prevent the removal
    of old WAL segments using <xref linkend="guc-wal-keep-size"/>, or by
    storing the segments in an archive using
    <xref linkend="guc-archive-command"/>.
    However, these methods often result in retaining more WAL segments than
    required, whereas replication slots retain only the number of segments
    known to be needed.  On the other hand, replication slots can retain so
    many WAL segments that they fill up the space allocated
    for <literal>pg_wal</literal>;
    <xref linkend="guc-max-slot-wal-keep-size"/> limits the size of WAL files
    retained by replication slots.
-->
レプリケーションスロットを使う代わりに、<xref linkend="guc-wal-keep-size"/>を使う、あるいは<xref linkend="guc-archive-command"/>を使用してセグメントをアーカイブに保存することによっても、古いWALセグメントの削除を防ぐことができます。
しかし、これらの方法はしばしば要求される以上のWALセグメントを残すことになってしまうのに対し、レプリケーションスロットは必要と判断されたセグメントのみを残します。
一方で、レプリケーションスロットは<literal>pg_wal</literal>のための領域を埋め尽くす大量のWALセグメントを残してしまうかも知れません。
これらの方法のメリットの一つは<literal>pg_wal</literal>が要求する領域を制限できることです。現時点でレプリケーションスロットを使って同じことをする方法はありません。
   </para>
   <para>
<!--
    Similarly, <xref linkend="guc-hot-standby-feedback"/>
    and <xref linkend="guc-vacuum-defer-cleanup-age"/> provide protection against
    relevant rows being removed by vacuum, but the former provides no
    protection during any time period when the standby is not connected,
    and the latter often needs to be set to a high value to provide adequate
    protection.  Replication slots overcome these disadvantages.
-->
同様に、<xref linkend="guc-hot-standby-feedback"/>と<xref linkend="guc-vacuum-defer-cleanup-age"/>は必要な行をvacuumが削除するのを防ぐ機能を提供しますが、前者はスタンバイが接続されていない間は行の保護を提供しませんし、後者は適切な保護を提供するために高い値を設定せざるを得ないことがしばしばあります。
レプリケーションスロットはこのような短所を克服しています。
   </para>
   <sect3 id="streaming-replication-slots-manipulation">
<!--
    <title>Querying and Manipulating Replication Slots</title>
-->
    <title>レプリケーションスロットへの問い合わせと操作</title>
    <para>
<!--
     Each replication slot has a name, which can contain lower-case letters,
     numbers, and the underscore character.
-->
いずれのレプリケーションスロットにも小文字、数字、アンダースコアを含む名前があります。
    </para>
    <para>
<!--
     Existing replication slots and their state can be seen in the
     <link linkend="view-pg-replication-slots"><structname>pg_replication_slots</structname></link>
     view.
-->
レプリケーションスロットとその状態は<link linkend="view-pg-replication-slots"><structname>pg_replication_slots</structname></link>
ビューより確認できます。
    </para>
    <para>
<!--
     Slots can be created and dropped either via the streaming replication
     protocol (see <xref linkend="protocol-replication"/>) or via SQL
     functions (see <xref linkend="functions-replication"/>).
-->
レプリケーションスロットはストリーミングレプリケーションプロトコル( <xref linkend="protocol-replication"/>参照)もしくはSQL関数(<xref linkend="functions-replication"/>参照)を使用し、作成や削除ができます。
    </para>
   </sect3>
   <sect3 id="streaming-replication-slots-config">
<!--
    <title>Configuration Example</title>
-->
    <title>設定の例</title>
    <para>
<!--
     You can create a replication slot like this:
-->
以下のような方法でレプリケーションスロットを作成できます。
<programlisting>
postgres=# SELECT * FROM pg_create_physical_replication_slot('node_a_slot');
  slot_name  | lsn
-------------+-----
 node_a_slot |

postgres=# SELECT slot_name, slot_type, active FROM pg_replication_slots;
  slot_name  | slot_type | active 
-------------+-----------+--------
 node_a_slot | physical  | f
(1 row)
</programlisting>
<!--
     To configure the standby to use this slot, <varname>primary_slot_name</varname>
     should be configured on the standby. Here is a simple example:
-->
スタンバイのレプリケーションスロットを使用できるように設定するためには、<varname>primary_slot_name</varname>をスタンバイ側で設定します。
以下は単純な設定例です。：
<programlisting>
primary_conninfo = 'host=192.168.1.50 port=5432 user=foo password=foopass'
primary_slot_name = 'node_a_slot'
</programlisting>
    </para>
   </sect3>
  </sect2>

  <sect2 id="cascading-replication">
<!--
   <title>Cascading Replication</title>
-->
   <title>カスケードレプリケーション</title>

   <indexterm zone="high-availability">
<!--
    <primary>Cascading Replication</primary>
-->
    <primary>カスケードレプリケーション</primary>
   </indexterm>

   <para>
<!--
    The cascading replication feature allows a standby server to accept replication
    connections and stream WAL records to other standbys, acting as a relay.
    This can be used to reduce the number of direct connections to the primary
    and also to minimize inter-site bandwidth overheads.
-->
カスケードレプリケーションは、リレーのような振る舞い、つまり、スタンバイサーバから他のスタンバイにレプリケーション接続し、WALレコードを送信することができます。
マスターサーバへ直接の接続を減らしたり、サイト相互の帯域オーバヘッドを最小化するために使用することができます。
   </para>

   <para>
<!--
    A standby acting as both a receiver and a sender is known as a cascading
    standby.  Standbys that are more directly connected to the primary are known
    as upstream servers, while those standby servers further away are downstream
    servers.  Cascading replication does not place limits on the number or
    arrangement of downstream servers, though each standby connects to only
    one upstream server which eventually links to a single primary server.
-->
カスケードスタンバイとして知られているとおり、スタンバイは受け取り手としても送り手としても振る舞うことができます。
よりマスターサーバに近いスタンバイサーバは上流サーバと呼ばれるのに対し、より遠いスタンバイサーバは下流サーバと呼ばれます。
カスケードレプリケーションには下流サーバの数に制限は設定されていません。しかし、どのスタンバイサーバも最終的には1つのマスター/プライマリサーバに繋がる1つの上流サーバに接続します。
   </para>

   <para>
<!--
    A cascading standby sends not only WAL records received from the
    primary but also those restored from the archive. So even if the replication
    connection in some upstream connection is terminated, streaming replication
    continues downstream for as long as new WAL records are available.
-->
カスケードスタンバイはマスターから受け取ったWALレコードだけでなく、アーカイブからリストアしたWALレコードも送信します。
このため、レプリケーション接続が上流サーバで切断しても、ストリーミングレプリケーションは下流サーバへ新しいWAL
レコードがある限り継続します。
   </para>

   <para>
<!--
    Cascading replication is currently asynchronous. Synchronous replication
    (see <xref linkend="synchronous-replication"/>) settings have no effect on
    cascading replication at present.
-->
カスケードレプリケーションは現時点では非同期です。同期レプリケーション（参照<xref linkend="synchronous-replication"/>）の設定は現時点でカスケードレプリケーションへは影響を与えません。
   </para>

   <para>
<!--
    Hot Standby feedback propagates upstream, whatever the cascaded arrangement.
-->
ホットスタンバイがどの様に配置されていても、ホットスタンバイフィードバックは上流に伝播します。
   </para>

   <para>
<!--
    If an upstream standby server is promoted to become the new primary, downstream
    servers will continue to stream from the new primary if
    <varname>recovery_target_timeline</varname> is set to <literal>'latest'</literal> (the default).
-->
上流スタンバイサーバが昇格し、新しいマスターサーバになった場合、<varname>recovery_target_timeline</varname>が<literal>'latest'</literal>に設定されていれば、下流サーバは新マスターサーバからのストリーミングレプリケーションを継続します（デフォルトです）。
   </para>

   <para>
<!--
    To use cascading replication, set up the cascading standby so that it can
    accept replication connections (that is, set
    <xref linkend="guc-max-wal-senders"/> and <xref linkend="guc-hot-standby"/>,
    and configure
    <link linkend="auth-pg-hba-conf">host-based authentication</link>).
    You will also need to set <varname>primary_conninfo</varname> in the downstream
    standby to point to the cascading standby.
-->
カスケードレプリケーションを使うためには、カスケードスタンバイをセットアップ、つまり、レプリケーション接続を許可してください。(<xref linkend="guc-max-wal-senders"/>と<xref linkend="guc-hot-standby"/>および、 <link linkend="auth-pg-hba-conf">クライアント認証</link>を設定してください)
また、下流スタンバイがカスケードスタンバイに接続できるために、下流スタンバイでは<varname>primary_conninfo</varname>を設定する必要があります。
   </para>
  </sect2>

  <sect2 id="synchronous-replication">
<!--
   <title>Synchronous Replication</title>
-->
   <title>同期レプリケーション</title>

   <indexterm zone="high-availability">
<!--
    <primary>Synchronous Replication</primary>
-->
    <primary>同期レプリケーション</primary>
   </indexterm>

   <para>
<!--
    <productname>PostgreSQL</productname> streaming replication is asynchronous by
    default. If the primary server
    crashes then some transactions that were committed may not have been
    replicated to the standby server, causing data loss. The amount
    of data loss is proportional to the replication delay at the time of
    failover.
-->
<productname>PostgreSQL</productname>のストリーミングレプリケーションはデフォルトで非同期です。
プライマリサーバがクラッシュした場合、コミットされた一部のトランザクションがスタンバイサーバに複製されず、データ損失を引き起こす可能性があります。
データ損失量はフェイルオーバー時点のレプリケーション遅延に比例します。
   </para>

   <para>
<!--
    Synchronous replication offers the ability to confirm that all changes
    made by a transaction have been transferred to one or more synchronous
    standby servers. This extends that standard level of durability
    offered by a transaction commit. This level of protection is referred
    to as 2-safe replication in computer science theory, and group-1-safe
    (group-safe and 1-safe) when <varname>synchronous_commit</varname> is set to
    <literal>remote_write</literal>.
-->
同期レプリケーションは、あるトランザクションでなされた変更はすべて、１つ以上の同期スタンバイサーバに転送されていることを確実にする機能を提供します。
これはトランザクションコミットで提供される永続性の標準レベルを拡張します。
この保護レベルはコンピュータ科学理論では、2-safeレプリケーション、そして<varname>synchronous_commit</varname>が<literal>remote_write</literal>に設定されている場合にはgroup-1-safe (group-safeと1-safe) と呼ばれます。
   </para>

   <para>
<!--
    When requesting synchronous replication, each commit of a
    write transaction will wait until confirmation is
    received that the commit has been written to the write-ahead log on disk
    of both the primary and standby server. The only possibility that data
    can be lost is if both the primary and the standby suffer crashes at the
    same time. This can provide a much higher level of durability, though only
    if the sysadmin is cautious about the placement and management of the two
    servers.  Waiting for confirmation increases the user's confidence that the
    changes will not be lost in the event of server crashes but it also
    necessarily increases the response time for the requesting transaction.
    The minimum wait time is the round-trip time between primary to standby.
-->
同期レプリケーションを要求する時、書き込みトランザクションのコミットはそれぞれ、そのコミットがプライマリサーバおよびスタンバイサーバの両方で、ディスク上の書き込み先行ログに書き込まれたという確認を受けとるまで待機します。
データ損失が起こる可能性は、プライマリサーバとスタンバイサーバが同時にクラッシュしてしまった場合のみです。
これは非常に高い永続性を提供することができますが、それはシステム管理者が２つのサーバの設置と管理に関して注意を払っている場合のみです。
確認のための待機は、サーバがクラッシュした場合でも変更が失われないということでユーザからの信頼性が大きくなりますが、同時に要求するトランザクションの応答時間も必ず大きくなります。
最小待機時間はプライマリとスタンバイの間の往復遅延時間です。
   </para>

   <para>
<!--
    Read-only transactions and transaction rollbacks need not wait for
    replies from standby servers. Subtransaction commits do not wait for
    responses from standby servers, only top-level commits. Long
    running actions such as data loading or index building do not wait
    until the very final commit message. All two-phase commit actions
    require commit waits, including both prepare and commit.
-->
読み取り専用のトランザクションおよびトランザクションのロールバックはスタンバイサーバからの応答を待つ必要はありません。
副トランザクションのコミットもスタンバイサーバからの応答を待つことはなく、最上位レベルのコミットのみ待機します。
データロード処理やインデックス構築など長時間実行される操作は、最終コミットメッセージまで待機しません。
準備およびコミットの両方を含め、二相コミット動作はすべてコミット待機を必要とします。
   </para>

   <para>
<!--
    A synchronous standby can be a physical replication standby or a logical
    replication subscriber.  It can also be any other physical or logical WAL
    replication stream consumer that knows how to send the appropriate
    feedback messages.  Besides the built-in physical and logical replication
    systems, this includes special programs such
    as <command>pg_receivewal</command> and <command>pg_recvlogical</command>
    as well as some third-party replication systems and custom programs.
    Check the respective documentation for details on synchronous replication
    support.
-->
同期スタンバイは、物理レプリケーションのスタンバイでも、論理レプリケーションのサブスクライバーのどちらでも構いません。
また同期スタンバイは、適切なフィードバックメッセージを送信する方法を知っている、物理あるいは論理WALレプリケーションストリームの消費者であっても構いません。
組み込みの物理あるいは論理レプリケーションシステムを別にすると、<command>pg_receivewal</command>と<command>pg_recvlogical</command>、それにサードパーティーのレプリケーションシステムとカスタムプログラムが該当します。
対応する同期レプリケーションのサポートの詳細に関するドキュメントを参照してください。
   </para>

   <sect3 id="synchronous-replication-config">
<!--
    <title>Basic Configuration</title>
-->
    <title>基本設定</title>

   <para>
<!--
    Once streaming replication has been configured, configuring synchronous
    replication requires only one additional configuration step:
    <xref linkend="guc-synchronous-standby-names"/> must be set to
    a non-empty value.  <varname>synchronous_commit</varname> must also be set to
    <literal>on</literal>, but since this is the default value, typically no change is
    required.  (See <xref linkend="runtime-config-wal-settings"/> and
    <xref linkend="runtime-config-replication-primary"/>.)
    This configuration will cause each commit to wait for
    confirmation that the standby has written the commit record to durable
    storage.
    <varname>synchronous_commit</varname> can be set by individual
    users, so it can be configured in the configuration file, for particular
    users or databases, or dynamically by applications, in order to control
    the durability guarantee on a per-transaction basis.
-->
一度、ストリーミングレプリケーションが設定されている場合、同期レプリケーションの設定には必要な追加設定は１つだけ：<xref linkend="guc-synchronous-standby-names"/>を空でない値に設定することです。
また<varname>synchronous_commit</varname>は<literal>on</literal>に設定されていなければなりませんが、これはデフォルト値ですので、通常は変更する必要はありません。(<xref linkend="runtime-config-wal-settings"/> および<xref linkend="runtime-config-replication-primary"/>を参照してください)
この設定によりスタンバイがそのコミットレコードを信頼できるストレージに書き込んだことが確認できるまで、各コミットが待たされるようになります。
<varname>synchronous_commit</varname>は個々のユーザによって設定することができます。
このため、トランザクション単位を基準とした永続性の保証を制御するために、設定ファイルの中で特定のユーザまたはデータベースについて設定することも、アプリケーションによって動的に設定することもできます。
   </para>

   <para>
<!--
    After a commit record has been written to disk on the primary, the
    WAL record is then sent to the standby. The standby sends reply
    messages each time a new batch of WAL data is written to disk, unless
    <varname>wal_receiver_status_interval</varname> is set to zero on the standby.
    In the case that <varname>synchronous_commit</varname> is set to
    <literal>remote_apply</literal>, the standby sends reply messages when the commit
    record is replayed, making the transaction visible.
    If the standby is chosen as a synchronous standby, according to the setting
    of <varname>synchronous_standby_names</varname> on the primary, the reply
    messages from that standby will be considered along with those from other
    synchronous standbys to decide when to release transactions waiting for
    confirmation that the commit record has been received. These parameters
    allow the administrator to specify which standby servers should be
    synchronous standbys. Note that the configuration of synchronous
    replication is mainly on the primary. Named standbys must be directly
    connected to the primary; the primary knows nothing about downstream
    standby servers using cascaded replication.
-->
コミットレコードがプライマリ上のディスクに書き出された後、WALレコードがスタンバイに送信されます。
スタンバイにて<varname>wal_receiver_status_interval</varname>がゼロに設定されていない限り、スタンバイは新しいWALデータの塊がディスクに書き出される度に応答メッセージを返します。
<varname>synchronous_commit</varname>が<literal>remote_apply</literal>に設定されている場合には、コミットレコードが再生され、そのトランザクションが可視化されたときに応答メッセージを返します。
スタンバイが、プライマリ上の<varname>synchronous_standby_names</varname>にしたがって、同期スタンバイとして選ばれた時は、コミットレコードの受領の確認のために待機しているトランザクションをいつ解放すべきかを決めるために、他の同期スタンバイとともにそれらスタンバイからの応答メッセージが考慮されます。
これらのパラメータにより、管理者はどのスタンバイサーバを同期スタンバイとすべきかを指定することができます。
同期レプリケーションの設定は主にマスタでなされることに注意してください。
指名されたスタンバイは直接マスターサーバに接続される必要があります。
つまり、カスケードレプリケーションを使用している下流スタンバイサーバについて、マスターサーバは何も知りません。
   </para>

   <para>
<!--
    Setting <varname>synchronous_commit</varname> to <literal>remote_write</literal> will
    cause each commit to wait for confirmation that the standby has received
    the commit record and written it out to its own operating system, but not
    for the data to be flushed to disk on the standby.  This
    setting provides a weaker guarantee of durability than <literal>on</literal>
    does: the standby could lose the data in the event of an operating system
    crash, though not a <productname>PostgreSQL</productname> crash.
    However, it's a useful setting in practice
    because it can decrease the response time for the transaction.
    Data loss could only occur if both the primary and the standby crash and
    the database of the primary gets corrupted at the same time.
-->
<varname>synchronous_commit</varname>を<literal>remote_write</literal>に設定することで、個々のコミットは、スタンバイサーバがコミットされたレコードを受け取り、オペレーティングシステムに書きだしたことが確認できるまで待ちますが、スタンバイ上のディスクに吐き出すまでは待ちません。
これは、<literal>on</literal>と設定するより、提供される永続性は弱くなります。
具体的には、スタンバイサーバはオペレーティングシステムがクラッシュした場合にデータを失う可能性がありますが、<productname>PostgreSQL</productname>がクラッシュした場合にはデータを失いません。
しかし、実用的にはこの設定はトランザクションの応答時間を短くすることができるので有用です。
データの損失は、プライマリサーバとスタンバイサーバが同時にクラッシュし、かつ、プライマリのデータベースが同時に壊れた場合にのみ発生します。
   </para>

   <para>
<!--
    Setting <varname>synchronous_commit</varname> to <literal>remote_apply</literal> will
    cause each commit to wait until the current synchronous standbys report
    that they have replayed the transaction, making it visible to user
    queries.  In simple cases, this allows for load balancing with causal
    consistency.
-->
<varname>synchronous_commit</varname>を<literal>remote_apply</literal>に設定することで、現在の同期スタンバイがトランザクションを再生し、ユーザから見えるようにしたと報告するまでは各々のコミットは待たされます。
単純なケースでは、因果一貫性を保つ負荷分散を可能にします。
   </para>

   <para>
<!--
    Users will stop waiting if a fast shutdown is requested.  However, as
    when using asynchronous replication, the server will not fully
    shutdown until all outstanding WAL records are transferred to the currently
    connected standby servers.
-->
高速シャットダウンが要求された場合、ユーザは待ち状態ではなくなります。
しかし非同期レプリケーションを使用している時と同じく、送信中のWALレコードが現在接続しているスタンバイサーバに転送されるまで、サーバは完全に停止しません。
   </para>

   </sect3>

   <sect3 id="synchronous-replication-multiple-standbys">
<!--
    <title>Multiple Synchronous Standbys</title>
-->
    <title>複数の同期スタンバイ</title>

   <para>
<!--
    Synchronous replication supports one or more synchronous standby servers;
    transactions will wait until all the standby servers which are considered
    as synchronous confirm receipt of their data. The number of synchronous
    standbys that transactions must wait for replies from is specified in
    <varname>synchronous_standby_names</varname>. This parameter also specifies
    a list of standby names and the method (<literal>FIRST</literal> and
    <literal>ANY</literal>) to choose synchronous standbys from the listed ones.
-->
同期レプリケーションは、一つ以上の同期スタンバイサーバをサポートします。
同期と見なされるすべてのスタンバイサーバがデータの受領を確認するまで、トランザクションは待機します。
トランザクションが応答を待たなければならない同期スタンバイの数は、<varname>synchronous_standby_names</varname>で指定されます。
また、このパラメータには、スタンバイの名前のリストと、リストされたものから同期スタンバイを選ぶ方法（<literal>FIRST</literal>と<literal>ANY</literal>）を指定します。
   </para>
   <para>
<!--
    The method <literal>FIRST</literal> specifies a priority-based synchronous
    replication and makes transaction commits wait until their WAL records are
    replicated to the requested number of synchronous standbys chosen based on
    their priorities. The standbys whose names appear earlier in the list are
    given higher priority and will be considered as synchronous. Other standby
    servers appearing later in this list represent potential synchronous
    standbys. If any of the current synchronous standbys disconnects for
    whatever reason, it will be replaced immediately with the
    next-highest-priority standby.
-->
方法<literal>FIRST</literal>は優先度に基づく同期レプリケーションを指定し、優先度に応じて選択された同期スタンバイにWALレコードがレプリケーションされるまで、トランザクションのコミットは待機します。
リストの前の方に名前が書いてあるスタンバイにはより高い優先度が与えられ、同期とみなされます。
リストの後ろの方に書いてあるスタンバイは、潜在的な同期スタンバイであることを示します。
どんな理由であれ、現在のスタンバイのどれかの接続が切断されると、次に優先度が高いスタンバイがとって代わります。
   </para>
   <para>
<!--
    An example of <varname>synchronous_standby_names</varname> for
    a priority-based multiple synchronous standbys is:
-->
優先度に基づく複数同期スタンバイのための<varname>synchronous_standby_names</varname>の例を示します。
   </para>
<programlisting>
synchronous_standby_names = 'FIRST 2 (s1, s2, s3)'
</programlisting>
   <para>
<!--
    In this example, if four standby servers <literal>s1</literal>, <literal>s2</literal>,
    <literal>s3</literal> and <literal>s4</literal> are running, the two standbys
    <literal>s1</literal> and <literal>s2</literal> will be chosen as synchronous standbys
    because their names appear early in the list of standby names.
    <literal>s3</literal> is a potential synchronous standby and will take over
    the role of synchronous standby when either of <literal>s1</literal> or
    <literal>s2</literal> fails. <literal>s4</literal> is an asynchronous standby since
    its name is not in the list.
-->
この例では、もし4つのスタンバイサーバ<literal>s1</literal>、<literal>s2</literal>、<literal>s3</literal>、<literal>s4</literal>が稼働中なら、<literal>s1</literal>と<literal>s2</literal>が同期スタンバイに選ばれます。
それらの名前がスタンバイ名のリストの最初の方にあるからです。
<literal>s3</literal>は潜在的な同期スタンバイで、<literal>s1</literal>あるいは<literal>s2</literal>が故障した時に同期スタンバイの役割を取って代わります。
このリストに名前が載っていないので、<literal>s4</literal>は非同期スタンバイです。
   </para>
   <para>
<!--
    The method <literal>ANY</literal> specifies a quorum-based synchronous
    replication and makes transaction commits wait until their WAL records
    are replicated to <emphasis>at least</emphasis> the requested number of
    synchronous standbys in the list.
-->
方法<literal>ANY</literal>はクォーラムに基づく同期レプリケーションを指定し、<emphasis>少なくとも</emphasis>リスト中で指定された数の同期スタンバイにWALレコードがレプリケーションされるまで、トランザクションのコミットを待たせます
   </para>
   <para>
<!--
    An example of <varname>synchronous_standby_names</varname> for
    a quorum-based multiple synchronous standbys is:
-->
クォーラムに基づく同期スタンバイのための<varname>synchronous_standby_names</varname>の例を示します。
<programlisting>
synchronous_standby_names = 'ANY 2 (s1, s2, s3)'
</programlisting>
<!--
    In this example, if four standby servers <literal>s1</literal>, <literal>s2</literal>,
    <literal>s3</literal> and <literal>s4</literal> are running, transaction commits will
    wait for replies from at least any two standbys of <literal>s1</literal>,
    <literal>s2</literal> and <literal>s3</literal>. <literal>s4</literal> is an asynchronous
    standby since its name is not in the list.
-->
この例では、もし4つのスタンバイサーバ<literal>s1</literal>、<literal>s2</literal>、<literal>s3</literal>、<literal>s4</literal>が稼働中なら、トランザクションのコミットは、<literal>s1</literal>、<literal>s2</literal>、<literal>s3</literal>のどれか二つのスタンバイから応答があるまで待たされます。
このリストに名前が載っていないので、<literal>s4</literal>は非同期スタンバイです。
   </para>
   <para>
<!--
    The synchronous states of standby servers can be viewed using
    the <structname>pg_stat_replication</structname> view.
-->
<structname>pg_stat_replication</structname>ビューを使って、スタンバイサーバの同期状態を見ることができます。
   </para>
   </sect3>

   <sect3 id="synchronous-replication-performance">
<!--
    <title>Planning for Performance</title>
-->
    <title>性能に関する考慮</title>

   <para>
<!--
    Synchronous replication usually requires carefully planned and placed
    standby servers to ensure applications perform acceptably. Waiting
    doesn't utilize system resources, but transaction locks continue to be
    held until the transfer is confirmed. As a result, incautious use of
    synchronous replication will reduce performance for database
    applications because of increased response times and higher contention.
-->
通常、同期レプリケーションは、アプリケーションが満足できる程度に実行されることを確実にするために、注意深くスタンバイサーバを計画し設置しなければなりません。
待機のためにシステムリソースを使用することはありませんが、トランザクションロックは転送が確認されるまで継続して保持されます。
結果として同期レプリケーションを注意せずに使用すると、応答時間が増加する、および競合がより高くなるため、データベースアプリケーションの性能は低下します。
   </para>

   <para>
<!--
    <productname>PostgreSQL</productname> allows the application developer
    to specify the durability level required via replication. This can be
    specified for the system overall, though it can also be specified for
    specific users or connections, or even individual transactions.
-->
<productname>PostgreSQL</productname>ではアプリケーション開発者がレプリケーション経由で必要とする永続性レベルを指定することができます。
これをシステム全体に対して指定することができますし、特定のユーザ、接続、個々のトランザクションに対してさえ指定することもできます。
   </para>

   <para>
<!--
    For example, an application workload might consist of:
    10% of changes are important customer details, while
    90% of changes are less important data that the business can more
    easily survive if it is lost, such as chat messages between users.
-->
例えばアプリケーションの作業量が、重要な顧客詳細の変更が10%、ユーザ間のチャットメッセージなど、あまり重要ではなく、失ったとしても業務をより簡単に戻すことができるようなデータの変更が90% という構成を考えてみます。
   </para>

   <para>
<!--
    With synchronous replication options specified at the application level
    (on the primary) we can offer synchronous replication for the most
    important changes, without slowing down the bulk of the total workload.
    Application level options are an important and practical tool for allowing
    the benefits of synchronous replication for high performance applications.
-->
（プライマリ上で）アプリケーションレベルで指定する同期レプリケーションオプションを使用して、作業全体を低速化させることなく、最も重要な変更に対して同期レプリケーションを企てることができます。
アプリケーションレベルのオプションは、高い性能が求められるアプリケーションで同期レプリケーションの利点が得られる、重要かつ現実的な手段です。
   </para>

   <para>
<!--
    You should consider that the network bandwidth must be higher than
    the rate of generation of WAL data.
-->
生成されるWALデータの割合よりネットワーク帯域幅が大きくなければならないことを考慮しなければなりません。
   </para>

   </sect3>

   <sect3 id="synchronous-replication-ha">
<!--
    <title>Planning for High Availability</title>
-->
    <title>高可用性に関する検討</title>

   <para>
<!--
    <varname>synchronous_standby_names</varname> specifies the number and
    names of synchronous standbys that transaction commits made when
    <varname>synchronous_commit</varname> is set to <literal>on</literal>,
    <literal>remote_apply</literal> or <literal>remote_write</literal> will wait for
    responses from. Such transaction commits may never be completed
    if any one of synchronous standbys should crash.
-->
<varname>synchronous_commit</varname>が、<literal>on</literal>、<literal>remote_apply</literal>、<literal>remote_write</literal>のいずれかに設定されている場合、<varname>synchronous_standby_names</varname>には、コミットされたトランザクションが応答を待つ同期スタンバイの数と名前を指定します。
そのようなトランザクションのコミットは、同期スタンバイのどれかがクラッシュすると決して完了しないかもしれません。
   </para>

   <para>
<!--
    The best solution for high availability is to ensure you keep as many
    synchronous standbys as requested. This can be achieved by naming multiple
    potential synchronous standbys using <varname>synchronous_standby_names</varname>.
-->
高可用性のもっとも良い解決方法は、想定したのと同じ数の同期スタンバイを確実に確保することです。
これは、<varname>synchronous_standby_names</varname>を使って同期スタンバイ候補を複数指定することによって実現できます。
そのリストの最初の方に名前が上がっているスタンバイは、同期スタンバイとして使用されます。
その後の方に名前が上がっているスタンバイは、同期スタンバイのどれかが故障した時に、その役割を取って代わります。
   </para>

   <para>
<!--
    In a priority-based synchronous replication, the standbys whose names
    appear earlier in the list will be used as synchronous standbys.
    Standbys listed after these will take over the role of synchronous standby
    if one of current ones should fail.
-->
優先度に基づく同期レプリケーションでは、リストの前の方に名前が現れるスタンバイが同期スタンバイになります。
現在の同期スタンバイのどれかが故障した際には、リストの後の方にあるスタンバイが同期スタンバイの役割を引き継ぎます。
   </para>

   <para>
<!--
    In a quorum-based synchronous replication, all the standbys appearing
    in the list will be used as candidates for synchronous standbys.
    Even if one of them should fail, the other standbys will keep performing
    the role of candidates of synchronous standby.
-->
クォーラムに基づく同期レプリケーションでは、リストに現れたすべてのスタンバイが同期スタンバイの候補となります。
そのどれかが故障した場合でも、他のスタンバイは引き続き同期スタンバイの候補としての役割を担い続けます。
   </para>

   <para>
<!--
    When a standby first attaches to the primary, it will not yet be properly
    synchronized. This is described as <literal>catchup</literal> mode. Once
    the lag between standby and primary reaches zero for the first time
    we move to real-time <literal>streaming</literal> state.
    The catch-up duration may be long immediately after the standby has
    been created. If the standby is shut down, then the catch-up period
    will increase according to the length of time the standby has been down.
    The standby is only able to become a synchronous standby
    once it has reached <literal>streaming</literal> state.
    This state can be viewed using
    the <structname>pg_stat_replication</structname> view.
-->
スタンバイが最初にプライマリに接続された時、それはまだ適切に同期されていません。
これは<literal>catchup</literal>モードと呼ばれます。
一旦スタンバイとプライマリ間の遅延がゼロになると、実時間<literal>streaming</literal>状態に移ります。
追従（catchup）期間はスタンバイが作成された直後は長くなるかもしれません。
スタンバイが停止している場合、追従期間はスタンバイの停止期間にしたがって長くなります。
スタンバイは、<literal>streaming</literal>状態に達した後でのみ、同期スタンバイになることができます。
この状態は、<structname>pg_stat_replication</structname>ビューで見ることができます。
   </para>

   <para>
<!--
    If primary restarts while commits are waiting for acknowledgment, those
    waiting transactions will be marked fully committed once the primary
    database recovers.
    There is no way to be certain that all standbys have received all
    outstanding WAL data at time of the crash of the primary. Some
    transactions may not show as committed on the standby, even though
    they show as committed on the primary. The guarantee we offer is that
    the application will not receive explicit acknowledgment of the
    successful commit of a transaction until the WAL data is known to be
    safely received by all the synchronous standbys.
-->
コミットが受領通知を待機している間にプライマリが再起動した場合、プライマリデータベースが復旧した後、待機中のトランザクションは完全にコミットされたものと記録されます。
すべてのスタンバイがプライマリのクラッシュ時点で送信中のWALデータのすべてを受信したかどうかを確認する方法はありません。
トランザクションの一部は、プライマリではコミットされたものと表示されていたとしても、スタンバイではコミットされていないと表示されるかもしれません。
PostgreSQLは、WALデータをすべてのスタンバイが安全に受信したことが分かるまで、アプリケーションは明示的なトランザクションコミットの成功に関する受領通知を受けとらないことを保証しています。
   </para>

   <para>
<!--
    If you really cannot keep as many synchronous standbys as requested
    then you should decrease the number of synchronous standbys that
    transaction commits must wait for responses from
    in <varname>synchronous_standby_names</varname> (or disable it) and
    reload the configuration file on the primary server.
-->
要求していた数の同期スタンバイを本当に確保できないときは、トランザクションが応答を待たなければならない同期スタンバイの数を、<varname>synchronous_standby_names</varname>から減らしてください（もしくは無効にします）。
そして、プライマリサーバの設定ファイルを再読み込みしてください。
   </para>

   <para>
<!--
    If the primary is isolated from remaining standby servers you should
    fail over to the best candidate of those other remaining standby servers.
-->
プライマリが既存のスタンバイサーバから切り離された場合は、スタンバイサーバの中から最善と思われる候補にフェイルオーバーしてください。
   </para>

   <para>
<!--
    If you need to re-create a standby server while transactions are
    waiting, make sure that the commands pg_start_backup() and
    pg_stop_backup() are run in a session with
    <varname>synchronous_commit</varname> = <literal>off</literal>, otherwise those
    requests will wait forever for the standby to appear.
-->
トランザクションの待機中にスタンバイサーバを再作成する必要がある場合、pg_start_backup()およびpg_stop_backup()を実行するコマンドを<varname>synchronous_commit</varname> = <literal>off</literal>であるセッション内で確実に実行してください。
さもないとこれらの要求はスタンバイに現れるまで永遠に待機します。
   </para>

   </sect3>
  </sect2>

  <sect2 id="continuous-archiving-in-standby">
<!--
   <title>Continuous Archiving in Standby</title>
-->
   <title>スタンバイにおける継続的アーカイビング</title>

   <indexterm>
<!--
     <primary>continuous archiving</primary>
     <secondary>in standby</secondary>
-->
     <primary>継続的アーカイビング</primary>
     <secondary>スタンバイにおける</secondary>
   </indexterm>

   <para>
<!--
     When continuous WAL archiving is used in a standby, there are two
     different scenarios: the WAL archive can be shared between the primary
     and the standby, or the standby can have its own WAL archive. When
     the standby has its own WAL archive, set <varname>archive_mode</varname>
     to <literal>always</literal>, and the standby will call the archive
     command for every WAL segment it receives, whether it's by restoring
     from the archive or by streaming replication. The shared archive can
     be handled similarly, but the <varname>archive_command</varname> must
     test if the file being archived exists already, and if the existing file
     has identical contents. This requires more care in the
     <varname>archive_command</varname>, as it must
     be careful to not overwrite an existing file with different contents,
     but return success if the exactly same file is archived twice. And
     all that must be done free of race conditions, if two servers attempt
     to archive the same file at the same time.
-->
スタンバイにおいてWALの継続的アーカイビングが行われる場合、2つのシナリオが考えられます。
WALアーカイブがプライマリとスタンバイで共有されるケースと、スタンバイが自分のWALアーカイブを持つケースです。
スタンバイが自分のWALアーカイブを持つケースでは、<varname>archive_mode</varname>を<literal>always</literal>に設定しておくことにより、アーカイブからリストアされたWALセグメントであろうと、ストリーミングレプリケーション由来のWALセグメントであろうと、WALセグメントを受信する度にスタンバイはアーカイブコマンドを呼び出します。
共有アーカイブのケースも同じように扱えますが、<varname>archive_command</varname>はアーカイブしようとしているファイルがすでに存在していて、それが同一内容かどうかのチェックを行う必要があります。
このため、<varname>archive_command</varname>はより工夫が必要です。
というのも、<varname>archive_command</varname>は既存のファイルを異なる内容で置き換えてはいけませんし、またまったく同じ内容のファイルを置き換えた場合には成功したと報告しなければならないからです。
更に、2つのサーバが同時に同じファイルをアーカイブしようとした時に、競合状態が起きないようにしなければなりません。
   </para>

   <para>
<!--
     If <varname>archive_mode</varname> is set to <literal>on</literal>, the
     archiver is not enabled during recovery or standby mode. If the standby
     server is promoted, it will start archiving after the promotion, but
     will not archive any WAL or timeline history files that
     it did not generate itself. To get a complete
     series of WAL files in the archive, you must ensure that all WAL is
     archived, before it reaches the standby. This is inherently true with
     file-based log shipping, as the standby can only restore files that
     are found in the archive, but not if streaming replication is enabled.
     When a server is not in recovery mode, there is no difference between
     <literal>on</literal> and <literal>always</literal> modes.
-->
<varname>archive_mode</varname>が<literal>on</literal>の場合には、リカバリモードあるいはスタンバイモードではアーカイブは有効になりません。
スタンバイサーバが昇格すると、昇格後にスタンバイサーバはアーカイブを開始します。
しかし、自分が生成しなかったWALやタイムライン履歴ファイルは一切アーカイブしません。
完全な一連のWALファイルをアーカイブから取り出すためには、WALがスタンバイに到着する前に、すべてのWALがアーカイブされていることを保証しなければなりません。
ファイルベースのログシッピングにおいても本質的にはこの通りです。
というのも、スタンバイはアーカイブにあるファイルだけをリストアできるからです。
ストリーミングレプリケーションが有効ならば、この限りではありません。
サーバがリカバリモードでない場合には、<literal>on</literal>と<literal>always</literal>のモードの間には違いはありません。
   </para>
  </sect2>
  </sect1>

  <sect1 id="warm-standby-failover">
<!--
   <title>Failover</title>
-->
   <title>フェイルオーバー</title>

   <para>
<!--
    If the primary server fails then the standby server should begin
    failover procedures.
-->
プライマリサーバに障害が起こると、スタンバイサーバはフェイルオーバー処理を始めなければなりません。
   </para>

   <para>
<!--
    If the standby server fails then no failover need take place. If the
    standby server can be restarted, even some time later, then the recovery
    process can also be restarted immediately, taking advantage of
    restartable recovery. If the standby server cannot be restarted, then a
    full new standby server instance should be created.
-->
スタンバイサーバが故障した場合、フェイルオーバーは不要です。
多少の時間の後に、スタンバイサーバを再起動できれば、再起動可能なリカバリのため、リカバリ処理も即座に再起動することができます。
スタンバイサーバを再起動できなければ、新しい完全なスタンバイサーバのインスタンスを作成しなければなりません。
   </para>

   <para>
<!--
    If the primary server fails and the standby server becomes the
    new primary, and then the old primary restarts, you must have
    a mechanism for informing the old primary that it is no longer the primary. This is
    sometimes known as <acronym>STONITH</acronym> (Shoot The Other Node In The Head), which is
    necessary to avoid situations where both systems think they are the
    primary, which will lead to confusion and ultimately data loss.
-->
プライマリサーバに障害が起こりスタンバイサーバが新しいプライマリとなり、その後古いプライマリが再起動した場合、もはやプライマリサーバでなくなっていることを古いプライマリに知らせる機構が必要です。
これは<acronym>STONITH</acronym> (Shoot the Other Node In The Head)と一部ではいわれています。
これは、混乱と最悪はデータ損失をもたらしかねない、両方のシステムが自身をプライマリとして認識してしまう状況を防ぐために必要です。
   </para>

   <para>
<!--
    Many failover systems use just two systems, the primary and the standby,
    connected by some kind of heartbeat mechanism to continually verify the
    connectivity between the two and the viability of the primary. It is
    also possible to use a third system (called a witness server) to prevent
    some cases of inappropriate failover, but the additional complexity
    might not be worthwhile unless it is set up with sufficient care and
    rigorous testing.
-->
多くのフェイルオーバーシステムではプライマリとスタンバイといった２つのシステムを使用します。
なんらかのハートビート機構でプライマリとスタンバイを接続し、両者の接続性とプライマリの実行能力を継続的に確認します。
また、第３のシステム（証言サーバと呼ばれます）を使用して、不適切なフェイルオーバーなどの状況を防ぐこともできます。
しかし、さらに複雑になりますので、十分な注意と厳密な検証の元に設定を行わない限り行う意味がありません。
   </para>

   <para>
<!--
    <productname>PostgreSQL</productname> does not provide the system
    software required to identify a failure on the primary and notify
    the standby database server.  Many such tools exist and are well
    integrated with the operating system facilities required for
    successful failover, such as IP address migration.
-->
<productname>PostgreSQL</productname>は、プライマリサーバの障害を識別し、スタンバイデータベースサーバに通知するために必要なシステムソフトウェアを提供しません。
こうしたツールは多く存在し、IPアドレスの移行といったフェイルオーバーを成功させるために必要な機能をオペレーティングシステムにうまく統合させています。
   </para>

   <para>
<!--
    Once failover to the standby occurs, there is only a
    single server in operation. This is known as a degenerate state.
    The former standby is now the primary, but the former primary is down
    and might stay down.  To return to normal operation, a standby server
    must be recreated,
    either on the former primary system when it comes up, or on a third,
    possibly new, system. The <xref linkend="app-pgrewind"/> utility can be
    used to speed up this process on large clusters.
    Once complete, the primary and standby can be
    considered to have switched roles. Some people choose to use a third
    server to provide backup for the new primary until the new standby
    server is recreated,
    though clearly this complicates the system configuration and
    operational processes.
-->
スタンバイサーバへのフェイルオーバーが起きた後、運用可能なサーバは1つしかありません。
これは縮退状態と呼ばれます。
以前のスタンバイサーバはプライマリサーバになり、以前のプライマリは停止し、その後も停止し続けるかもしれません。
通常の運用に戻すには、スタンバイサーバを再作成しなければなりません。
以前のプライマリサーバが起動できれば、これを使用しても構いませんし、第三のおそらく新規のシステムを使用しても構いません。
<xref linkend="app-pgrewind"/>を使って、大きなクラスタにおける処理を早めることもできます。
完了すれば、プライマリとスタンバイの役割が切り替わったとみなすことができます。
新しいスタンバイサーバを再作成するまでに第三のサーバを使用して新しいプライマリのバックアップを提供することを選択する人もいますが、これがシステム構成と運用手順を複雑にすることは明らかです。
   </para>

   <para>
<!--
    So, switching from primary to standby server can be fast but requires
    some time to re-prepare the failover cluster. Regular switching from
    primary to standby is useful, since it allows regular downtime on
    each system for maintenance. This also serves as a test of the
    failover mechanism to ensure that it will really work when you need it.
    Written administration procedures are advised.
-->
プライマリサーバからスタンバイサーバへの切り替えは高速ですが、フェイルオーバークラスタを再度準備するのに多少時間が必要です。
それぞれのシステムを保守のために定期的に停止することができるので、プライマリからスタンバイへの定期的切り替えは有益です。
これは同時に、必要になった時、フェイルオーバー機構が実際に機能するかどうかを確認する試験としても役立ちます。
管理手順の文書化を勧めます。
   </para>

   <para>
<!--
    To trigger failover of a log-shipping standby server, run
    <command>pg_ctl promote</command>, call <function>pg_promote()</function>,
    or create a trigger file with the file name and path specified by the
    <varname>promote_trigger_file</varname>. If you're planning to use
    <command>pg_ctl promote</command> or to call
    <function>pg_promote()</function> to fail over,
    <varname>promote_trigger_file</varname> is not required. If you're
    setting up the reporting servers that are only used to offload read-only
    queries from the primary, not for high availability purposes, you don't
    need to promote it.
-->
ログシッピングを行うスタンバイサーバのフェイルオーバーを発生させるためには、<command>pg_ctl promote</command>を実行する、<function>pg_promote()</function>を呼び出す、あるいは<varname>promote_trigger_file</varname>で指定されるファイル名とパスを持つトリガファイルを作成してください。
フェイルオーバーのために<command>pg_ctl promote</command>を使用する、あるいは<function>pg_promote()</function>を呼び出すつもりならば、<varname>promote_trigger_file</varname>は必要ありません。
プライマリから読み取り専用の問い合わせによる負荷を軽減させるためだけに使用し、高可用性を目的としていない、報告処理用サーバを構築する場合は、昇格させる必要はありません。
   </para>
  </sect1>

 <sect1 id="hot-standby">
<!--
  <title>Hot Standby</title>
-->
  <title>ホットスタンバイ</title>

  <indexterm zone="high-availability">
<!--
   <primary>Hot Standby</primary>
-->
   <primary>ホットスタンバイ</primary>
  </indexterm>

   <para>
<!--
    Hot Standby is the term used to describe the ability to connect to
    the server and run read-only queries while the server is in archive
    recovery or standby mode. This
    is useful both for replication purposes and for restoring a backup
    to a desired state with great precision.
    The term Hot Standby also refers to the ability of the server to move
    from recovery through to normal operation while users continue running
    queries and/or keep their connections open.
-->
ホットスタンバイという単語は、サーバがアーカイブリカバリを実行している最中にサーバに接続し読み取り専用の問い合わせを実行することができる機能を説明するために使われます。
これは、レプリケーションという目的およびバックアップからのリストアの両方で高い精度で好ましい状態にするために有用です。
ホットスタンバイという単語はまた、ユーザが問い合わせを実行しながら、または、開いている接続を維持しながら、またはその両方で、サーバをリカバリ状態から通常の動作に移すことができる機能も示すものです。
   </para>

   <para>
<!--
    Running queries in hot standby mode is similar to normal query operation,
    though there are several usage and administrative differences
    explained below.
-->
ホットスタンバイモードにおける問い合わせは、通常の問い合わせに類似していますが、利用上および管理上の差異が多少あり、以下に説明します。
   </para>

  <sect2 id="hot-standby-users">
<!--
   <title>User's Overview</title>
-->
   <title>ユーザのための概説</title>

   <para>
<!--
    When the <xref linkend="guc-hot-standby"/> parameter is set to true on a
    standby server, it will begin accepting connections once the recovery has
    brought the system to a consistent state.  All such connections are
    strictly read-only; not even temporary tables may be written.
-->
スタンバイサーバで<xref linkend="guc-hot-standby"/>パラメータが真に設定されている場合、リカバリによりシステムが一貫性を持つようになった後接続を受け付け始めます。
こうした接続はすべて読み取り専用に限定されます。
一時テーブルであっても書き込むことはできません。
   </para>

   <para>
<!--
    The data on the standby takes some time to arrive from the primary server
    so there will be a measurable delay between primary and standby. Running the
    same query nearly simultaneously on both primary and standby might therefore
    return differing results. We say that data on the standby is
    <firstterm>eventually consistent</firstterm> with the primary.  Once the
    commit record for a transaction is replayed on the standby, the changes
    made by that transaction will be visible to any new snapshots taken on
    the standby.  Snapshots may be taken at the start of each query or at the
    start of each transaction, depending on the current transaction isolation
    level.  For more details, see <xref linkend="transaction-iso"/>.
-->
スタンバイ上のデータはプライマリサーバから届くまでに多少の時間がかかります。
このため、プライマリとスタンバイの間にはある程度の遅延があります。
したがって、同じ問い合わせをほとんど同時にプライマリとスタンバイに対して実行すると、異なる結果が返る可能性があります。
スタンバイ上のデータはプライマリに対して<firstterm>最後には一貫性を持つ</firstterm>といいます。
あるトランザクションのコミットレコードがスタンバイ上で再生されると、そのトランザクションでなされた変更はスタンバイで獲得されるすべての新規スナップショットで可視になります。
現在のトランザクション隔離レベルに応じて、スナップショットは各問い合わせの開始時または各トランザクションの開始時に獲得されます。
詳細については<xref linkend="transaction-iso"/>を参照してください。
   </para>

   <para>
<!--
    Transactions started during hot standby may issue the following commands:
-->
ホットスタンバイ中に開始されたトランザクションは以下のコマンドを発行することができます。

    <itemizedlist>
     <listitem>
      <para>
<!--
       Query access: <command>SELECT</command>, <command>COPY TO</command>
-->
問い合わせによるアクセス: <command>SELECT</command>および<command>COPY TO</command>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Cursor commands: <command>DECLARE</command>, <command>FETCH</command>, <command>CLOSE</command>
-->
カーソルコマンド: <command>DECLARE</command>と<command>FETCH</command>と<command>CLOSE</command>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Settings: <command>SHOW</command>, <command>SET</command>, <command>RESET</command>
-->
設定の操作: <command>SHOW</command>と<command>SET</command>と<command>RESET</command>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Transaction management commands:
-->
トランザクション管理コマンド:
        <itemizedlist>
         <listitem>
          <para>
<!--
           <command>BEGIN</command>, <command>END</command>, <command>ABORT</command>, <command>START TRANSACTION</command>
-->
<command>BEGIN</command>と<command>END</command>と<command>ABORT</command>と<command>START TRANSACTION</command>
          </para>
         </listitem>
         <listitem>
          <para>
<!--
           <command>SAVEPOINT</command>, <command>RELEASE</command>, <command>ROLLBACK TO SAVEPOINT</command>
-->
<command>SAVEPOINT</command>と<command>RELEASE</command>と<command>ROLLBACK TO SAVEPOINT</command>
          </para>
         </listitem>
         <listitem>
          <para>
<!--
           <command>EXCEPTION</command> blocks and other internal subtransactions
-->
<command>EXCEPTION</command>ブロックおよびこの他の内部サブトランザクション
          </para>
         </listitem>
        </itemizedlist>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       <command>LOCK TABLE</command>, though only when explicitly in one of these modes:
       <literal>ACCESS SHARE</literal>, <literal>ROW SHARE</literal> or <literal>ROW EXCLUSIVE</literal>.
-->
<command>LOCK TABLE</command>。
なお、以下のモードが明示された場合に限ります。
<literal>ACCESS SHARE</literal>または<literal>ROW SHARE</literal>または<literal>ROW EXCLUSIVE</literal>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Plans and resources: <command>PREPARE</command>, <command>EXECUTE</command>,
       <command>DEALLOCATE</command>, <command>DISCARD</command>
-->
計画と資源: <command>PREPARE</command>と<command>EXECUTE</command>と<command>DEALLOCATE</command>と<command>DISCARD</command>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Plugins and extensions: <command>LOAD</command>
-->
プラグインと拡張: <command>LOAD</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>UNLISTEN</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>UNLISTEN</command>
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
<!--
    Transactions started during hot standby will never be assigned a
    transaction ID and cannot write to the system write-ahead log.
    Therefore, the following actions will produce error messages:
-->
ホットスタンバイ中に開始したトランザクションではトランザクションIDを割り当てられません。
また、システムのログ先行書き込みに書き出すことができません。
このため、以下の動作はエラーメッセージを生成します。

    <itemizedlist>
     <listitem>
      <para>
<!--
       Data Manipulation Language (DML): <command>INSERT</command>,
       <command>UPDATE</command>, <command>DELETE</command>, <command>COPY FROM</command>,
       <command>TRUNCATE</command>.
       Note that there are no allowed actions that result in a trigger
       being executed during recovery.  This restriction applies even to
       temporary tables, because table rows cannot be read or written without
       assigning a transaction ID, which is currently not possible in a
       Hot Standby environment.
-->
データ操作言語（DML）:
<command>INSERT</command>、<command>UPDATE</command>、<command>DELETE</command>、<command>COPY FROM</command>および<command>TRUNCATE</command>。
リカバリ中にトリガ内で実行されてしまう場合でも許されていない動作であることに注意してください。
現在のホットスタンバイ環境では行うことができないトランザクションIDの割り当てを行うことなく、テーブル行の読み書きを行うことができませんので、この制限は一時テーブルであっても適用されます。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Data Definition Language (DDL): <command>CREATE</command>,
       <command>DROP</command>, <command>ALTER</command>, <command>COMMENT</command>.
       This restriction applies even to temporary tables, because carrying
       out these operations would require updating the system catalog tables.
-->
データ定義言語（DDL）:
<command>CREATE</command>、<command>DROP</command>、<command>ALTER</command>および<command>COMMENT</command>。
この制約は一時テーブルに対しても適用されます。
これらの操作の実行がシステムカタログテーブルの更新を必要とするためです。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       <command>SELECT ... FOR SHARE | UPDATE</command>, because row locks cannot be
       taken without updating the underlying data files.
-->
<command>SELECT ... FOR SHARE | UPDATE</command>。
背後のデータファイルを更新することなく行ロックを獲得することはできないためです。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Rules on <command>SELECT</command> statements that generate DML commands.
-->
データ操作言語のコマンドを生成する<command>SELECT</command>文のルール
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       <command>LOCK</command> that explicitly requests a mode higher than <literal>ROW EXCLUSIVE MODE</literal>.
-->
<literal>ROW EXCLUSIVE MODE</literal>より高いモードを明示的に要求する<command>LOCK</command>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       <command>LOCK</command> in short default form, since it requests <literal>ACCESS EXCLUSIVE MODE</literal>.
-->
短いデフォルト構文の<command>LOCK</command>。
これは<literal>ACCESS EXCLUSIVE MODE</literal>を要求するためです。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Transaction management commands that explicitly set non-read-only state:
-->
読み取り専用でない状態を明示的に設定するトランザクション処理コマンド
        <itemizedlist>
         <listitem>
          <para>
<!--
            <command>BEGIN READ WRITE</command>,
            <command>START TRANSACTION READ WRITE</command>
-->
<command>BEGIN READ WRITE</command>と<command>START TRANSACTION READ WRITE</command>
          </para>
         </listitem>
         <listitem>
          <para>
<!--
            <command>SET TRANSACTION READ WRITE</command>,
            <command>SET SESSION CHARACTERISTICS AS TRANSACTION READ WRITE</command>
-->
<command>SET TRANSACTION READ WRITE</command>と<command>SET SESSION CHARACTERISTICS AS TRANSACTION READ WRITE</command>
          </para>
         </listitem>
         <listitem>
          <para>
<!--
           <command>SET transaction_read_only = off</command>
-->
<command>SET transaction_read_only = off</command>
          </para>
         </listitem>
        </itemizedlist>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Two-phase commit commands: <command>PREPARE TRANSACTION</command>,
       <command>COMMIT PREPARED</command>, <command>ROLLBACK PREPARED</command>
       because even read-only transactions need to write WAL in the
       prepare phase (the first phase of two phase commit).
-->
二相コミットコマンド: <command>PREPARE TRANSACTION</command>、<command>COMMIT PREPARED</command>および<command>ROLLBACK PREPARED</command>。
読み取り専用トランザクションでも、プリペア相（二相コミットの第1相）においてWALの書き込みが必要だからです。
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       Sequence updates: <function>nextval()</function>, <function>setval()</function>
-->
シーケンス更新の関数: <function>nextval()</function>と<function>setval()</function>
      </para>
     </listitem>
     <listitem>
      <para>
<!--
       <command>LISTEN</command>, <command>NOTIFY</command>
-->
<command>LISTEN</command>、<command>NOTIFY</command>
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
<!--
    In normal operation, <quote>read-only</quote> transactions are allowed to
    use <command>LISTEN</command> and <command>NOTIFY</command>,
    so Hot Standby sessions operate under slightly tighter
    restrictions than ordinary read-only sessions.  It is possible that some
    of these restrictions might be loosened in a future release.
-->
通常の操作では、<quote>読み取り専用</quote>トランザクションには<command>LISTEN</command>と<command>NOTIFY</command>の使用が許可されています。
ホットスタンバイセッションの操作では、通常の読み取り専用セッションよりも少し厳しい制約を受けます。
将来のリリースではこの制約の一部が緩和されるかもしれません。
   </para>

   <para>
<!--
    During hot standby, the parameter <varname>transaction_read_only</varname> is always
    true and may not be changed.  But as long as no attempt is made to modify
    the database, connections during hot standby will act much like any other
    database connection.  If failover or switchover occurs, the database will
    switch to normal processing mode.  Sessions will remain connected while the
    server changes mode.  Once hot standby finishes, it will be possible to
    initiate read-write transactions (even from a session begun during
    hot standby).
-->
ホットスタンバイ中は、<varname>transaction_read_only</varname>パラメータは常に真であり、変更することはできません。
しかし、データベースを変更するような試行がない限り、ホットスタンバイ中の接続は他のデータベース接続とほとんど同じように動作します。
もし、フェイルオーバーまたはスイッチオーバが発生すると、データベースは通常処理モードに切り替わります。
サーバのモードが変わってもセッションは接続を保持します。
ホットスタンバイが完了すると、読み書き可能なトランザクションを（ホットスタンバイ中に始まったセッションからであっても）始められるようになります。
   </para>

   <para>
<!--
    Users can determine whether hot standby is currently active for their
    session by issuing <command>SHOW in_hot_standby</command>.
    (In server versions before 14, the <varname>in_hot_standby</varname>
    parameter did not exist; a workable substitute method for older servers
    is <command>SHOW transaction_read_only</command>.)  In addition, a set of
    functions (<xref linkend="functions-recovery-info-table"/>) allow users to
    access information about the standby server. These allow you to write
    programs that are aware of the current state of the database. These
    can be used to monitor the progress of recovery, or to allow you to
    write complex programs that restore the database to particular states.
-->
ユーザは<command>SHOW transaction_read_only</command>を発行することで、そのセッションが読み取り専用かどうかを調べることができます。
さらに、ユーザがスタンバイサーバに関する情報にアクセスできる関数群(<xref linkend="functions-recovery-info-table"/>)があります。
これらによりデータベースの現状認識を行うプログラムを作成することができます。
これらを使用して、リカバリの進行状況を監視するために使用したり、データベースを特定の状態にリストアする複雑なプログラムを作成したりすることができます。
   </para>
  </sect2>

  <sect2 id="hot-standby-conflict">
<!--
   <title>Handling Query Conflicts</title>
-->
   <title>問い合わせコンフリクトの処理</title>

   <para>
<!--
    The primary and standby servers are in many ways loosely connected. Actions
    on the primary will have an effect on the standby. As a result, there is
    potential for negative interactions or conflicts between them. The easiest
    conflict to understand is performance: if a huge data load is taking place
    on the primary then this will generate a similar stream of WAL records on the
    standby, so standby queries may contend for system resources, such as I/O.
-->
プライマリサーバとスタンバイサーバは、多方面でゆるく結合しています。
プライマリサーバの動作はスタンバイサーバに影響します。
その結果、負の相互作用またはコンフリクトの可能性があります。
最も分かりやすいコンフリクトは性能です。
プライマリサーバで巨大なデータがロードされた場合、スタンバイサーバにおいて同様に巨大なWALレコードが生成されるので、スタンバイサーバにおける問い合わせは互いにI/Oなどのシステム資源を奪い合います。
   </para>

   <para>
<!--
    There are also additional types of conflict that can occur with Hot Standby.
    These conflicts are <emphasis>hard conflicts</emphasis> in the sense that queries
    might need to be canceled and, in some cases, sessions disconnected to resolve them.
    The user is provided with several ways to handle these
    conflicts. Conflict cases include:
-->
ホットスタンバイで発生する可能性があるコンフリクトの種類には他にもあります。
これらのコンフリクトは、問い合わせをキャンセルしなければならない可能性があり、解消させるためにはセッションの接続を閉ざすことになる場合もあるため、<emphasis>致命的なコンフリクト</emphasis>です。
ユーザにはこうしたコンフリクトを扱うための複数の方法が提供されます。
コンフリクトする状況には以下があります。

      <itemizedlist>
       <listitem>
        <para>
<!--
         Access Exclusive locks taken on the primary server, including both
         explicit <command>LOCK</command> commands and various <acronym>DDL</acronym>
         actions, conflict with table accesses in standby queries.
-->
プライマリサーバで獲得されたアクセス排他ロックは、スタンバイの問い合わせにおけるテーブルアクセスとコンフリクトします。
明示的な<command>LOCK</command>コマンドおよび各種<acronym>DDL</acronym>操作を含みます。
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Dropping a tablespace on the primary conflicts with standby queries
         using that tablespace for temporary work files.
-->
プライマリでテーブル空間を削除することは、一時作業ファイル用にそのテーブル空間を使用するスタンバイ側の問い合わせとコンフリクトします。
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Dropping a database on the primary conflicts with sessions connected
         to that database on the standby.
-->
プライマリでデータベースを削除することは、スタンバイ側でそのデータベースに接続するセッションとコンフリクトします。
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Application of a vacuum cleanup record from WAL conflicts with
         standby transactions whose snapshots can still <quote>see</quote> any of
         the rows to be removed.
-->
WALからのバキュームクリーンアップレコードの適用は、その適用により削除される行のどれか1つでも<quote>見る</quote>ことができるスナップショットを持つスタンバイでのトランザクションとコンフリクトします。
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Application of a vacuum cleanup record from WAL conflicts with
         queries accessing the target page on the standby, whether or not
         the data to be removed is visible.
-->
WALからのバキュームクリーンアップレコードは、消去されるデータが可視か否かに関係なく、スタンバイで対象ページにアクセスする問い合わせとコンフリクトします。
        </para>
       </listitem>
      </itemizedlist>
   </para>

   <para>
<!--
    On the primary server, these cases simply result in waiting; and the
    user might choose to cancel either of the conflicting actions.  However,
    on the standby there is no choice: the WAL-logged action already occurred
    on the primary so the standby must not fail to apply it.  Furthermore,
    allowing WAL application to wait indefinitely may be very undesirable,
    because the standby's state will become increasingly far behind the
    primary's.  Therefore, a mechanism is provided to forcibly cancel standby
    queries that conflict with to-be-applied WAL records.
-->
プライマリサーバでは、こうした状況は単に待たされるだけです。
ユーザはコンフリクトする操作をキャンセルすることを選ぶことができます。
しかし、スタンバイ側には選択肢がありません。
WALに記録された操作はすでにプライマリで発生したものですので、スタンバイではその適用に失敗してはなりません。
さらに、適用したいWALを無制限に待機させることを許すことは、まったく望まない結果になってしまうかもしれません。
なぜなら、スタンバイの状態がプライマリの状態とだんだんとかけ離れてしまうからです。
したがって適用すべきWALレコードとコンフリクトするスタンバイの問い合わせを強制的に取り消す仕組みが用意されています。
   </para>

   <para>
<!--
    An example of the problem situation is an administrator on the primary
    server running <command>DROP TABLE</command> on a table that is currently being
    queried on the standby server.  Clearly the standby query cannot continue
    if the <command>DROP TABLE</command> is applied on the standby. If this situation
    occurred on the primary, the <command>DROP TABLE</command> would wait until the
    other query had finished. But when <command>DROP TABLE</command> is run on the
    primary, the primary doesn't have information about what queries are
    running on the standby, so it will not wait for any such standby
    queries. The WAL change records come through to the standby while the
    standby query is still running, causing a conflict.  The standby server
    must either delay application of the WAL records (and everything after
    them, too) or else cancel the conflicting query so that the <command>DROP
    TABLE</command> can be applied.
-->
この問題の例として、スタンバイサーバで現在問い合わせ対象となっているテーブルをプライマリサーバで<command>DROP TABLE</command>を行う管理者を考えてみます。
スタンバイで<command>DROP TABLE</command>が適用されたら問い合わせを継続できないことは明確です。
プライマリ上でこうした状況が発生した場合は、他の問い合わせが終わるまで<command>DROP TABLE</command>は待機させられます。
しかし、<command>DROP TABLE</command>がプライマリで実行された時、プライマリ側でスタンバイで稼動する問い合わせに関する情報がありませんので、スタンバイ側のこうした問い合わせを待機させることはできません。
スタンバイ側で問い合わせが実行している時にWALの変更レコードがスタンバイに届けば、コンフリクトが発生します。
スタンバイサーバはWALレコードの適用を遅延させる（およびその後の適用すべても遅延させる）か、<command>DROP TABLE</command>を適用できるようにコンフリクトする問い合わせを取り消すかのいずれかを行わなければなりません。
   </para>

   <para>
<!--
    When a conflicting query is short, it's typically desirable to allow it to
    complete by delaying WAL application for a little bit; but a long delay in
    WAL application is usually not desirable.  So the cancel mechanism has
    parameters, <xref linkend="guc-max-standby-archive-delay"/> and <xref
    linkend="guc-max-standby-streaming-delay"/>, that define the maximum
    allowed delay in WAL application.  Conflicting queries will be canceled
    once it has taken longer than the relevant delay setting to apply any
    newly-received WAL data.  There are two parameters so that different delay
    values can be specified for the case of reading WAL data from an archive
    (i.e., initial recovery from a base backup or <quote>catching up</quote> a
    standby server that has fallen far behind) versus reading WAL data via
    streaming replication.
-->
コンフリクトする問い合わせが短ければ、適用したいWALを多少遅延させることで、問い合わせを完了させることが通常望まれます。
しかし、WALの適用が長く遅延することはたいていは望まれません。
したがって、取り消し機能は<xref linkend="guc-max-standby-archive-delay"/>と<xref linkend="guc-max-standby-streaming-delay"/>というパラメータを持ちます。
これらはWAL適用に許される遅延を定義するものです。
コンフリクトする問い合わせは、何らかの新しく受信したWALデータを適用するための各種遅延設定を超えたら取り消されます。
アーカイブからWALデータを読み取る場合（つまりベースバックアップからの初期リカバリや大きく遅延したスタンバイサーバの<quote>追従</quote>）とストリーミングレプリケーションとで異なる遅延値を指定することができるように2つのパラメータが存在します。
   </para>

   <para>
<!--
    In a standby server that exists primarily for high availability, it's
    best to set the delay parameters relatively short, so that the server
    cannot fall far behind the primary due to delays caused by standby
    queries.  However, if the standby server is meant for executing
    long-running queries, then a high or even infinite delay value may be
    preferable.  Keep in mind however that a long-running query could
    cause other sessions on the standby server to not see recent changes
    on the primary, if it delays application of WAL records.
-->
主に高可用性のために存在するスタンバイサーバでは、スタンバイ側の問い合わせによって発生する遅延のためにプライマリと大きく遅延が発生することがないように、遅延パラメータを相対的に短く設定することが最善です。
しかし、スタンバイサーバが長時間かかる問い合わせを実行するためのものであれば、長い遅延もしくは制限を設けないことが好まれるかもしれません。
しかし、長時間かかる問い合わせがWALレコードの適用を遅延させてしまう場合、スタンバイサーバ上の他のセッションがプライマリにおける最近の変更を参照することができなくなることは覚えておいてください。
   </para>

   <para>
<!--
    Once the delay specified by <varname>max_standby_archive_delay</varname> or
    <varname>max_standby_streaming_delay</varname> has been exceeded, conflicting
    queries will be canceled.  This usually results just in a cancellation
    error, although in the case of replaying a <command>DROP DATABASE</command>
    the entire conflicting session will be terminated.  Also, if the conflict
    is over a lock held by an idle transaction, the conflicting session is
    terminated (this behavior might change in the future).
-->
<varname>max_standby_archive_delay</varname>または<varname>max_standby_streaming_delay</varname>で指定した遅延を超えると、コンフリクトする問い合わせは取り消されます。
通常これは単なる取り消しエラーという結果となりますが、<command>DROP DATABASE</command>を再生する場合では、コンフリクトするセッション全体が終了します。
また、コンフリクトが待機中のトランザクションで保持されるロックについてのものであれば、そのコンフリクトするセッションが終了します（この動作は将来変更されるかもしれません）。
   </para>

   <para>
<!--
    Canceled queries may be retried immediately (after beginning a new
    transaction, of course).  Since query cancellation depends on
    the nature of the WAL records being replayed, a query that was
    canceled may well succeed if it is executed again.
-->
ユーザは取り消された問い合わせをすぐに再試行するかもしれません（もちろん新規のトランザクション開始後に）。
問い合わせの取り消しは、再生されるWALレコードの性質に依存するので、取り消された問い合わせが再度実行された場合には正常に動作するかもしれません。
   </para>

   <para>
<!--
    Keep in mind that the delay parameters are compared to the elapsed time
    since the WAL data was received by the standby server.  Thus, the grace
    period allowed to any one query on the standby is never more than the
    delay parameter, and could be considerably less if the standby has already
    fallen behind as a result of waiting for previous queries to complete, or
    as a result of being unable to keep up with a heavy update load.
-->
遅延パラメータはスタンバイサーバでWALデータを受信してからの経過時間と比べられることに注意してください。
したがって、スタンバイ上で任意の問い合わせに許される猶予期間は、この遅延パラメータよりも大きくなることは決してありません。
これまでの問い合わせを完了させるために待機した結果、あるいは、大量の更新負荷に追従することができなくなった結果、スタンバイがすでに遅延している場合は相当小さくなります。
   </para>

   <para>
<!--
    The most common reason for conflict between standby queries and WAL replay
    is <quote>early cleanup</quote>.  Normally, <productname>PostgreSQL</productname> allows
    cleanup of old row versions when there are no transactions that need to
    see them to ensure correct visibility of data according to MVCC rules.
    However, this rule can only be applied for transactions executing on the
    primary.  So it is possible that cleanup on the primary will remove row
    versions that are still visible to a transaction on the standby.
-->
スタンバイ側の問い合わせとWAL再生の間でもっともよくあるコンフリクト理由は<quote>早すぎる消去</quote>です。
通常<productname>PostgreSQL</productname>はMVCC規則にしたがって正確なデータの可視性を確実にするために、古い行バージョンを参照するトランザクションが存在しない場合それらを消去することが許されています。
しかし、この規則はマスタ上で実行するトランザクションのみに適用させることができます。
したがって、スタンバイ上のトランザクションでまだ可視である行バージョンを、マスタ上の消去処理が削除してしまう可能性があります。
   </para>

   <para>
<!--
    Experienced users should note that both row version cleanup and row version
    freezing will potentially conflict with standby queries. Running a manual
    <command>VACUUM FREEZE</command> is likely to cause conflicts even on tables with
    no updated or deleted rows.
-->
熟練したユーザは、行バージョンの消去と行バージョンの凍結の両方ともスタンバイ側の問い合わせとコンフリクトする可能性があることに気づくはずです。
手作業での<command>VACUUM FREEZE</command>は、更新または削除された行がないテーブルであったとしてもコンフリクトを発生し易いものです。
   </para>

   <para>
<!--
    Users should be clear that tables that are regularly and heavily updated
    on the primary server will quickly cause cancellation of longer running
    queries on the standby. In such cases the setting of a finite value for
    <varname>max_standby_archive_delay</varname> or
    <varname>max_standby_streaming_delay</varname> can be considered similar to
    setting <varname>statement_timeout</varname>.
-->
プライマリサーバにおいて規則的かつ頻繁に更新されるテーブルは、スタンバイサーバにおける問い合わせの取り消しの原因になりやすいことを利用者は理解するべきです。
そのような場合、<varname>max_standby_archive_delay</varname>または<varname>max_standby_streaming_delay</varname>の設定値は<varname>statement_timeout</varname>の設定と同様に考えることができます。
   </para>

   <para>
<!--
    Remedial possibilities exist if the number of standby-query cancellations
    is found to be unacceptable.  The first option is to set the parameter
    <varname>hot_standby_feedback</varname>, which prevents <command>VACUUM</command> from
    removing recently-dead rows and so cleanup conflicts do not occur.
    If you do this, you
    should note that this will delay cleanup of dead rows on the primary,
    which may result in undesirable table bloat. However, the cleanup
    situation will be no worse than if the standby queries were running
    directly on the primary server, and you are still getting the benefit of
    off-loading execution onto the standby.
    If standby servers connect and disconnect frequently, you
    might want to make adjustments to handle the period when
    <varname>hot_standby_feedback</varname> feedback is not being provided.
    For example, consider increasing <varname>max_standby_archive_delay</varname>
    so that queries are not rapidly canceled by conflicts in WAL archive
    files during disconnected periods.  You should also consider increasing
    <varname>max_standby_streaming_delay</varname> to avoid rapid cancellations
    by newly-arrived streaming WAL entries after reconnection.
-->
スタンバイにおける問い合わせの中断が受け入れがたいほど多い場合、この問題を改善する方法が用意されています。
１つ目の選択肢は、<varname>hot_standby_feedback</varname>パラメータを設定することです。
これは<command>VACUUM</command>による最近不要になった行の削除を防止しますので、消去によるコンフリクトが発生しません。
これを行う場合、プライマリで不要になった行の消去が遅延することに注意が必要です。望まないテーブルの膨張が発生してしまうかもしれません。
しかし、スタンバイ側で行うべき問い合わせをプライマリサーバ上で直接実行することと比べ、こうした消去に関する問題を優先する価値はありません。
また、スタンバイに実行負荷を分散できるという利点があります。
スタンバイサーバが接続、切断を頻繁に繰り返す場合、<varname>hot_standby_feedback</varname>によるフィードバックが提供されていなければ、その値を調整したいと思うでしょう。
例えば、<varname>max_standby_archive_delay</varname>が増大し、切断している期間WALアーカイブのコンフリクト発生による問い合わせの中断が速やかに行われないことを考えてみてください。また、再接続後に速やかに問い合わせが中断されることを避けるために<varname>max_standby_streaming_delay</varname>を大きくすることを考えてみてください。
   </para>

   <para>
<!--
    Another option is to increase <xref linkend="guc-vacuum-defer-cleanup-age"/>
    on the primary server, so that dead rows will not be cleaned up as quickly
    as they normally would be.  This will allow more time for queries to
    execute before they are canceled on the standby, without having to set
    a high <varname>max_standby_streaming_delay</varname>.  However it is
    difficult to guarantee any specific execution-time window with this
    approach, since <varname>vacuum_defer_cleanup_age</varname> is measured in
    transactions executed on the primary server.
-->
他の選択肢は、不要になった行が通常よりも早く消去されないようにプライマリサーバで<xref linkend="guc-vacuum-defer-cleanup-age"/>を増やすことです。
これにより、<varname>max_standby_streaming_delay</varname>を長くすることなく、スタンバイでキャンセルが起こるようになる前により多くの時間、問い合わせを実行することができます。
しかし、<varname>vacuum_defer_cleanup_age</varname>はプライマリサーバ上で実行されたトランザクションを単位に測定されますので、この方法では特定の実行期間を保証することは困難です。
   </para>

   <para>
<!--
    The number of query cancels and the reason for them can be viewed using
    the <structname>pg_stat_database_conflicts</structname> system view on the standby
    server. The <structname>pg_stat_database</structname> system view also contains
    summary information.
-->
問い合わせキャンセルの個数とその原因はスタンバイサーバ上の<structname>pg_stat_database_conflicts</structname>システムビューを用いて参照することができます。
また<structname>pg_stat_database</structname>システムビューには要約された情報が含まれます。
   </para>

   <para>
    Users can control whether a log message is produced when WAL replay is waiting
    longer than <varname>deadlock_timeout</varname> for conflicts. This
    is controlled by the <xref linkend="guc-log-recovery-conflict-waits"/> parameter.
   </para>
  </sect2>

  <sect2 id="hot-standby-admin">
<!--
   <title>Administrator's Overview</title>
-->
   <title>管理者のための概説</title>

   <para>
<!--
    If <varname>hot_standby</varname> is <literal>on</literal> in <filename>postgresql.conf</filename>
    (the default value) and there is a
    <link linkend="file-standby-signal"><filename>standby.signal</filename></link><indexterm><primary>standby.signal</primary><secondary>for hot standby</secondary></indexterm>
    file present, the server will run in Hot Standby mode.
    However, it may take some time for Hot Standby connections to be allowed,
    because the server will not accept connections until it has completed
    sufficient recovery to provide a consistent state against which queries
    can run.  During this period,
    clients that attempt to connect will be refused with an error message.
    To confirm the server has come up, either loop trying to connect from
    the application, or look for these messages in the server logs:
-->
<filename>postgresql.conf</filename>において<varname>hot_standby</varname>が<literal>on</literal>で（これはデフォルトです）、かつ<filename>standby.signal</filename>が存在すれば、サーバはホットスタンバイモードで稼動します。
しかし、サーバはまず問い合わせが実行できる程度の一貫性を持つ状態を提供するために十分なリカバリを完了させなければなりませんので、ホットスタンバイでの接続が有効になるまでに多少の時間がかかるかもしれません。
サーバの準備ができたことを確認するために、アプリケーションで接続試行を繰り返すか、サーバログに以下のメッセージがあるかどうかを確認します。

<programlisting>
LOG:  entering standby mode

<!--
... then some time later ...
-->
... 多少時間が経過して ...

LOG:  consistent recovery state reached
LOG:  database system is ready to accept read-only connections
</programlisting>

<!--
    Consistency information is recorded once per checkpoint on the primary.
    It is not possible to enable hot standby when reading WAL
    written during a period when <varname>wal_level</varname> was not set to
    <literal>replica</literal> or <literal>logical</literal> on the primary.  Reaching
    a consistent state can also be delayed in the presence of both of these
    conditions:

-->
一貫性に関する情報はプライマリでチェックポイント毎に一回記録されます。
プライマリで<varname>wal_level</varname>が<literal>replica</literal>もしくは<literal>logical</literal>に設定されていなかった期間に書き込まれたWALを読み取っている間は、ホットスタンバイを有効にすることはできません。
また、一貫性のある状態への到達は、以下の両方が存在する間遅延することがあります。
      <itemizedlist>
       <listitem>
        <para>
<!--
         A write transaction has more than 64 subtransactions
-->
サブトランザクション数が64を超える書き込みトランザクション
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Very long-lived write transactions
-->
非常に長く実行される書き込みトランザクション
        </para>
       </listitem>
      </itemizedlist>

<!--
    If you are running file-based log shipping ("warm standby"), you might need
    to wait until the next WAL file arrives, which could be as long as the
    <varname>archive_timeout</varname> setting on the primary.
-->
ファイルベースのログシッピング(「ウォームスタンバイ」)を実行しているのであれば、次のWALファイルが届く、長くともプライマリの<varname>archive_timeout</varname>設定まで待機しなければなりません。
   </para>

   <para>
<!--
    The settings of some parameters determine the size of shared memory for
    tracking transaction IDs, locks, and prepared transactions.  These shared
    memory structures must be no smaller on a standby than on the primary in
    order to ensure that the standby does not run out of shared memory during
    recovery.  For example, if the primary had used a prepared transaction but
    the standby had not allocated any shared memory for tracking prepared
    transactions, then recovery could not continue until the standby's
    configuration is changed.  The parameters affected are:
-->
プライマリサーバにおける設定値を変更した場合、スタンバイサーバにおいて数個のパラメータの再設定が必要です。
スタンバイサーバにおける設定値は、プライマリサーバにおける設定値以上でなければなりません。
ですから、これらの値を増やしたいなら、プライマリで設定を変更する前に、まずスタンバイで設定変更するべきです。
逆にこれらの値を減らしたいなら、スタンバイで設定を変更する前に、まずプライマリで設定変更するべきです。
これらのパラメータが所定値未満の設定の場合、スタンバイは起動を取りやめます。
所定値以上の設定により、スタンバイサーバは再起動してリカバリが再び開始されます。
このパラメータは以下です。

      <itemizedlist>
       <listitem>
        <para>
         <varname>max_connections</varname>
        </para>
       </listitem>
       <listitem>
        <para>
         <varname>max_prepared_transactions</varname>
        </para>
       </listitem>
       <listitem>
        <para>
         <varname>max_locks_per_transaction</varname>
        </para>
       </listitem>
       <listitem>
        <para>
         <varname>max_wal_senders</varname>
        </para>
       </listitem>
       <listitem>
        <para>
         <varname>max_worker_processes</varname>
        </para>
       </listitem>
      </itemizedlist>

    The easiest way to ensure this does not become a problem is to have these
    parameters set on the standbys to values equal to or greater than on the
    primary.  Therefore, if you want to increase these values, you should do
    so on all standby servers first, before applying the changes to the
    primary server.  Conversely, if you want to decrease these values, you
    should do so on the primary server first, before applying the changes to
    all standby servers.  Keep in mind that when a standby is promoted, it
    becomes the new reference for the required parameter settings for the
    standbys that follow it.  Therefore, to avoid this becoming a problem
    during a switchover or failover, it is recommended to keep these settings
    the same on all standby servers.
   </para>

   <para>
    The WAL tracks changes to these parameters on the
    primary.  If a hot standby processes WAL that indicates that the current
    value on the primary is higher than its own value, it will log a warning
    and pause recovery, for example:
<screen>
WARNING:  hot standby is not possible because of insufficient parameter settings
DETAIL:  max_connections = 80 is a lower setting than on the primary server, where its value was 100.
LOG:  recovery has paused
DETAIL:  If recovery is unpaused, the server will shut down.
HINT:  You can then restart the server after making the necessary configuration changes.
</screen>
    At that point, the settings on the standby need to be updated and the
    instance restarted before recovery can continue.  If the standby is not a
    hot standby, then when it encounters the incompatible parameter change, it
    will shut down immediately without pausing, since there is then no value
    in keeping it up.
   </para>

   <para>
<!--
    It is important that the administrator select appropriate settings for
    <xref linkend="guc-max-standby-archive-delay"/> and <xref
    linkend="guc-max-standby-streaming-delay"/>.  The best choices vary
    depending on business priorities.  For example if the server is primarily
    tasked as a High Availability server, then you will want low delay
    settings, perhaps even zero, though that is a very aggressive setting. If
    the standby server is tasked as an additional server for decision support
    queries then it might be acceptable to set the maximum delay values to
    many hours, or even -1 which means wait forever for queries to complete.
-->
<xref linkend="guc-max-standby-archive-delay"/>および<xref linkend="guc-max-standby-streaming-delay"/>の値が適切であるように管理者が選択することが重要です。
最善の選択は業務上の優先順位によって変化します。
例えば、サーバが主に高可用性を目的としたサーバとして作業するものであれば、短い遅延を設定したいでしょう。
非常に積極的な設定ですが、ゼロにしたいかもしれません。
スタンバイサーバが意思決定支援のための問い合わせ用の追加サーバとして作業するものであれば、数時間程度の最大の遅延値の設定、あるいは問い合わせの完了を永遠に待つことを意味する-1という設定でさえ、許容範囲であるかもしれません。
   </para>

   <para>
<!--
    Transaction status "hint bits" written on the primary are not WAL-logged,
    so data on the standby will likely re-write the hints again on the standby.
    Thus, the standby server will still perform disk writes even though
    all users are read-only; no changes occur to the data values
    themselves.  Users will still write large sort temporary files and
    re-generate relcache info files, so no part of the database
    is truly read-only during hot standby mode.
    Note also that writes to remote databases using
    <application>dblink</application> module, and other operations outside the
    database using PL functions will still be possible, even though the
    transaction is read-only locally.
-->
プライマリ側で「ヒントビット」として書き出されたトランザクション状態はWALに記録されません。
このためスタンバイ側のデータはスタンバイ側でヒントを再度書き出すことになります。
ユーザは大規模なソート用の一時ファイルを書き出し、relcache情報ファイルを再作成します。
したがって、ホットスタンバイモードではデータベースのすべてが本当に読み取り専用ではありません。
また、ローカルでは読み取り専用のトランザクションであっても<application>dblink</application>モジュールを使用したリモートデータベースへの書き出しや、その他のPL関数を使用したデータベース外部への操作が可能であることに注意してください。
   </para>

   <para>
<!--
    The following types of administration commands are not accepted
    during recovery mode:
-->
リカバリモードの間、下記の管理者用コマンドは受理されません。

      <itemizedlist>
       <listitem>
        <para>
<!--
         Data Definition Language (DDL): e.g., <command>CREATE INDEX</command>
-->
データ定義言語: 例えば<command>CREATE INDEX</command>
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Privilege and Ownership: <command>GRANT</command>, <command>REVOKE</command>,
         <command>REASSIGN</command>
-->
権限および所有権: <command>GRANT</command>と<command>REVOKE</command>と<command>REASSIGN</command>
        </para>
       </listitem>
       <listitem>
        <para>
<!--
         Maintenance commands: <command>ANALYZE</command>, <command>VACUUM</command>,
         <command>CLUSTER</command>, <command>REINDEX</command>
-->
保守コマンド: <command>ANALYZE</command>と<command>VACUUM</command>と<command>CLUSTER</command>と<command>REINDEX</command>
        </para>
       </listitem>
      </itemizedlist>
   </para>

   <para>
<!--
    Again, note that some of these commands are actually allowed during
    "read only" mode transactions on the primary.
-->
繰り返しますが、これらのコマンドの一部は、プライマリサーバにおける「読み取り専用」モードのトランザクションで実際に許可されていることに注意してください。
   </para>

   <para>
<!--
    As a result, you cannot create additional indexes that exist solely
    on the standby, nor statistics that exist solely on the standby.
    If these administration commands are needed, they should be executed
    on the primary, and eventually those changes will propagate to the
    standby.
-->
その結果、スタンバイ側にのみ存在する追加のインデックスやスタンバイ側にのみ存在する統計情報を作成することはできません。
これらの管理者用コマンドが必要な場合、プライマリ側で実行しなければなりません。
最終的にこの変更はスタンバイ側に伝播します。
   </para>

   <para>
<!--
    <function>pg_cancel_backend()</function>
    and <function>pg_terminate_backend()</function> will work on user backends,
    but not the Startup process, which performs
    recovery. <structname>pg_stat_activity</structname> does not show
    recovering transactions as active. As a result,
    <structname>pg_prepared_xacts</structname> is always empty during
    recovery. If you wish to resolve in-doubt prepared transactions, view
    <literal>pg_prepared_xacts</literal> on the primary and issue commands to
    resolve transactions there or resolve them after the end of recovery.
-->
<function>pg_cancel_backend()</function>と<function>pg_terminate_backend()</function>は利用者のバックエンドでは実行できますが、リカバリを実行する起動プロセスでは実行できません。
<structname>pg_stat_activity</structname>はリカバリ中のトランザクションをアクティブとして表示しません。
その結果、リカバリの間<structname>pg_prepared_xacts</structname>は常に空となります。
調査が必要な準備されたトランザクションがある場合は、プライマリサーバにおいて<literal>pg_prepared_xacts</literal>を表示し、その場でトランザクションを解決するか、リカバリが終わるのを待ってからトランザクションを解決します。
   </para>

   <para>
<!--
    <structname>pg_locks</structname> will show locks held by backends,
    as normal. <structname>pg_locks</structname> also shows
    a virtual transaction managed by the Startup process that owns all
    <literal>AccessExclusiveLocks</literal> held by transactions being replayed by recovery.
    Note that the Startup process does not acquire locks to
    make database changes, and thus locks other than <literal>AccessExclusiveLocks</literal>
    do not show in <structname>pg_locks</structname> for the Startup
    process; they are just presumed to exist.
-->
<structname>pg_locks</structname>は通常通りバックエンドで保持されるロックを示します。
<structname>pg_locks</structname>はまた、リカバリによって再生されているトランザクションで保持される<literal>AccessExclusiveLocks</literal>のすべてを所有する、起動プロセスで管理される仮想トランザクションも表示します。
起動プロセスはデータベースの変更を行うためのロックを獲得しません。
このため起動プロセスにおいて<literal>AccessExclusiveLocks</literal>以外のロックは<structname>pg_locks</structname>では表示されません。
これらは存在することを想定されているだけです。
   </para>

   <para>
<!--
    The <productname>Nagios</productname> plugin <productname>check_pgsql</productname> will
    work, because the simple information it checks for exists.
    The <productname>check_postgres</productname> monitoring script will also work,
    though some reported values could give different or confusing results.
    For example, last vacuum time will not be maintained, since no
    vacuum occurs on the standby.  Vacuums running on the primary
    do still send their changes to the standby.
-->
存在を検知する情報が単純なので、<productname>Nagios</productname>プラグインは稼動します。
一部の報告値が異なった、混乱を招く結果となりますが、<productname>check_postgres</productname>の監視スクリプトも動作します。
それでも、プライマリで行われるバキュームはその変更をスタンバイに送信します。
   </para>

   <para>
<!--
    WAL file control commands will not work during recovery,
    e.g., <function>pg_start_backup</function>, <function>pg_switch_wal</function> etc.
-->
リカバリの間WALの制御コマンドは稼動しません。
例えば、<function>pg_start_backup</function>や<function>pg_switch_wal</function>などです。
   </para>

   <para>
<!--
    Dynamically loadable modules work, including <structname>pg_stat_statements</structname>.
-->
<structname>pg_stat_statements</structname>も含み、動的に読み込み可能なモジュールは稼動します。
   </para>

   <para>
<!--
    Advisory locks work normally in recovery, including deadlock detection.
    Note that advisory locks are never WAL logged, so it is impossible for
    an advisory lock on either the primary or the standby to conflict with WAL
    replay. Nor is it possible to acquire an advisory lock on the primary
    and have it initiate a similar advisory lock on the standby. Advisory
    locks relate only to the server on which they are acquired.
訳者注、advisory lockはアドバイザリロックとした
-->
デッドロック検出を含むアドバイザリロックは、通常リカバリにおいて稼動します。
アドバイザリロックはWALに決して記録されないので、プライマリサーバでもスタンバイサーバでもWALの再実行においてコンフリクトが起こらないことに注意してください。
プライマリサーバでアドバイザリロックを取得して、スタンバイサーバで同様のアドバイザリロックを掛けることはできません。
アドバイザリロックは取得したサーバだけに関係するものです。
   </para>

   <para>
<!--
    Trigger-based replication systems such as <productname>Slony</productname>,
    <productname>Londiste</productname> and <productname>Bucardo</productname> won't run on the
    standby at all, though they will run happily on the primary server as
    long as the changes are not sent to standby servers to be applied.
    WAL replay is not trigger-based so you cannot relay from the
    standby to any system that requires additional database writes or
    relies on the use of triggers.
-->
<productname>Slony</productname>や<productname>Londiste</productname>や<productname>Bucardo</productname>のようにトリガに基づいたレプリケーションシステムは、スタンバイサーバで全く稼動しません。
しかし、それによる変更がスタンバイサーバに送られるまでは、プライマリサーバにおいて問題なく稼動します。
WALの再実行はトリガに基づいたものではありません。
したがって、データベースへの付加的な書き込みを必要とするか、トリガの使用に依存するものを、スタンバイサーバを中継して他のシステムへ送ることはできません。
   </para>

   <para>
<!--
    New OIDs cannot be assigned, though some <acronym>UUID</acronym> generators may still
    work as long as they do not rely on writing new status to the database.
-->
一部の<acronym>UUID</acronym>ジェネレータは、データベースに新しい状態を書き出すことに依存していない限り動作可能ですが、新しいOIDを割り当てることはできません。
   </para>

   <para>
<!--
    Currently, temporary table creation is not allowed during read-only
    transactions, so in some cases existing scripts will not run correctly.
    This restriction might be relaxed in a later release. This is
    both an SQL Standard compliance issue and a technical issue.
-->
現時点では、読み取り専用のトランザクションでは一時テーブルの作成は許されません。
このため既存のスクリプトが正しく動作しない場合があります。
この制限は将来のリリースで緩和されるかもしれません。
これは、標準SQLとの互換性の問題でもあり、技術的な問題でもあります。
   </para>

   <para>
<!--
    <command>DROP TABLESPACE</command> can only succeed if the tablespace is empty.
    Some standby users may be actively using the tablespace via their
    <varname>temp_tablespaces</varname> parameter. If there are temporary files in the
    tablespace, all active queries are canceled to ensure that temporary
    files are removed, so the tablespace can be removed and WAL replay
    can continue.
-->
テーブル空間が空の場合だけ、<command>DROP TABLESPACE</command>が成功します。
一部のスタンバイ側のユーザは<varname>temp_tablespaces</varname>パラメータを介してテーブル空間を活発に使用しているかもしれません。
テーブル空間に一時ファイルが存在する場合、一時ファイルを確実に削除するためすべての問い合わせが取り消されます。
このため、WAL再生を続けながらテーブル空間を削除することができます。
   </para>

   <para>
<!--
    Running <command>DROP DATABASE</command> or <command>ALTER DATABASE ... SET
    TABLESPACE</command> on the primary
    will generate a WAL entry that will cause all users connected to that
    database on the standby to be forcibly disconnected. This action occurs
    immediately, whatever the setting of
    <varname>max_standby_streaming_delay</varname>. Note that
    <command>ALTER DATABASE ... RENAME</command> does not disconnect users, which
    in most cases will go unnoticed, though might in some cases cause a
    program confusion if it depends in some way upon database name.
-->
プライマリサーバにおける<command>DROP DATABASE</command>または<command>ALTER DATABASE ... SET TABLESPACE</command>の実行により、スタンバイサーバのデータベースに接続するすべてのユーザを強制的に接続を切断させることになるWALエントリを生成します。
これは<varname>max_standby_streaming_delay</varname>の設定にかかわらず、直ちに起こります。
<command>ALTER DATABASE ... RENAME</command>はユーザを切断しないので大部分の場合は気がつきませんが、プログラムがデータベースの名称に依存するときは混乱の原因となることに注意してください。
   </para>

   <para>
<!--
    In normal (non-recovery) mode, if you issue <command>DROP USER</command> or <command>DROP ROLE</command>
    for a role with login capability while that user is still connected then
    nothing happens to the connected user &mdash; they remain connected. The user cannot
    reconnect however. This behavior applies in recovery also, so a
    <command>DROP USER</command> on the primary does not disconnect that user on the standby.
-->
通常の(リカバリ以外の)モードで、ログイン権限を持つロールが接続している間にそのロールに<command>DROP USER</command>または<command>DROP ROLE</command>を発行した場合、接続中のユーザには何も起こらず、接続し続けます。
しかし、そのユーザは再接続できません。
この振舞いはリカバリモードでも適用されます。
このためプライマリ側で<command>DROP USER</command>されたとしても、スタンバイ側のユーザの接続は切断されません。
   </para>

   <para>
<!--
    The statistics collector is active during recovery. All scans, reads, blocks,
    index usage, etc., will be recorded normally on the standby. Replayed
    actions will not duplicate their effects on primary, so replaying an
    insert will not increment the Inserts column of pg_stat_user_tables.
    The stats file is deleted at the start of recovery, so stats from primary
    and standby will differ; this is considered a feature, not a bug.
-->
リカバリの間も統計情報は収集されます。
すべてのスキャン、読み取り、ブロック、インデックスの使用などは、スタンバイサーバにおいて正常に記録されます。
再実行によりプライマリサーバの結果が重複して収集されることはないので、行の挿入によりpg_stat_user_tablesの挿入列の値は増加しません。
リカバリの開始時点で統計情報ファイルが削除されるので、プライマリサーバとスタンバイサーバで統計情報は異なります。
これは将来どうするか検討中であり、バグではありません。
   </para>

   <para>
<!--
    Autovacuum is not active during recovery.  It will start normally at the
    end of recovery.
-->
リカバリの間は自動バキュームは稼動しません。
リカバリが終わると正常に起動します。
   </para>

   <para>
<!--
    The checkpointer process and the background writer process are active during
    recovery. The checkpointer process will perform restartpoints (similar to
    checkpoints on the primary) and the background writer process will perform
    normal block cleaning activities. This can include updates of the hint bit
    information stored on the standby server.
    The <command>CHECKPOINT</command> command is accepted during recovery,
    though it performs a restartpoint rather than a new checkpoint.
-->
リカバリの間、チェックポイントプロセスとバックグラウンドライタプロセスは稼動しています。
チェックポイントプロセスは（プライマリサーバにおけるチェックポイントに類似した）リスタートポイントを設定し、通常のブロック消去を行います。
これはスタンバイサーバに保存されるヒントビット情報の更新を含むことができます。
リカバリの間<command>CHECKPOINT</command>コマンドは受理されますが、新規のチェックポイントではなくてリスタートポイントが設定されます。
   </para>
  </sect2>

  <sect2 id="hot-standby-parameters">
<!--
   <title>Hot Standby Parameter Reference</title>
-->
   <title>ホットスタンバイパラメータリファレンス</title>

   <para>
<!--
    Various parameters have been mentioned above in
    <xref linkend="hot-standby-conflict"/> and
    <xref linkend="hot-standby-admin"/>.
-->
種々のパラメータが上記<xref linkend="hot-standby-conflict"/>および<xref linkend="hot-standby-admin"/>で述べられています。
   </para>

   <para>
<!--
    On the primary, parameters <xref linkend="guc-wal-level"/> and
    <xref linkend="guc-vacuum-defer-cleanup-age"/> can be used.
    <xref linkend="guc-max-standby-archive-delay"/> and
    <xref linkend="guc-max-standby-streaming-delay"/> have no effect if set on
    the primary.
-->
プライマリサーバでは、<xref linkend="guc-wal-level"/>および<xref linkend="guc-vacuum-defer-cleanup-age"/>のパラメータを使用できます。
プライマリサーバに<xref linkend="guc-max-standby-archive-delay"/>および<xref linkend="guc-max-standby-streaming-delay"/>を設定しても無効です。
   </para>

   <para>
<!--
    On the standby, parameters <xref linkend="guc-hot-standby"/>,
    <xref linkend="guc-max-standby-archive-delay"/> and
    <xref linkend="guc-max-standby-streaming-delay"/> can be used.
    <xref linkend="guc-vacuum-defer-cleanup-age"/> has no effect
    as long as the server remains in standby mode, though it will
    become relevant if the standby becomes primary.
-->
スタンバイサーバでは<xref linkend="guc-hot-standby"/>と<xref linkend="guc-max-standby-archive-delay"/>と<xref linkend="guc-max-standby-streaming-delay"/>のパラメータを使用できます。
サーバがスタンバイモードの間<xref linkend="guc-vacuum-defer-cleanup-age"/>を設定しても無効です。
しかし、スタンバイサーバがプライマリサーバになった場合、意味を持つようになります。
   </para>
  </sect2>

  <sect2 id="hot-standby-caveats">
<!--
   <title>Caveats</title>
-->
   <title>警告</title>

   <para>
<!--
    There are several limitations of Hot Standby.
    These can and probably will be fixed in future releases:
-->
ホットスタンバイには幾つかの制限があります。
将来のリリースでは改善されると思われます。

  <itemizedlist>
   <listitem>
    <para>
<!--
     Full knowledge of running transactions is required before snapshots
     can be taken. Transactions that use large numbers of subtransactions
     (currently greater than 64) will delay the start of read-only
     connections until the completion of the longest running write transaction.
     If this situation occurs, explanatory messages will be sent to the server log.
-->
スナップショットを取ることができるようになる前に、実行中のトランザクションについての完全な知識が要求されます。
(現時点では64を超える)多くのサブトランザクションを使用するトランザクションでは、実行中の最長の書き込みトランザクションが完了するまで、読み取り専用の接続の開始は遅延されます。
この状況が起こると、それを説明するメッセージがサーバログに記録されます。
    </para>
   </listitem>
   <listitem>
    <para>
<!--
     Valid starting points for standby queries are generated at each
     checkpoint on the primary. If the standby is shut down while the primary
     is in a shutdown state, it might not be possible to re-enter Hot Standby
     until the primary is started up, so that it generates further starting
     points in the WAL logs.  This situation isn't a problem in the most
     common situations where it might happen. Generally, if the primary is
     shut down and not available anymore, that's likely due to a serious
     failure that requires the standby being converted to operate as
     the new primary anyway.  And in situations where the primary is
     being intentionally taken down, coordinating to make sure the standby
     becomes the new primary smoothly is also standard procedure.
-->
スタンバイ問い合わせ用の有効な起動ポイントは、マスタにおけるチェックポイント毎に生成されます。
マスタが停止状態にある時にスタンバイが停止した場合、プライマリが起動し、さらに起動ポイントをWALログに生成するまで再度ホットスタンバイになることができないことがあります。
この状況は、通常考えられる状態では問題ではありません。
一般的に、プライマリが停止し利用できなくなった場合、それはスタンバイに対して新しいプライマリに切り替わることを要求するような深刻な失敗が原因であることが多いはずです。
また、プライマリを意図的に停止させるような状況では、それに伴いスタンバイが新しいプライマリになめらかに切り替わることも普通の手順です。
    </para>
   </listitem>
   <listitem>
    <para>
<!--
     At the end of recovery, <literal>AccessExclusiveLocks</literal> held by prepared transactions
     will require twice the normal number of lock table entries. If you plan
     on running either a large number of concurrent prepared transactions
     that normally take <literal>AccessExclusiveLocks</literal>, or you plan on having one
     large transaction that takes many <literal>AccessExclusiveLocks</literal>, you are
     advised to select a larger value of <varname>max_locks_per_transaction</varname>,
     perhaps as much as twice the value of the parameter on
     the primary server. You need not consider this at all if
     your setting of <varname>max_prepared_transactions</varname> is 0.
-->
リカバリの終了において、準備されたトランザクションが保持する<literal>AccessExclusiveLocks</literal>には、通常の2倍のロックテーブルへのエントリ数が必要です。
通常<literal>AccessExclusiveLocks</literal>を取るプリペアドトランザクションを大量に同時実行させる、または、多くの<literal>AccessExclusiveLocks</literal>を取る大規模なトランザクションを1つ実行させることを考えている場合、<varname>max_locks_per_transaction</varname>の値を、おそらくプライマリサーバのパラメータ値の倍程度に大きくすることを勧めます。
<varname>max_prepared_transactions</varname>の設定が0ならば、これを検討する必要はまったくありません。
    </para>
   </listitem>
   <listitem>
    <para>
<!--
     The Serializable transaction isolation level is not yet available in hot
     standby.  (See <xref linkend="xact-serializable"/> and
     <xref linkend="serializable-consistency"/> for details.)
     An attempt to set a transaction to the serializable isolation level in
     hot standby mode will generate an error.
-->
シリアライザブルトランザクション隔離レベルはまだホットスタンバイでは利用できません。
（<xref linkend="xact-serializable"/>および<xref linkend="serializable-consistency"/>参照）
ホットスタンバイにおいてトランザクションをシリアライザブルトランザクション隔離レベルに設定しようとすると、エラーになります。
    </para>
   </listitem>
  </itemizedlist>

   </para>
  </sect2>

 </sect1>

</chapter>
