<!-- doc/src/sgml/wal.sgml -->

<chapter id="wal">
<!--
 <title>Reliability and the Write-Ahead Log</title>
-->
 <title>信頼性と先行書き込みログ（WAL）</title>

 <para>
<!--
  This chapter explains how to control the reliability of
  <productname>PostgreSQL</productname>, including details about the
  Write-Ahead Log.
-->
本章では、先行書き込みログに関する詳細を含めて、<productname>PostgreSQL</productname>の信頼性を制御する方法を説明します。
 </para>

 <sect1 id="wal-reliability">
<!--
  <title>Reliability</title>
-->
  <title>信頼性</title>

  <para>
<!--
   Reliability is an important property of any serious database
   system, and <productname>PostgreSQL</productname> does everything possible to
   guarantee reliable operation. One aspect of reliable operation is
   that all data recorded by a committed transaction should be stored
   in a nonvolatile area that is safe from power loss, operating
   system failure, and hardware failure (except failure of the
   nonvolatile area itself, of course).  Successfully writing the data
   to the computer's permanent storage (disk drive or equivalent)
   ordinarily meets this requirement.  In fact, even if a computer is
   fatally damaged, if the disk drives survive they can be moved to
   another computer with similar hardware and all committed
   transactions will remain intact.
-->
信頼性は、すべての本格的なデータベースシステムで重要な特性です。
<productname>PostgreSQL</productname>は信頼できる操作を保証するためにできることは何でもします。
信頼できる操作の一面は、コミットされたトランザクションにより記録されたデータはすべて不揮発性の領域に格納され、電源断、オペレーティングシステムの障害、ハードウェアの障害（当然ですが、不揮発性の領域自体の障害は除きます。）があっても安全であるという点です。
通常、コンピュータの永続的格納領域（ディスク装置など）へのデータ書き込みの成功がこの条件を満たします。
実際、コンピュータに致命的な障害が発生したとしても、もしディスク装置が無事ならば、類似のハードウェアを持つ別のコンピュータに移すことができ、コミットされたトランザクションを元通りに復元できます。
  </para>

  <para>
<!--
   While forcing data to the disk platters periodically might seem like
   a simple operation, it is not. Because disk drives are dramatically
   slower than main memory and CPUs, several layers of caching exist
   between the computer's main memory and the disk platters.
   First, there is the operating system's buffer cache, which caches
   frequently requested disk blocks and combines disk writes. Fortunately,
   all operating systems give applications a way to force writes from
   the buffer cache to disk, and <productname>PostgreSQL</productname> uses those
   features.  (See the <xref linkend="guc-wal-sync-method"/> parameter
   to adjust how this is done.)
-->
データを周期的にディスクプラッタに書き出すことは簡単な操作に思われるかもしれませんが、そうではありません。
ディスク装置は主メモリ、CPU、コンピュータの主メモリとディスクプラッタの間にある各種のキャッシュ層と比べ非常に低速であるからです。
まず、オペレーティングシステムのバッファキャッシュが存在します。
これは頻繁にアクセス要求があるディスクブロックをキャッシュし、ディスクへの書き込みをまとめます。
好運にもすべてのオペレーティングシステムがバッファキャッシュをディスクに強制書き込みさせる方法をアプリケーションに提供しています。
<productname>PostgreSQL</productname>はこの機能を使用します。
（これを調整する方法については<xref linkend="guc-wal-sync-method"/>パラメータを参照してください。）
  </para>

  <para>
<!--
   Next, there might be a cache in the disk drive controller; this is
   particularly common on <acronym>RAID</acronym> controller cards. Some of
   these caches are <firstterm>write-through</firstterm>, meaning writes are sent
   to the drive as soon as they arrive. Others are
   <firstterm>write-back</firstterm>, meaning data is sent to the drive at
   some later time. Such caches can be a reliability hazard because the
   memory in the disk controller cache is volatile, and will lose its
   contents in a power failure.  Better controller cards have
   <firstterm>battery-backup units</firstterm> (<acronym>BBU</acronym>s), meaning
   the card has a battery that
   maintains power to the cache in case of system power loss.  After power
   is restored the data will be written to the disk drives.
-->
次に、ディスク装置のコントローラキャッシュが存在する可能性があります。
特に、<acronym>RAID</acronym>コントローラカードでは、これは一般的です。
これらの中には<firstterm>write-through</firstterm>キャッシュがあり、つまり、データが届いた時に即座に書き込みがディスク装置に対して行なわれます。
他には<firstterm>write-back</firstterm>キャッシュがあり、多少遅れて書き込みがディスク装置に対して行なわれます。
こうしたキャッシュでは、ディスクコントローラキャッシュが揮発性で、電源障害の際にその内容が失われてしまい、信頼性に関して致命的な問題になる可能性があります。
より優れたコントローラカードには<firstterm>バッテリバックアップ付き装置</firstterm>(<acronym>BBU</acronym>s)があり、システムの電源が落ちた場合もキャッシュに電源を供給します。
後で電源が復旧した後に、データがディスク装置に書き出されます。
  </para>

  <para>
<!--
   And finally, most disk drives have caches. Some are write-through
   while some are write-back, and the same concerns about data loss
   exist for write-back drive caches as for disk controller
   caches.  Consumer-grade IDE and SATA drives are particularly likely
   to have write-back caches that will not survive a power failure.  Many
   solid-state drives (SSD) also have volatile write-back caches.
-->
最後に、ほとんどのディスク装置がキャッシュを持っています。一部はwrite-throughであり、一部はwrite-backです。
ディスクコントローラキャッシュの場合と同様にwrite-backのディスク装置キャッシュの場合にはデータが損失する恐れがあります。
一般消費者向けのIDEおよびSATA装置では、電源障害時にデータが残らないwrite-backキャッシュを使用している可能性がとりわけ高いです。
多くのソリッドステートドライブ(SSD)も同様に揮発性のwrite-backキャッシュを持っています。
  </para>

  <para>
<!--
   These caches can typically be disabled; however, the method for doing
   this varies by operating system and drive type:
-->
これらのキャッシュは、大抵は無効にできます。しかしながらオペレーティングシステムやドライブの種類によってその方法は異なります。
  </para>

  <itemizedlist>
    <listitem>
      <para>
<!--
        On <productname>Linux</productname>, IDE and SATA drives can be queried using
        <command>hdparm -I</command>; write caching is enabled if there is
        a <literal>*</literal> next to <literal>Write cache</literal>.  <command>hdparm -W 0</command>
        can be used to turn off write caching.  SCSI drives can be queried
        using <ulink url="http://sg.danny.cz/sg/sdparm.html"><application>sdparm</application></ulink>.
        Use <command>sdparm &#45;-get=WCE</command> to check
        whether the write cache is enabled and <command>sdparm &#45;-clear=WCE</command>
        to disable it.
-->
<productname>Linux</productname>上で<command>hdparm -I</command>を使用することでIDEおよびSATAドライブのキャッシュについて調べることができます。
<literal>Write cache</literal>の次に <literal>*</literal>があれば書き込みキャッシュが有効になっています。
<command>hdparm -W 0</command>により書き込みキャッシュを無効にできます。
SCSIドライブであれば<ulink url="http://sg.danny.cz/sg/sdparm.html"><application>sdparm</application></ulink>を使うことで調査が可能です。
<command>sdparm --get=WCE</command>によりキャッシュが有効かどうかの確認ができ、<command>sdparm --clear=WCE</command>により無効にすることができます。
      </para>
    </listitem>

    <listitem>
      <para>
<!--
        On <productname>FreeBSD</productname>, IDE drives can be queried using
        <command>camcontrol identify</command> and write caching turned off using
        <literal>hw.ata.wc=0</literal> in <filename>/boot/loader.conf</filename>;
        SCSI drives can be queried using <command>camcontrol identify</command>,
        and the write cache both queried and changed using
        <command>sdparm</command> when available.
-->
<productname>FreeBSD</productname>では、IDEドライブに対して<command>camcontrol identify</command>により確認ができ、そして書き込みキャッシュを無効にするには<filename>/boot/loader.conf</filename>の<literal>hw.ata.wc=0</literal>を利用します。SCSIドライブに対しては<command>camcontrol identify</command>を確認に使用することができ、<command>sdparm</command>を使用できる場合にはそれを用いて書き込みキャッシュの確認と変更が可能です。
      </para>
    </listitem>

    <listitem>
      <para>
<!--
        On <productname>Solaris</productname>, the disk write cache is controlled by
        <command>format -e</command>.
        (The Solaris <acronym>ZFS</acronym> file system is safe with disk write-cache
        enabled because it issues its own disk cache flush commands.)
-->
<productname>Solaris</productname>では、ディスクの書き込みキャッシュは<command>format -e</command>で制御できます。
(Solarisの<acronym>ZFS</acronym>ファイルシステムは、独自のディスクキャッシュ書き出しコマンドを発行しているため、ディスクの書き込みキャッシュを有効にしても安全です。)
      </para>
    </listitem>

    <listitem>
      <para>
<!--
        On <productname>Windows</productname>, if <varname>wal_sync_method</varname> is
        <literal>open_datasync</literal> (the default), write caching can be disabled
        by unchecking <literal>My Computer\Open\<replaceable>disk drive</replaceable>\Properties\Hardware\Properties\Policies\Enable write caching on the disk</literal>.
        Alternatively, set <varname>wal_sync_method</varname> to
        <literal>fdatasync</literal> (NTFS only), <literal>fsync</literal> or
        <literal>fsync_writethrough</literal>, which prevent
        write caching.
-->
<productname>Windows</productname>では、もし<varname>wal_sync_method</varname>
が<literal>open_datasync</literal>(デフォルト)の場合、<literal>My Computer\Open\<replaceable>disk drive</replaceable>\Properties\Hardware\Properties\Policies\Enable write caching on the disk</literal>のチェックを外すことで、書き込みキャッシュを無効にできます。
もう一つの方法としては、<varname>wal_sync_method</varname>を<literal>fdatasync</literal>（NTFSのみ）、<literal>fsync</literal>または<literal>fsync_writethrough</literal>に設定し、書き込みキャッシュを使用しないようにします。
      </para>
    </listitem>

    <listitem>
      <para>
<!--
        On <productname>macOS</productname>, write caching can be prevented by
        setting <varname>wal_sync_method</varname> to <literal>fsync_writethrough</literal>.
-->
<productname>macOS</productname>では、<varname>wal_sync_method</varname>を<literal>fsync_writethrough</literal>に設定することで書き込みキャッシュを使用しないようにします。
      </para>
    </listitem>
  </itemizedlist>

  <para>
<!--
   Recent SATA drives (those following <acronym>ATAPI-6</acronym> or later)
   offer a drive cache flush command (<command>FLUSH CACHE EXT</command>),
   while SCSI drives have long supported a similar command
   <command>SYNCHRONIZE CACHE</command>.  These commands are not directly
   accessible to <productname>PostgreSQL</productname>, but some file systems
   (e.g., <acronym>ZFS</acronym>, <acronym>ext4</acronym>) can use them to flush
   data to the platters on write-back-enabled drives.  Unfortunately, such
   file systems behave suboptimally when combined with battery-backup unit
   (<acronym>BBU</acronym>) disk controllers.  In such setups, the synchronize
   command forces all data from the controller cache to the disks,
   eliminating much of the benefit of the BBU.  You can run the
   <xref linkend="pgtestfsync"/> program to see
   if you are affected.  If you are affected, the performance benefits
   of the BBU can be regained by turning off write barriers in
   the file system or reconfiguring the disk controller, if that is
   an option.  If write barriers are turned off, make sure the battery
   remains functional; a faulty battery can potentially lead to data loss.
   Hopefully file system and disk controller designers will eventually
   address this suboptimal behavior.
-->
最近のSATAドライブ(<acronym>ATAPI-6</acronym>またはそれ以降)はドライブキャッシュの書き出しコマンド(<command>FLUSH CACHE EXT</command>)を提供している一方、SCSIドライブでは従来から類似の<command>SYNCHRONIZE CACHE</command>コマンドをサポートしていました。
これらのコマンドは、直接<productname>PostgreSQL</productname>に発行されませんが、いくつかのファイルシステム(例えば<acronym>ZFS</acronym>や<acronym>ext4</acronym>)では、それらをwrite-backが有効なドライブへデータを書き出すために使います。
不幸なことに、このようなwriteバリアを持つファイルシステムは、バッテリバックアップ付き装置(<acronym>BBU</acronym>)のディスクコントローラと組み合わせた際に、好ましい動作をしません。
このような処理の流れにおいて、同期コマンドはコントローラキャッシュにあるデータを全てディスクへ強制的に書き込みを行うため、BBUのメリットの大半を失わせています。
<xref linkend="pgtestfsync"/>プログラムを使うことで、あなたの環境が影響を受けるかどうかを確認できます。
もし影響を受けるようであれば、ファイルシステムのwriteバリアを無効にするか、(オプションがあれば)ディスクコントローラを再設定することで、BBUによる性能上の効果を再び得ることができるでしょう。
もしwriteバリアを無効にした場合は、バッテリが動作していることを確認しておきましょう。バッテリの欠陥はデータロスの可能性に繋がります。
ファイルシステムやディスクコントローラの設計者が、いずれはこの動作を修正してくれることが望まれます。
  </para>

  <para>
<!--
   When the operating system sends a write request to the storage hardware,
   there is little it can do to make sure the data has arrived at a truly
   non-volatile storage area. Rather, it is the
   administrator's responsibility to make certain that all storage components
   ensure integrity for both data and file-system metadata.
   Avoid disk controllers that have non-battery-backed write caches.
   At the drive level, disable write-back caching if the
   drive cannot guarantee the data will be written before shutdown.
   If you use SSDs, be aware that many of these do not honor cache flush
   commands by default.
   You can test for reliable I/O subsystem behavior using <ulink
   url="https://brad.livejournal.com/2116715.html"><filename>diskchecker.pl</filename></ulink>.
-->
オペレーティングシステムが、ストレージハードウェアに書き込み要求を送信した時、データが不揮発性のストレージ領域に本当に届いたかどうかを確認することはほぼできません。
ですので、全てのストレージ構成品がデータとファイルシステムのメタデータの整合性を保証することをよく確認しておくことは、管理者の責任です。
バッテリバックアップされた書き込みキャッシュを持たないコントローラの使用は避けてください。
装置レベルでは、もし装置が停止前にデータが書き出されることを保証できないのであれば、write-backキャッシュを無効にしてください。
もしSSDを使っている場合、多くのドライブはデフォルトでキャッシュ書き出しコマンドを無視することに注意して下さい。
<ulink url="https://brad.livejournal.com/2116715.html"><filename>diskchecker.pl</filename></ulink>を使うことで、I/Oサブシステムの動作の信頼性をテストすることができます。
  </para>

  <para>
<!--
   Another risk of data loss is posed by the disk platter write
   operations themselves. Disk platters are divided into sectors,
   commonly 512 bytes each.  Every physical read or write operation
   processes a whole sector.
   When a write request arrives at the drive, it might be for some multiple
   of 512 bytes (<productname>PostgreSQL</productname> typically writes 8192 bytes, or
   16 sectors, at a time), and the process of writing could fail due
   to power loss at any time, meaning some of the 512-byte sectors were
   written while others were not.  To guard against such failures,
   <productname>PostgreSQL</productname> periodically writes full page images to
   permanent WAL storage <emphasis>before</emphasis> modifying the actual page on
   disk. By doing this, during crash recovery <productname>PostgreSQL</productname> can
   restore partially-written pages from WAL.  If you have file-system software
   that prevents partial page writes (e.g., ZFS),  you can turn off
   this page imaging by turning off the <xref
   linkend="guc-full-page-writes"/> parameter. Battery-Backed Unit
   (BBU) disk controllers do not prevent partial page writes unless
   they guarantee that data is written to the BBU as full (8kB) pages.
-->
ディスクプラッタの書き込み操作自体によってもデータ損失が発生することがあります。
ディスクプラッタは、通常512バイトのセクタに分割されています。
物理的な読み込み操作、書き込み操作はすべて、セクタ全体を処理します。
書き込み要求がディスクに達した時、その要求は512バイトの倍数になるでしょう(<productname>PostgreSQL</productname>では大抵一度に8192バイトすなわち16セクタを書き込みます)。そして電源断により、任意のタイミングで書き込み処理が失敗することがありえます。これは一部の512バイトのセクタに書き込みが行なわれたのに、残りのセクタには書き込みが行なわれていない状況を意味します。
こうした問題の対策として、<productname>PostgreSQL</productname>は、ディスク上の実際のページを変更する<emphasis>前</emphasis>に定期的にページ全体のイメージを永続的なWAL格納領域に書き出します。
これにより、<productname>PostgreSQL</productname>はクラッシュリカバリ時に部分的に書き出されたページをWALから復旧させることができます。
もし、部分的なページ書き込みを防止できるファイルシステムソフトウェア（例えばZFS）を使うのであれば、<xref linkend="guc-full-page-writes"/>を無効にしてページイメージ作成を無効にすることができます。バッテリバックアップ付き（BBU）のディスクコントローラでは、フルページ（8kB）がBBUへ書き込まれることを保証できなければ、部分的なページ書き出しを防止できません。
  </para>
  <para>
<!--
   <productname>PostgreSQL</productname> also protects against some kinds of data corruption
   on storage devices that may occur because of hardware errors or media failure over time,
   such as reading/writing garbage data.
-->
さらに<productname>PostgreSQL</productname>は、ハードウェアエラーや経時変化によるメディア障害により発生する、ごみデータを読み書きしてしまうようなストレージ装置内のある種のデータ破損を防ぎます。
   <itemizedlist>
    <listitem>
     <para>
<!--
      Each individual record in a WAL file is protected by a CRC-32 (32-bit) check
      that allows us to tell if record contents are correct. The CRC value
      is set when we write each WAL record and checked during crash recovery,
      archive recovery and replication.
-->
WALファイルのそれぞれのレコードは、レコードの内容が正確かどうかを伝えるためCRC-32 (32-bit)チェックにより保護されています。
CRCの値はそれぞれのWALレコードを書き込む時に設定され、クラッシュリカバリ、アーカイブリカバリとレプリケーション時に検証されます。
     </para>
    </listitem>
    <listitem>
     <para>
<!--
      Data pages are not currently checksummed by default, though full page images
      recorded in WAL records will be protected; see <link
      linkend="app-initdb-data-checksums"><application>initdb</application></link>
      for details about enabling data checksums.
-->
今のところ、デフォルトではデータページはチェックサム計算はされませんが、WALレコードに記録されているページ全体のイメージは保護されます。
データチェックサム有効化についての詳細は<link linkend="app-initdb-data-checksums"><application>initdb</application></link>を参照してください。
     </para>
    </listitem>
    <listitem>
     <para>
<!--
      Internal data structures such as <filename>pg_xact</filename>, <filename>pg_subtrans</filename>, <filename>pg_multixact</filename>,
      <filename>pg_serial</filename>, <filename>pg_notify</filename>, <filename>pg_stat</filename>, <filename>pg_snapshots</filename> are not directly
      checksummed, nor are pages protected by full page writes. However, where
      such data structures are persistent, WAL records are written that allow
      recent changes to be accurately rebuilt at crash recovery and those
      WAL records are protected as discussed above.
-->
<filename>pg_xact</filename>、<filename>pg_subtrans</filename>、<filename>pg_multixact</filename>、<filename>pg_serial</filename>、<filename>pg_notify</filename>、<filename>pg_stat</filename>、<filename>pg_snapshots</filename>のような内部データ構造は直接チェックサム計算もされず、全ページ書き込みによる保護もされていません。
しかし、そのようなデータ構造が永続する場所では、クラッシュリカバリ時に直近の更新が正確に再構築されるようにWALレコードが書き出され、それらのWALレコードは上記のように保護されます。
     </para>
    </listitem>
    <listitem>
     <para>
<!--
      Individual state files in <filename>pg_twophase</filename> are protected by CRC-32.
-->
<filename>pg_twophase</filename>にある個別の状態ファイルはCRC-32で保護されています。
     </para>
    </listitem>
    <listitem>
     <para>
<!--
      Temporary data files used in larger SQL queries for sorts,
      materializations and intermediate results are not currently checksummed,
      nor will WAL records be written for changes to those files.
-->
大きな問い合わせの中でソート、具現化、および中間結果用に使用される暫定的なデータファイルは現在チェックサム計算されず、それらのファイルに対する変更もWALレコードに書き込まれません。
     </para>
    </listitem>
   </itemizedlist>
  </para>
  <para>
<!--
   <productname>PostgreSQL</productname> does not protect against correctable memory errors
   and it is assumed you will operate using RAM that uses industry standard
   Error Correcting Codes (ECC) or better protection.
-->
<productname>PostgreSQL</productname>は修復可能なメモリエラーに対して保護を行いません。業界標準の誤り検出訂正（Error Correcting Codes -ECC-）またはそれ以上の保護付きのRAM使用が想定されています。
  </para>
 </sect1>

 <sect1 id="checksums">
<!--
  <title>Data Checksums</title>
-->
  <title>データチェックサム</title>
  <indexterm>
   <primary>checksums</primary>
  </indexterm>

  <para>
<!--
   By default, data pages are not protected by checksums, but this can
   optionally be enabled for a cluster. When enabled, each data page includes
   a checksum that is updated when the page is written and verified each time
   the page is read. Only data pages are protected by checksums; internal data
   structures and temporary files are not.
-->
デフォルトでは、データページはチェックサムで保護されていませんが、オプションでデータベースクラスタに対して有効にすることができます。
チェックサムを有効にすると、各データページにチェックサムが含まれます。
チェックサムは、ページが書き込まれるときに更新され、ページが読み取られるたびに検証されます。
チェックサムによってデータページのみ保護されます。
内部データ構造と一時ファイルは保護されません。
  </para>

  <para>
<!--
   Checksums are normally enabled when the cluster is initialized using <link
   linkend="app-initdb-data-checksums"><application>initdb</application></link>.
   They can also be enabled or disabled at a later time as an offline
   operation. Data checksums are enabled or disabled at the full cluster
   level, and cannot be specified individually for databases or tables.
-->
チェックサムは通常、<link linkend="app-initdb-data-checksums"><application>initdb</application></link>を使用してデータベースクラスタを初期化するときに有効にできます。
また、オフライン操作で後から有効化または無効化することもできます。
データチェックサムは、データベースクラスタ全体のレベルで有効または無効になり、データベースやテーブルに対して個別に指定することはできません。
  </para>

  <para>
<!--
   The current state of checksums in the cluster can be verified by viewing the
   value of the read-only configuration variable <xref
   linkend="guc-data-checksums" /> by issuing the command <command>SHOW
   data_checksums</command>.
-->
データベースクラスタのチェックサムの現在の状態は、<command>SHOW data_checksums</command>コマンドを実行して読み取り専用設定変数<xref linkend="guc-data-checksums" />の値を参照することで確認できます。
  </para>

  <para>
<!--
   When attempting to recover from page corruptions, it may be necessary to
   bypass the checksum protection. To do this, temporarily set the
   configuration parameter <xref linkend="guc-ignore-checksum-failure" />.
-->
ページ破損からの復旧を試みる場合、チェックサム保護のバイパスが必要な場合があります。
これを行うには、一時的に設定パラメータ<xref linkend="guc-ignore-checksum-failure" />を設定します。
  </para>

  <sect2 id="checksums-offline-enable-disable">
<!--
   <title>Off-line Enabling of Checksums</title>
-->
   <title>オフラインでのチェックサムの有効化</title>

   <para>
<!--
    The <link linkend="app-pgchecksums"><application>pg_checksums</application></link>
    application can be used to enable or disable data checksums, as well as
    verify checksums, on an offline cluster.
-->
<link linkend="app-pgchecksums"><application>pg_checksums</application></link>アプリケーションは、オフラインのデータベースクラスタ上でデータチェックサムを有効または無効にしたり、チェックサムを検証したりできます。
   </para>

  </sect2>
 </sect1>

  <sect1 id="wal-intro">
<!--
   <title>Write-Ahead Logging (<acronym>WAL</acronym>)</title>
-->
   <title>先行書き込みログ(<acronym>WAL</acronym>)</title>

   <indexterm zone="wal">
    <primary>WAL</primary>
   </indexterm>

   <indexterm>
    <primary>transaction log</primary>
    <see>WAL</see>
   </indexterm>
   <indexterm>
    <primary>トランザクションログ</primary>
    <see>WAL</see>
   </indexterm>

   <para>
<!--
    <firstterm>Write-Ahead Logging</firstterm> (<acronym>WAL</acronym>)
    is a standard method for ensuring data integrity.  A detailed
    description can be found in most (if not all) books about
    transaction processing. Briefly, <acronym>WAL</acronym>'s central
    concept is that changes to data files (where tables and indexes
    reside) must be written only after those changes have been logged,
    that is, after WAL records describing the changes have been flushed
    to permanent storage. If we follow this procedure, we do not need
    to flush data pages to disk on every transaction commit, because we
    know that in the event of a crash we will be able to recover the
    database using the log: any changes that have not been applied to
    the data pages can be redone from the WAL records.  (This is
    roll-forward recovery, also known as REDO.)
-->
<firstterm>先行書き込みログ</firstterm>（<acronym>WAL</acronym>）はデータの一貫性を確実にするための標準的な手法です。
詳細については、トランザクション処理について書かれた(すべてとは言いませんが)たいていの書籍に記載されています。
簡単に言うと、<acronym>WAL</acronym>の基本的な考え方は、(テーブルやインデックスがある)データファイルへの変更は、ログへの記録、つまり、変更内容を記述したWALレコードが永続格納領域にフラッシュされた後にのみ書き出されなければならないということです。
このような手順に従って処理を行えば、たとえクラッシュが起きてもログを使ってデータベースをリカバリすることができるため、トランザクションのコミットの度にデータページをディスクにフラッシュする必要がなくなります。
リカバリの時点でデータページに対してまだ行われていない変更分は、WALレコードを使って再実行されます（これがREDOとして知られているロールフォワードリカバリです）。
   </para>

   <tip>
    <para>
<!--
     Because <acronym>WAL</acronym> restores database file
     contents after a crash, journaled file systems are not necessary for
     reliable storage of the data files or WAL files.  In fact, journaling
     overhead can reduce performance, especially if journaling
     causes file system <emphasis>data</emphasis> to be flushed
     to disk.  Fortunately, data flushing during journaling can
     often be disabled with a file system mount option, e.g.,
     <literal>data=writeback</literal> on a Linux ext3 file system.
     Journaled file systems do improve boot speed after a crash.
-->
<acronym>WAL</acronym>によりデータベースファイルの中身を障害後にリストアするため、信頼性のある格納領域にあるデータファイルやWALファイルに対しては、ジャーナルファイルシステムは必要ありません。
実際、特に、もしファイルシステムの<emphasis>データ</emphasis>をディスクにフラッシュさせている場合には、ジャーナリングのオーバーヘッドは性能を劣化させることがあります。
幸運なことに、ジャーナリング中のデータのフラッシュをマウントオプションにより無効にできることが多いです。例えばLinuxのext3ファイルシステムでは、<literal>data=writeback</literal>と指定します。
ジャーナルファイルシステムは障害後の起動速度を改善します。
    </para>
   </tip>


   <para>
<!--
    Using <acronym>WAL</acronym> results in a
    significantly reduced number of disk writes, because only the WAL
    file needs to be flushed to disk to guarantee that a transaction is
    committed, rather than every data file changed by the transaction.
    The WAL file is written sequentially,
    and so the cost of syncing the WAL is much less than the cost of
    flushing the data pages.  This is especially true for servers
    handling many small transactions touching different parts of the data
    store.  Furthermore, when the server is processing many small concurrent
    transactions, one <function>fsync</function> of the WAL file may
    suffice to commit many transactions.
-->
<acronym>WAL</acronym>を使用することでディスクへの書き込み回数が大幅に減少します。
と言うのも、トランザクションがコミットされたことを保証するために、そのトランザクションで変更された全てのデータファイルではなく、WALファイルだけをディスクにフラッシュする必要があるからです。
WALファイルへの書き込みはシーケンシャルに行われるため、データページをフラッシュするコストに比べWALの同期はずっと低コストになります。
これは特に、データ格納領域の様々な部分を変更する小さなトランザクションを多く扱うサーバで顕著に現れます。
さらに、サーバが小規模なトランザクションを同時に多く処理する時、WALファイルを一度<function>fsync</function>することで、多くのトランザクションをコミットすることができる場合もあります。
   </para>

   <para>
<!--
    <acronym>WAL</acronym> also makes it possible to support on-line
    backup and point-in-time recovery, as described in <xref
    linkend="continuous-archiving"/>.  By archiving the WAL data we can support
    reverting to any time instant covered by the available WAL data:
    we simply install a prior physical backup of the database, and
    replay the WAL just as far as the desired time.  What's more,
    the physical backup doesn't have to be an instantaneous snapshot
    of the database state &mdash; if it is made over some period of time,
    then replaying the WAL for that period will fix any internal
    inconsistencies.
-->
また、<acronym>WAL</acronym>により、<xref linkend="continuous-archiving"/>で説明するオンラインバックアップとポイントインタイムリカバリをサポートできます。
WALのデータを保持することにより、そのWALデータが範囲内とする任意の時点に戻すことができます。
単純にデータベースの主となる物理バックアップをインストールし、WALを目的の時点まで単に再生することで実現できます。
さらに、物理バックアップはインスタンス化可能なデータベース状態のスナップショットである必要もありません。
ある程度の時間を経過して作成されたバックアップであっても、その期間用のWALを再生することにより、内部の不整合を修復します。
   </para>
  </sect1>

 <sect1 id="wal-async-commit">
<!--
  <title>Asynchronous Commit</title>
-->
  <title>非同期コミット</title>

   <indexterm>
    <primary>synchronous commit</primary>
   </indexterm>
   <indexterm>
    <primary>同期コミット</primary>
   </indexterm>

   <indexterm>
    <primary>asynchronous commit</primary>
   </indexterm>
   <indexterm>
    <primary>非同期コミット</primary>
   </indexterm>

  <para>
<!--
   <firstterm>Asynchronous commit</firstterm> is an option that allows transactions
   to complete more quickly, at the cost that the most recent transactions may
   be lost if the database should crash.  In many applications this is an
   acceptable trade-off.
-->
<firstterm>非同期コミット</firstterm>とは、トランザクションをより高速に完了することができるオプションです。
もっとも最近のトランザクションがデータベースがクラッシュしてしまった場合に失われるという危険があります。
これは、多くのアプリケーションで受け入れられるトレードオフです。
  </para>

  <para>
<!--
   As described in the previous section, transaction commit is normally
   <firstterm>synchronous</firstterm>: the server waits for the transaction's
   <acronym>WAL</acronym> records to be flushed to permanent storage
   before returning a success indication to the client.  The client is
   therefore guaranteed that a transaction reported to be committed will
   be preserved, even in the event of a server crash immediately after.
   However, for short transactions this delay is a major component of the
   total transaction time.  Selecting asynchronous commit mode means that
   the server returns success as soon as the transaction is logically
   completed, before the <acronym>WAL</acronym> records it generated have
   actually made their way to disk.  This can provide a significant boost
   in throughput for small transactions.
-->
前節で説明した通り、通常トランザクションのコミットは<firstterm>同期的</firstterm>です。
サーバはトランザクションの<acronym>WAL</acronym>レコードが永続的格納領域にフラッシュされるまで、クライアントに成功したことを通知することを待機します。
従って、直後にサーバクラッシュといった障害があったとしても、コミットされたと報告されたトランザクションは保持されることをクライアントは保証されます。
しかし、短期のトランザクションでは、この遅延はトランザクションの処理時間の大半を占める要素となります。
非同期コミットモードを選択することは、サーバが<acronym>WAL</acronym>レコードが実際に作成された通りにディスクに書き込まれるより前に、トランザクションの論理的な完了をもって成功したと通知することを意味します。
これにより、小規模なトランザクションでスループットがかなり向上します。
  </para>

  <para>
<!--
   Asynchronous commit introduces the risk of data loss. There is a short
   time window between the report of transaction completion to the client
   and the time that the transaction is truly committed (that is, it is
   guaranteed not to be lost if the server crashes).  Thus asynchronous
   commit should not be used if the client will take external actions
   relying on the assumption that the transaction will be remembered.
   As an example, a bank would certainly not use asynchronous commit for
   a transaction recording an ATM's dispensing of cash.  But in many
   scenarios, such as event logging, there is no need for a strong
   guarantee of this kind.
-->
非同期コミットにはデータ損失の危険があります。
トランザクションの完了をクライアントに通知してからトランザクションが本当に完了する（つまり、サーバクラッシュしても損失がないことが保証される）までの間にわずかな時間が存在します。
したがって、クライアントがトランザクションが記録されているという仮定を元に外部的な動作を行う場合は、非同期コミットを使用すべきではありません。
例えば、銀行では、ATMの現金支払を記録するトランザクションで非同期コミットを決して使用していないでしょう。
しかし、イベントロギングなど多くのシナリオでは、この種の強力な保証は必要ありません。
  </para>

  <para>
<!--
   The risk that is taken by using asynchronous commit is of data loss,
   not data corruption.  If the database should crash, it will recover
   by replaying <acronym>WAL</acronym> up to the last record that was
   flushed.  The database will therefore be restored to a self-consistent
   state, but any transactions that were not yet flushed to disk will
   not be reflected in that state.  The net effect is therefore loss of
   the last few transactions.  Because the transactions are replayed in
   commit order, no inconsistency can be introduced &mdash; for example,
   if transaction B made changes relying on the effects of a previous
   transaction A, it is not possible for A's effects to be lost while B's
   effects are preserved.
-->
非同期コミットによりもたらされる危険性は、データの破損ではなくデータの損失です。
データベースがクラッシュした場合、最後にフラッシュされた記録まで<acronym>WAL</acronym>を再生することで復旧が行われます。
このため、データベースは内部で一貫性を持った状態に復旧されますが、ディスクにフラッシュされていないトランザクションはすべてそこには反映されません。
したがって、影響を受けるのは、最後に行われたいくつかのトランザクションの損失です。
トランザクションはコミットされた順に再生されますので、一貫性が失われることはありません。
例えば、トランザクションBが以前に行われたトランザクションAの結果に依存した変更を行った場合、Bの影響が保存されている限り、Aの影響が失われることは起こり得ません。
  </para>

  <para>
<!--
   The user can select the commit mode of each transaction, so that
   it is possible to have both synchronous and asynchronous commit
   transactions running concurrently.  This allows flexible trade-offs
   between performance and certainty of transaction durability.
   The commit mode is controlled by the user-settable parameter
   <xref linkend="guc-synchronous-commit"/>, which can be changed in any of
   the ways that a configuration parameter can be set.  The mode used for
   any one transaction depends on the value of
   <varname>synchronous_commit</varname> when transaction commit begins.
-->
ユーザは各トランザクションでコミットモードを選択することができます。
このため、同時実行されるトランザクションを同期的、および非同期の両方でコミットさせることができます。
これにより、性能とトランザクションの信頼性の確実性との間で柔軟な選択を行うことができます。
コミットモードはユーザによる設定が可能なパラメータ<xref linkend="guc-synchronous-commit"/>で制御されます。
このパラメータは、設定パラメータを設定することができる全ての方法で変更することが可能です。
あるひとつのトランザクションで使用されるモードは、トランザクションのコミットが始まった時の<varname>synchronous_commit</varname>の値に依存します。
  </para>

  <para>
<!--
   Certain utility commands, for instance <command>DROP TABLE</command>, are
   forced to commit synchronously regardless of the setting of
   <varname>synchronous_commit</varname>.  This is to ensure consistency
   between the server's file system and the logical state of the database.
   The commands supporting two-phase commit, such as <command>PREPARE
   TRANSACTION</command>, are also always synchronous.
-->
例えば<command>DROP TABLE</command>などの特定のユーティリティコマンドでは、<varname>synchronous_commit</varname>の設定に関わらず、強制的に同期的コミットが行われます。
これにより、サーバのファイルシステムとデータベースの論理的な状態との間の一貫性が保証されます。
<command>PREPARE TRANSACTION</command>などの二相コミットをサポートするコマンドもまた、常に同期的です。
  </para>

  <para>
<!--
   If the database crashes during the risk window between an
   asynchronous commit and the writing of the transaction's
   <acronym>WAL</acronym> records,
   then changes made during that transaction <emphasis>will</emphasis> be lost.
   The duration of the
   risk window is limited because a background process (the <quote>WAL
   writer</quote>) flushes unwritten <acronym>WAL</acronym> records to disk
   every <xref linkend="guc-wal-writer-delay"/> milliseconds.
   The actual maximum duration of the risk window is three times
   <varname>wal_writer_delay</varname> because the WAL writer is
   designed to favor writing whole pages at a time during busy periods.
-->
もし非同期コミットとそのトランザクションの<acronym>WAL</acronym>レコードの書き込みの間の危険期間にデータベースがクラッシュしたとすると、そのトランザクションでなされた変更は失われる<emphasis>でしょう</emphasis>。
バックグラウンドプロセス（<quote>WALライタ</quote>）が未書き込みの<acronym>WAL</acronym>レコードを<xref linkend="guc-wal-writer-delay"/>ミリ秒毎にディスクにフラッシュしますので、この危険期間は制限されます。
WALライタは稼働中に一回ページ全体を書き込むように設計されているため、危険期間の実際の最大の長さは<varname>wal_writer_delay</varname>の３倍です。
  </para>

  <caution>
   <para>
<!--
    An immediate-mode shutdown is equivalent to a server crash, and will
    therefore cause loss of any unflushed asynchronous commits.
-->
即時モードのシャットダウンはサーバクラッシュと同じことですので、フラッシュされていない非同期コミットが失われることになります。
   </para>
  </caution>

  <para>
<!--
   Asynchronous commit provides behavior different from setting
   <xref linkend="guc-fsync"/> = off.
   <varname>fsync</varname> is a server-wide
   setting that will alter the behavior of all transactions.  It disables
   all logic within <productname>PostgreSQL</productname> that attempts to synchronize
   writes to different portions of the database, and therefore a system
   crash (that is, a hardware or operating system crash, not a failure of
   <productname>PostgreSQL</productname> itself) could result in arbitrarily bad
   corruption of the database state.  In many scenarios, asynchronous
   commit provides most of the performance improvement that could be
   obtained by turning off <varname>fsync</varname>, but without the risk
   of data corruption.
-->
非同期コミットでは<xref linkend="guc-fsync"/> = offという設定とは異なる動作になります。
<varname>fsync</varname>はサーバ全体に関する設定であり、すべてのトランザクションの動作を変更します。
これは、<productname>PostgreSQL</productname>における、データベースの様々な場所への書き込みを同期しようとするすべてのロジックを無効にします。
このため、システムクラッシュ（<productname>PostgreSQL</productname>自体の障害ではなくハードウェアやオペレーティングシステムのクラッシュ）の結果、予測できないデータベース状態の破損が起こります。
非同期コミットはデータ破損の危険性はなく、多くの状況では<varname>fsync</varname>を無効にした場合に得られる性能向上とほぼ同等の性能を提供します。
  </para>

  <para>
<!--
   <xref linkend="guc-commit-delay"/> also sounds very similar to
   asynchronous commit, but it is actually a synchronous commit method
   (in fact, <varname>commit_delay</varname> is ignored during an
   asynchronous commit).  <varname>commit_delay</varname> causes a delay
   just before a transaction flushes <acronym>WAL</acronym> to disk, in
   the hope that a single flush executed by one such transaction can also
   serve other transactions committing at about the same time.  The
   setting can be thought of as a way of increasing the time window in
   which transactions can join a group about to participate in a single
   flush, to amortize the cost of the flush among multiple transactions.
-->
また<xref linkend="guc-commit-delay"/>も非同期コミットと類似のように見えますが、これは実のところ同期コミットの一方法です。
（実際、非同期コミット時<varname>commit_delay</varname>は無視されます。）
トランザクションが<acronym>WAL</acronym>をディスクにフラッシュする直前に、こうしたトランザクションによって実行される一度のフラッシュにより、ほぼ同時期にコミットを行う他のトランザクションの分も処理できるようにすることを目的とした遅延が<varname>commit_delay</varname>により発生します。
この設定は、複数のトランザクションの中でフラッシュのコストを償却するために、トランザクションが一回のフラッシュに参加しようとするグループに参加できる時間的猶予を広げる方法として考えることができます。
  </para>

 </sect1>

 <sect1 id="wal-configuration">
<!--
  <title><acronym>WAL</acronym> Configuration</title>
-->
  <title><acronym>WAL</acronym>の設定</title>

  <para>
<!--
   There are several <acronym>WAL</acronym>-related configuration parameters that
   affect database performance. This section explains their use.
   Consult <xref linkend="runtime-config"/> for general information about
   setting server configuration parameters.
-->
データベースの性能に影響するような<acronym>WAL</acronym>に関連した設定パラメータが複数あります。
本節では、その使い方を説明します。
サーバ設定パラメータの設定方法についての詳細は<xref linkend="runtime-config"/>を参照してください。
  </para>

  <para>
<!--
   <firstterm>Checkpoints</firstterm><indexterm><primary>checkpoint</primary></indexterm>
   are points in the sequence of transactions at which it is guaranteed
   that the heap and index data files have been updated with all
   information written before that checkpoint.  At checkpoint time, all
   dirty data pages are flushed to disk and a special checkpoint record is
   written to the WAL file.  (The change records were previously flushed
   to the <acronym>WAL</acronym> files.)
   In the event of a crash, the crash recovery procedure looks at the latest
   checkpoint record to determine the point in the WAL (known as the redo
   record) from which it should start the REDO operation.  Any changes made to
   data files before that point are guaranteed to be already on disk.
   Hence, after a checkpoint, WAL segments preceding the one containing
   the redo record are no longer needed and can be recycled or removed. (When
   <acronym>WAL</acronym> archiving is being done, the WAL segments must be
   archived before being recycled or removed.)
-->
<firstterm>チェックポイント</firstterm><indexterm><primary>checkpoint</primary></indexterm>は、一連のトランザクションにおいて、そのチェックポイント以前に書かれた全ての情報によりヒープとインデックスファイルがすでに更新されていることを保証する時点です。
チェックポイント時に、全てのダーティページデータはディスクにフラッシュされ、特殊なチェックポイントレコードがWALファイルに書き込まれます。
(変更されたレコードは以前に<acronym>WAL</acronym>ファイルにフラッシュされています。)
クラッシュした時、クラッシュリカバリ処理は最新のチェックポイントレコードを見つけ、WALの中でどのレコード(これはredoレコードと呼ばれています)からREDOログ操作を開始すべきかを決定します。
このチェックポイント以前になされたデータファイルの変更は、すでにディスク上にあることが保証されています。
従って、チェックポイント後、redoレコード内のそのチェックポイント以前のWALセグメントは不要となり、再利用または削除することができます。
(<acronym>WAL</acronym>アーカイブが行われる場合、このWALセグメントは削除もしくは再利用される前に保存されなければなりません。)
  </para>

  <para>
<!--
   The checkpoint requirement of flushing all dirty data pages to disk
   can cause a significant I/O load.  For this reason, checkpoint
   activity is throttled so that I/O begins at checkpoint start and completes
   before the next checkpoint is due to start; this minimizes performance
   degradation during checkpoints.
-->
チェックポイント処理は、全てのダーティデータページをディスクへフラッシュするため、大きなI/O負荷を発生させます。
チェックポイント処理においては、I/Oはチェックポイント開始時に始まり、次のチェックポイントが開始する前に完了するように調節されます。
これは、チェックポイント処理中の性能劣化を極力抑える効果があります。
  </para>

  <para>
<!--
   The server's checkpointer process automatically performs
   a checkpoint every so often.  A checkpoint is begun every <xref
   linkend="guc-checkpoint-timeout"/> seconds, or if
   <xref linkend="guc-max-wal-size"/> is about to be exceeded,
   whichever comes first.
   The default settings are 5 minutes and 1 GB, respectively.
   If no WAL has been written since the previous checkpoint, new checkpoints
   will be skipped even if <varname>checkpoint_timeout</varname> has passed.
   (If WAL archiving is being used and you want to put a lower limit on how
   often files are archived in order to bound potential data loss, you should
   adjust the <xref linkend="guc-archive-timeout"/> parameter rather than the
   checkpoint parameters.)
   It is also possible to force a checkpoint by using the SQL
   command <command>CHECKPOINT</command>.
-->
サーバのチェックポインタプロセスは、自動的にチェックポイントを時々実行します。
<xref linkend="guc-checkpoint-timeout"/>秒が経過するか、または<xref linkend="guc-max-wal-size"/>に達するか、どちらかの条件が最初に満たされるとチェックポイントが開始されます。
デフォルトの設定では、それぞれ5分と1GBとなっています。
前回のチェックポイント以降書き出すWALがない場合、<varname>checkpoint_timeout</varname>が経過したとしても新しいチェックポイントが飛ばされます。
(WALアーカイブ処理を使用しており、かつ、データ損失の可能性を限定するためにファイルのアーカイブ頻度の下限を設定したい場合、チェックポイント関連のパラメータよりも、<xref linkend="guc-archive-timeout"/>パラメータを調節するべきです。)
また、<command>CHECKPOINT</command> SQLコマンドで強制的にチェックポイントを作成することもできます。
  </para>

  <para>
<!--
   Reducing <varname>checkpoint_timeout</varname> and/or
   <varname>max_wal_size</varname> causes checkpoints to occur
   more often. This allows faster after-crash recovery, since less work
   will need to be redone. However, one must balance this against the
   increased cost of flushing dirty data pages more often. If
   <xref linkend="guc-full-page-writes"/> is set (as is the default), there is
   another factor to consider. To ensure data page consistency,
   the first modification of a data page after each checkpoint results in
   logging the entire page content. In that case,
   a smaller checkpoint interval increases the volume of output to the WAL,
   partially negating the goal of using a smaller interval,
   and in any case causing more disk I/O.
-->
<varname>checkpoint_timeout</varname>または<varname>max_wal_size</varname>、あるいはその両者を減少させると、チェックポイントはより頻繁に行われます。
これにより、やり直しに要する処理量が少なくなるので、クラッシュ後の修復は高速になります。
しかし、変更されたデータページのフラッシュがより頻繁に行われることにより増大するコストとバランスを考えなければなりません。
<xref linkend="guc-full-page-writes"/>が設定されている（デフォルトです）場合、他に考慮しなければならない点があります。
データページの一貫性を保証するために、各チェックポイント後の最初に変更されるデータページは、そのページ全体の内容がログに保存されることになります。
このような場合、チェックポイントの間隔を少なくすることは、WALへの出力を増加させ、間隔を短くする目的の一部を無意味にします。
また、確実により多くのディスクI/Oが発生します。
  </para>

  <para>
<!--
   Checkpoints are fairly expensive, first because they require writing
   out all currently dirty buffers, and second because they result in
   extra subsequent WAL traffic as discussed above.  It is therefore
   wise to set the checkpointing parameters high enough so that checkpoints
   don't happen too often.  As a simple sanity check on your checkpointing
   parameters, you can set the <xref linkend="guc-checkpoint-warning"/>
   parameter.  If checkpoints happen closer together than
   <varname>checkpoint_warning</varname> seconds,
   a message will be output to the server log recommending increasing
   <varname>max_wal_size</varname>.  Occasional appearance of such
   a message is not cause for alarm, but if it appears often then the
   checkpoint control parameters should be increased. Bulk operations such
   as large <command>COPY</command> transfers might cause a number of such warnings
   to appear if you have not set <varname>max_wal_size</varname> high
   enough.
-->
チェックポイントはかなり高価なものです。
1番の理由は、この処理は現時点の全てのダーティバッファを書き出す必要があること、2番目の理由は、上記のようにその後に余計なWALの書き込みが発生することです。
そのため、チェックポイント用のパラメータを高くし、チェックポイントがあまりにも頻発することがないようにすることを勧めます。
簡単なチェックポイント用のパラメータの健全性検査として、<xref linkend="guc-checkpoint-warning"/>パラメータを設定することができます。
チェックポイントの発生間隔が<varname>checkpoint_warning</varname>秒未満の場合、<varname>max_wal_size</varname>の増加を勧めるメッセージがサーバのログに出力されます。
このメッセージが稀に現れたとしても問題にはなりませんが、頻出するようであれば、チェックポイントの制御パラメータを増加させるべきです。
<varname>max_wal_size</varname>を十分高く設定していないと、大規模な<command>COPY</command>転送などのまとまった操作でこうした警告が多く発生するかもしれません。
  </para>

  <para>
<!--
   To avoid flooding the I/O system with a burst of page writes,
   writing dirty buffers during a checkpoint is spread over a period of time.
   That period is controlled by
   <xref linkend="guc-checkpoint-completion-target"/>, which is
   given as a fraction of the checkpoint interval (configured by using
   <varname>checkpoint_timeout</varname>).
   The I/O rate is adjusted so that the checkpoint finishes when the
   given fraction of
   <varname>checkpoint_timeout</varname> seconds have elapsed, or before
   <varname>max_wal_size</varname> is exceeded, whichever is sooner.
   With the default value of 0.9,
   <productname>PostgreSQL</productname> can be expected to complete each checkpoint
   a bit before the next scheduled checkpoint (at around 90% of the last checkpoint's
   duration).  This spreads out the I/O as much as possible so that the checkpoint
   I/O load is consistent throughout the checkpoint interval.  The disadvantage of
   this is that prolonging checkpoints affects recovery time, because more WAL
   segments will need to be kept around for possible use in recovery.  A user
   concerned about the amount of time required to recover might wish to reduce
   <varname>checkpoint_timeout</varname> so that checkpoints occur more frequently
   but still spread the I/O across the checkpoint interval.  Alternatively,
   <varname>checkpoint_completion_target</varname> could be reduced, but this would
   result in times of more intense I/O (during the checkpoint) and times of less I/O
   (after the checkpoint completed but before the next scheduled checkpoint) and
   therefore is not recommended.
   Although <varname>checkpoint_completion_target</varname> could be set as high as
   1.0, it is typically recommended to set it to no higher than 0.9 (the default)
   since checkpoints include some other activities besides writing dirty buffers.
   A setting of 1.0 is quite likely to result in checkpoints not being
   completed on time, which would result in performance loss due to
   unexpected variation in the number of WAL segments needed.
-->
ページ書き出しの集中によるI/Oシステムの溢れを防ぐために、チェックポイント期間のダーティバッファの書き出しは一定の期間に分散されます。
この期間は<xref linkend="guc-checkpoint-completion-target"/>により制御され、<varname>checkpoint_timeout</varname>によって設定されるチェックポイント間隔の割合として指定されます。
I/Oの割合は、チェックポイントの起動時から<varname>checkpoint_timeout</varname>秒が経過した時、あるいは<varname>max_wal_size</varname>を超えた時、このどちらかが発生するとすぐに、チェックポイントが完了するように調整されます。
デフォルトの0.9という値では、<productname>PostgreSQL</productname>は次のチェックポイントが始まる少し前に、前回のチェックポイント期間の約90%程度の時間で各チェックポイントが完了するものと想定できることになります。
これにより、チェックポイントのI/O負荷がチェックポイント期間を通して一定になるように、I/Oが可能な限り分散されます。
この欠点は、延長されたチェックポイントがリカバリ時間に影響をあたえることです。
リカバリ時に使用できるように、より多くのWALセグメントを保持する必要があるためです。
リカバリに必要な時間を気にするユーザは、<varname>checkpoint_timeout</varname>を減らして、チェックポイントをより頻繁に発生しながらも、チェックポイント間隔全体にI/Oを分散させることを望むかもしれません。
または、<varname>checkpoint_completion_target</varname>を減らすこともできますが、この場合、チェックポイント中のI/Oが多い時間帯と、チェックポイント完了後から次に予定されているチェックポイントの前までのI/Oの少ない時間帯が発生しますので、推奨されません。
<varname>checkpoint_completion_target</varname>を最大の1.0に設定することもできますが、チェックポイントにはダーティバッファを書き出す以外の活動も含まれているため、通常はデフォルトの0.9以下に設定することをお勧めします。
1.0という設定は、ある時点でチェックポイントが完了しなくなるという結果に陥ります。
これは必要なWALセグメント数が想定以上に変動することになり、性能の劣化が発生することになります。
  </para>

  <para>
<!--
   On Linux and POSIX platforms <xref linkend="guc-checkpoint-flush-after"/>
   allows to force the OS that pages written by the checkpoint should be
   flushed to disk after a configurable number of bytes.  Otherwise, these
   pages may be kept in the OS's page cache, inducing a stall when
   <literal>fsync</literal> is issued at the end of a checkpoint.  This setting will
   often help to reduce transaction latency, but it also can have an adverse
   effect on performance; particularly for workloads that are bigger than
   <xref linkend="guc-shared-buffers"/>, but smaller than the OS's page cache.
-->
LinuxおよびPOSIXプラットフォームでは、チェックポイントによって書かれたページを、設定したバイト数の後にディスクにフラッシュさせるように<xref linkend="guc-checkpoint-flush-after"/>を使ってOSに強制させることができます。
この設定がない場合はこのページはOSのページキャッシュに保持されるかもしれず、チェックポイントの最後に<literal>fsync</literal>が発行された際の速度低下を招きます。
この設定は、しばしばトランザクションの遅延を減少させるのに役立ちます。
しかし、とりわけワークロードが<xref linkend="guc-shared-buffers"/>よりも大きく、かつOSのページキャッシュよりも小さい場合には性能上不利になることもあります。
  </para>

  <para>
<!--
   The number of WAL segment files in <filename>pg_wal</filename> directory depends on
   <varname>min_wal_size</varname>, <varname>max_wal_size</varname> and
   the amount of WAL generated in previous checkpoint cycles. When old WAL
   segment files are no longer needed, they are removed or recycled (that is,
   renamed to become future segments in the numbered sequence). If, due to a
   short-term peak of WAL output rate, <varname>max_wal_size</varname> is
   exceeded, the unneeded segment files will be removed until the system
   gets back under this limit. Below that limit, the system recycles enough
   WAL files to cover the estimated need until the next checkpoint, and
   removes the rest. The estimate is based on a moving average of the number
   of WAL files used in previous checkpoint cycles. The moving average
   is increased immediately if the actual usage exceeds the estimate, so it
   accommodates peak usage rather than average usage to some extent.
   <varname>min_wal_size</varname> puts a minimum on the amount of WAL files
   recycled for future usage; that much WAL is always recycled for future use,
   even if the system is idle and the WAL usage estimate suggests that little
   WAL is needed.
-->
<filename>pg_wal</filename>ディレクトリ内のWALセグメントファイルの数は、<varname>min_wal_size</varname>、<varname>max_wal_size</varname>、それに前回のチェックポイントで生成されたWALの量に依存します。
古いWALセグメントファイルが不要になると、削除または再利用(連番のうち、今後利用される予定の番号に名前が変更されます)されます。
WALの出力レートが短期間にピークを迎えたために<varname>max_wal_size</varname>を超えた場合、この制限以下になるまで不要なセグメントファイルが削除されます。
この制限以下になると、次のチェックポイントまでは、システムは見積もりを満たすだけのWALファイルを再利用します。
この見積は、前回のチェックポイントの際に使用されたWALファイルの移動平均に基づいています。
もし実際の使用量が見積もりを上回ると、移動平均は直ちに増加します。
これにより、平均需要というよりは、ピーク時の需要をある程度満たすことができるわけです。
<varname>min_wal_size</varname>は、今後のために再利用されるWALファイル数の最小値を設定します。
システムがアイドル状態にあり、WALの使用量を見積った結果、少ないWALしか必要ないとなったとしても、こうした量のWALファイルは必ず再利用されます。
  </para>

  <para>
<!--
   Independently of <varname>max_wal_size</varname>,
   the most recent <xref linkend="guc-wal-keep-size"/> megabytes of
   WAL files plus one additional WAL file are
   kept at all times. Also, if WAL archiving is used, old segments cannot be
   removed or recycled until they are archived. If WAL archiving cannot keep up
   with the pace that WAL is generated, or if <varname>archive_command</varname>
   or <varname>archive_library</varname>
   fails repeatedly, old WAL files will accumulate in <filename>pg_wal</filename>
   until the situation is resolved. A slow or failed standby server that
   uses a replication slot will have the same effect (see
   <xref linkend="streaming-replication-slots"/>).
-->
<varname>max_wal_size</varname>に関わらず、最新の<xref linkend="guc-wal-keep-size"/>メガバイトのWALファイルに加えて、もう一つのWALファイルが常に保持されます。
また、WALアーカイブを利用している場合は、古いセグメントは、アーカイブされるまでは削除も再利用もされません。
WALが生成されるペースにWALのアーカイブ処理が追いつかなかったり、<varname>archive_command</varname>や<varname>archive_library</varname>が連続して失敗すると、事態が解決するまでWALファイルは<filename>pg_wal</filename>の下に蓄積されていきます。
レプリケーションスロットを使用しているスタンバイサーバが低速だったり、失敗すると、同じ現象が起きます(<xref linkend="streaming-replication-slots"/>を参照のこと)
  </para>

  <para>
<!--
   In archive recovery or standby mode, the server periodically performs
   <firstterm>restartpoints</firstterm>,<indexterm><primary>restartpoint</primary></indexterm>
   which are similar to checkpoints in normal operation: the server forces
   all its state to disk, updates the <filename>pg_control</filename> file to
   indicate that the already-processed WAL data need not be scanned again,
   and then recycles any old WAL segment files in the <filename>pg_wal</filename>
   directory.
   Restartpoints can't be performed more frequently than checkpoints on the
   primary because restartpoints can only be performed at checkpoint records.
   A restartpoint is triggered when a checkpoint record is reached if at
   least <varname>checkpoint_timeout</varname> seconds have passed since the last
   restartpoint, or if WAL size is about to exceed
   <varname>max_wal_size</varname>. However, because of limitations on when a
   restartpoint can be performed, <varname>max_wal_size</varname> is often exceeded
   during recovery, by up to one checkpoint cycle's worth of WAL.
   (<varname>max_wal_size</varname> is never a hard limit anyway, so you should
   always leave plenty of headroom to avoid running out of disk space.)
-->
アーカイブリカバリもしくはスタンバイモードにおいて、サーバでは定期的に通常運用でのチェックポイント処理と似た<firstterm>リスタートポイント</firstterm><indexterm><primary>restartpoint</primary></indexterm>処理を行います。これは、すでに再生されたWALを再度読み込む必要がないよう、ディスクに現在の状態を強制的に書き込み、<filename>pg_control</filename>ファイルを更新します。また<filename>pg_wal</filename>ディレクトリの中の古いWALセグメントを再利用できるようにします。
リスタートポイント処理はチェックポイントレコードに対してしか実施されないので、プライマリ側のチェックポイント処理よりも発生頻度が多いということはありません。
リスタートポイントは、最後のリスタートポイントより少なくとも<varname>checkpoint_timeout</varname>秒が経過しているか、あるいは<varname>max_wal_size</varname>を超えそうな場合に起動されます。
しかし、リスタートポイントが実施できるための制約事項により、リカバリの際には1回のチェックポイント分のWALを上限に、<varname>max_wal_size</varname>を超えてしまいがちです。
(どのみち<varname>max_wal_size</varname>はハードリミットではないので、ディスクスペースを使い尽くしてしまわないように、常に十分な余裕を持っておくべきです)
  </para>

  <para>
<!--
   There are two commonly used internal <acronym>WAL</acronym> functions:
   <function>XLogInsertRecord</function> and <function>XLogFlush</function>.
   <function>XLogInsertRecord</function> is used to place a new record into
   the <acronym>WAL</acronym> buffers in shared memory. If there is no
   space for the new record, <function>XLogInsertRecord</function> will have
   to write (move to kernel cache) a few filled <acronym>WAL</acronym>
   buffers. This is undesirable because <function>XLogInsertRecord</function>
   is used on every database low level modification (for example, row
   insertion) at a time when an exclusive lock is held on affected
   data pages, so the operation needs to be as fast as possible.  What
   is worse, writing <acronym>WAL</acronym> buffers might also force the
   creation of a new WAL segment, which takes even more
   time. Normally, <acronym>WAL</acronym> buffers should be written
   and flushed by an <function>XLogFlush</function> request, which is
   made, for the most part, at transaction commit time to ensure that
   transaction records are flushed to permanent storage. On systems
   with high WAL output, <function>XLogFlush</function> requests might
   not occur often enough to prevent <function>XLogInsertRecord</function>
   from having to do writes.  On such systems
   one should increase the number of <acronym>WAL</acronym> buffers by
   modifying the <xref linkend="guc-wal-buffers"/> parameter.  When
   <xref linkend="guc-full-page-writes"/> is set and the system is very busy,
   setting <varname>wal_buffers</varname> higher will help smooth response times
   during the period immediately following each checkpoint.
-->
よく使われる2つの内部用<acronym>WAL</acronym>関数があります。
<function>XLogInsertRecord</function>と<function>XLogFlush</function>です。
<function>XLogInsertRecord</function>は共有メモリ上の<acronym>WAL</acronym>バッファに新しいレコードを挿入します。
新しいレコードを挿入する余地がない時は、<function>XLogInsertRecord</function>は、満杯になった<acronym>WAL</acronym>バッファを書き込み（カーネルキャッシュに移動）しなければいけません。
これは望ましいことではありません。
なぜなら、データベースへの低レベルの変更（例えば行の挿入）の度に<function>XLogInsertRecord</function>が呼ばれますが、そのような場合には変更を受けたページに対して排他ロックがかかっており、それゆえこの操作は可能な限り高速に実行されなければなりません。
さらに悪いことには、<acronym>WAL</acronym>バッファへの書き込みの際に、さらに時間がかかる、強制的な新しいWALセグメントの生成が必要となるかもしれません。
通常、<acronym>WAL</acronym>の書き込み、フラッシュは<function>XLogFlush</function>要求で実施されます。
これはたいていの場合、トランザクションコミットの際に永続的な記憶領域にトランザクションレコードがフラッシュされることを保証するために行われます。
WAL出力が大量に行われるシステムでは、<function>XLogInsertRecord</function>によって必要となる書き込みを防ぐほどには<function>XLogFlush</function>要求が頻繁に起こらないかもしれません。
そういうシステムでは、<xref linkend="guc-wal-buffers"/>パラメータを変更して<acronym>WAL</acronym>バッファの数を増やしてください。
<xref linkend="guc-full-page-writes"/>が設定され、かつ、システムが高負荷状態である場合、<varname>wal_buffers</varname>を高くすることで、各チェックポイントの直後の応答時間を滑らかにすることができます。
  </para>

  <para>
<!--
   The <xref linkend="guc-commit-delay"/> parameter defines for how many
   microseconds a group commit leader process will sleep after acquiring a
   lock within <function>XLogFlush</function>, while group commit
   followers queue up behind the leader.  This delay allows other server
   processes to add their commit records to the WAL buffers so that all of
   them will be flushed by the leader's eventual sync operation.  No sleep
   will occur if <xref linkend="guc-fsync"/> is not enabled, or if fewer
   than <xref linkend="guc-commit-siblings"/> other sessions are currently
   in active transactions; this avoids sleeping when it's unlikely that
   any other session will commit soon.  Note that on some platforms, the
   resolution of a sleep request is ten milliseconds, so that any nonzero
   <varname>commit_delay</varname> setting between 1 and 10000
   microseconds would have the same effect.  Note also that on some
   platforms, sleep operations may take slightly longer than requested by
   the parameter.
-->
<xref linkend="guc-commit-delay"/>パラメータは、<function>XLogFlush</function>内でロックを取得してからグループコミット上位者が何マイクロ秒休止するかを定義します。一方、グループコミット追従者は上位者の後に並びます。
すべてが上位者の結果として生ずる同期操作によりフラッシュされるように、この遅延は他のサーバプロセスがそれらのコミットレコードをWALバッファに追加することを許容します。
<xref linkend="guc-fsync"/>が有効でないか、または<xref linkend="guc-commit-siblings"/>より少ない他のセッションがその時点で活動しているトランザクションであれば休止は行われません。
他の何らかのセッションが直ぐにでもコミットするという起こりそうにない時の休止を避けるものです。
いくつかのプラットフォームにおいて、休止要求の分解能は10ミリ秒で、１から10000マイクロ秒の間の<varname>commit_delay</varname>の設定は、どの値でも同じ効果となることを覚えておいてください。
いくつかのプラットフォームで、休止操作はパラメータによって要求された時間よりわずかに長くなることも覚えておいてください。
  </para>

  <para>
<!--
   Since the purpose of <varname>commit_delay</varname> is to allow the
   cost of each flush operation to be amortized across concurrently
   committing transactions (potentially at the expense of transaction
   latency), it is necessary to quantify that cost before the setting can
   be chosen intelligently.  The higher that cost is, the more effective
   <varname>commit_delay</varname> is expected to be in increasing
   transaction throughput, up to a point.  The <xref
   linkend="pgtestfsync"/> program can be used to measure the average time
   in microseconds that a single WAL flush operation takes.  A value of
   half of the average time the program reports it takes to flush after a
   single 8kB write operation is often the most effective setting for
   <varname>commit_delay</varname>, so this value is recommended as the
   starting point to use when optimizing for a particular workload.  While
   tuning <varname>commit_delay</varname> is particularly useful when the
   WAL is stored on high-latency rotating disks, benefits can be
   significant even on storage media with very fast sync times, such as
   solid-state drives or RAID arrays with a battery-backed write cache;
   but this should definitely be tested against a representative workload.
   Higher values of <varname>commit_siblings</varname> should be used in
   such cases, whereas smaller <varname>commit_siblings</varname> values
   are often helpful on higher latency media.  Note that it is quite
   possible that a setting of <varname>commit_delay</varname> that is too
   high can increase transaction latency by so much that total transaction
   throughput suffers.
-->
<varname>commit_delay</varname>の目的は、それぞれのフラッシュ操作のコストを並列にコミット中のトランザクションに（潜在的にはトランザクションの待ち時間と引き換えに）分散させることにあり、うまく設定を行うためには、まずそのコストを測る必要があります。
そのコストが高ければ高いほど、トランザクションのスループットがある程度向上するという意味において、<varname>commit_delay</varname>の効果がより増すことが期待できます。
<xref linkend="pgtestfsync"/>プログラムは、一つのWALフラッシュが必要とするマイクロ秒単位の平均時間を計測するために使用可能です。
プログラムが報告する単一の8kB書き込み操作のあとのフラッシュ平均時間の２分の１の値は、しばしば<varname>commit_delay</varname>の最も効果的な設定です。
従って、この値は特定の作業負荷のための最適化を行うときに使用するための手始めとして推奨されます。
WALが高遅延の回転ディスクに格納されているときは、<varname>commit_delay</varname>のチューニングは特に有効ですが、半導体ドライブまたはバッテリバックアップされている書き込みキャッシュ付きのRAIDアレイのような、特に同期時間が高速な格納メディア上であっても大きなメリットがある場合があります。
しかし、このことは、代表的作業負荷に対してきちんと検証しておくべきです。
<varname>commit_siblings</varname>の高い値は、これらの状況で使用すべきで、一方より小さな<varname>commit_siblings</varname>の値は高遅延メディア上でしばしば有用です。
余りにも高い値の<varname>commit_delay</varname>を設定すると、トランザクション遅延を増加させかねないことになり、トランザクションの総スループットが低下します。
  </para>

  <para>
<!--
   When <varname>commit_delay</varname> is set to zero (the default), it
   is still possible for a form of group commit to occur, but each group
   will consist only of sessions that reach the point where they need to
   flush their commit records during the window in which the previous
   flush operation (if any) is occurring.  At higher client counts a
   <quote>gangway effect</quote> tends to occur, so that the effects of group
   commit become significant even when <varname>commit_delay</varname> is
   zero, and thus explicitly setting <varname>commit_delay</varname> tends
   to help less.  Setting <varname>commit_delay</varname> can only help
   when (1) there are some concurrently committing transactions, and (2)
   throughput is limited to some degree by commit rate; but with high
   rotational latency this setting can be effective in increasing
   transaction throughput with as few as two clients (that is, a single
   committing client with one sibling transaction).
-->
<varname>commit_delay</varname>が(デフォルトの)ゼロに設定されても、グループコミットが起こることがあります。
しかし、それぞれのグループは前回のフラッシュ操作（あった場合）が発生していた期間中に、それぞれのコミットレコードをフラッシュする必要に至ったセッションのみから成ります。
クライアントが多い状況では、<quote>gangway effect</quote>が起こる傾向があり、そのため<varname>commit_delay</varname>がゼロであってもグループコミットの効果が著しく、従って、<varname>commit_delay</varname>を明示的に設定しても役立ちません。
<varname>commit_delay</varname>の設定は（１）複数の同時にコミット中のトランザクションが存在すること、そして（２）コミット頻度によりある程度までスループットが制限されている場合に役立ちます。
しかし、回転待ち時間が長い場合、この設定はわずか二つのクライアントにおいてさえトランザクションスループットを向上させる効果があるかもしれません（言いかえれば、一つの兄弟（sibling）トランザクションを所有する単一のコミット中のクライアントです）。
  </para>

  <para>
<!--
   The <xref linkend="guc-wal-sync-method"/> parameter determines how
   <productname>PostgreSQL</productname> will ask the kernel to force
   <acronym>WAL</acronym> updates out to disk.
   All the options should be the same in terms of reliability, with
   the exception of <literal>fsync_writethrough</literal>, which can sometimes
   force a flush of the disk cache even when other options do not do so.
   However, it's quite platform-specific which one will be the fastest.
   You can test the speeds of different options using the <xref
   linkend="pgtestfsync"/> program.
   Note that this parameter is irrelevant if <varname>fsync</varname>
   has been turned off.
-->
<xref linkend="guc-wal-sync-method"/>パラメータは<productname>PostgreSQL</productname>がカーネルに対して<acronym>WAL</acronym>更新のディスクへの書き込みを要求する方法を決定します。
<literal>fsync_writethrough</literal>を除き、どういう設定でも信頼性は同じはずです。<literal>fsync_writethrough</literal>は他のオプションがそうしないときでも、時々ディスクキャッシュの書き出しを強制することができます。
しかしながら、プラットフォームによってどれが一番速いのかがまったく違います。
<xref linkend="pgtestfsync"/>プログラムを使って異なるオプションの速度テストを行うことができます。
ちなみに、このパラメータは<varname>fsync</varname>が無効になっている場合は役に立ちません。
  </para>

  <para>
<!--
   Enabling the <xref linkend="guc-wal-debug"/> configuration parameter
   (provided that <productname>PostgreSQL</productname> has been
   compiled with support for it) will result in each
   <function>XLogInsertRecord</function> and <function>XLogFlush</function>
   <acronym>WAL</acronym> call being logged to the server log. This
   option might be replaced by a more general mechanism in the future.
-->
<xref linkend="guc-wal-debug"/>設定パラメータを有効にすることで、<function>XLogInsertRecord</function>と<function>XLogFlush</function>という<acronym>WAL</acronym>呼び出しは毎回サーバログにログが残ります
（このパラメータをサポートするように<productname>PostgreSQL</productname>をコンパイルする必要があります）。
将来このオプションはより一般的な機構に置き換わる可能性があります。
  </para>

  <para>
<!--
   There are two internal functions to write WAL data to disk:
   <function>XLogWrite</function> and <function>issue_xlog_fsync</function>.
   When <xref linkend="guc-track-wal-io-timing"/> is enabled, the total
   amounts of time <function>XLogWrite</function> writes and
   <function>issue_xlog_fsync</function> syncs WAL data to disk are counted as
   <literal>wal_write_time</literal> and <literal>wal_sync_time</literal> in
   <xref linkend="pg-stat-wal-view"/>, respectively.
   <function>XLogWrite</function> is normally called by
   <function>XLogInsertRecord</function> (when there is no space for the new
   record in WAL buffers), <function>XLogFlush</function> and the WAL writer,
   to write WAL buffers to disk and call <function>issue_xlog_fsync</function>.
   <function>issue_xlog_fsync</function> is normally called by
   <function>XLogWrite</function> to sync WAL files to disk.
   If <varname>wal_sync_method</varname> is either
   <literal>open_datasync</literal> or <literal>open_sync</literal>,
   a write operation in <function>XLogWrite</function> guarantees to sync written
   WAL data to disk and <function>issue_xlog_fsync</function> does nothing.
   If <varname>wal_sync_method</varname> is either <literal>fdatasync</literal>,
   <literal>fsync</literal>, or <literal>fsync_writethrough</literal>,
   the write operation moves WAL buffers to kernel cache and
   <function>issue_xlog_fsync</function> syncs them to disk. Regardless
   of the setting of <varname>track_wal_io_timing</varname>, the number
   of times <function>XLogWrite</function> writes and
   <function>issue_xlog_fsync</function> syncs WAL data to disk are also
   counted as <literal>wal_write</literal> and <literal>wal_sync</literal>
   in <structname>pg_stat_wal</structname>, respectively.
-->
WALデータをディスクに書き込むための2つの内部関数があります。
<function>XLogWrite</function>と<function>issue_xlog_fsync</function>です。
<xref linkend="guc-track-wal-io-timing"/>が有効な場合、<function>XLogWrite</function>がWALデータをディスクに書き込み、<function>issue_xlog_fsync</function>がWALデータをディスクに同期する合計時間は、それぞれ<xref linkend="pg-stat-wal-view"/>の<literal>wal_write_time</literal>および<literal>wal_sync_time</literal>として数えられます。
<function>XLogWrite</function>は、WALバッファをディスクに書き込んで<function>issue_xlog_fsync</function>を呼び出すために、通常は<function>XLogInsertRecord</function>（WALバッファに新しいレコード用の領域がない場合）、<function>XLogFlush</function>、WALライタによって呼び出されます。
<function>issue_xlog_fsync</function>は通常、WALファイルをディスクに同期するために<function>XLogWrite</function>によって呼び出されます。
<varname>wal_sync_method</varname>が<literal>open_datasync</literal>または<literal>open_sync</literal>の場合、<function>XLogWrite</function>での書き込み操作はディスクに書き込まれたWALデータの同期を保証し、<function>issue_xlog_fsync</function>は何も行いません。
<varname>wal_sync_method</varname>が<literal>fdatasync</literal>、<literal>fsync</literal>、または<literal>fsync_writethrough</literal>のいずれかの場合、書き込み操作はWALバッファをカーネルキャッシュに移動し、<function>issue_xlog_fsync</function>はそれらをディスクに同期します。
<varname>track_wal_io_timing</varname>の設定に関係なく、<function>XLogWrite</function>の書き込み回数と<function>issue_xlog_fsync</function>のディスクへのWALデータの同期回数もそれぞれ<structname>pg_stat_wal</structname>の<literal>wal_write</literal>と<literal>wal_sync</literal>としてカウントされます。
  </para>

  <para>
<!--
   The <xref linkend="guc-recovery-prefetch"/> parameter can be used to reduce
   I/O wait times during recovery by instructing the kernel to initiate reads
   of disk blocks that will soon be needed but are not currently in
   <productname>PostgreSQL</productname>'s buffer pool.
   The <xref linkend="guc-maintenance-io-concurrency"/> and
   <xref linkend="guc-wal-decode-buffer-size"/> settings limit prefetching
   concurrency and distance, respectively.  By default, it is set to
   <literal>try</literal>, which enables the feature on systems where
   <function>posix_fadvise</function> is available.
-->
<xref linkend="guc-recovery-prefetch"/>パラメータは、すぐに必要になるが現在<productname>PostgreSQL</productname>のバッファプールにないディスクブロックの読み取りを開始するようカーネルに指示することにより、リカバリ中の入出力待ち時間を減らすために使用できます。
<xref linkend="guc-maintenance-io-concurrency"/>と<xref linkend="guc-wal-decode-buffer-size"/>の設定は、プリフェッチの並列度と先読み量をそれぞれ制限します。
デフォルトでは<literal>try</literal>に設定されており、<function>posix_fadvise</function>が利用可能なシステムでこの機能が有効になります。
  </para>
 </sect1>

 <sect1 id="wal-internals">
<!--
  <title>WAL Internals</title>
-->
  <title>WALの内部</title>

  <indexterm zone="wal-internals">
   <primary>LSN</primary>
  </indexterm>

  <para>
<!--
   <acronym>WAL</acronym> is automatically enabled; no action is
   required from the administrator except ensuring that the
   disk-space requirements for the <acronym>WAL</acronym> files are met,
   and that any necessary tuning is done (see <xref
   linkend="wal-configuration"/>).
-->
<acronym>WAL</acronym>は自動的に有効になります。
<acronym>WAL</acronym>ファイルが必要とするディスク容量を確保することと、必要なチューニングを実施すること（<xref linkend="wal-configuration"/>を参照）以外は、管理者は何もする必要はありません。
  </para>

  <para>
<!--
   <acronym>WAL</acronym> records are appended to the <acronym>WAL</acronym>
   files as each new record is written. The insert position is described by
   a Log Sequence Number (<acronym>LSN</acronym>) that is a byte offset into
   the WAL, increasing monotonically with each new record.
   <acronym>LSN</acronym> values are returned as the datatype
   <link linkend="datatype-pg-lsn"><type>pg_lsn</type></link>. Values can be
   compared to calculate the volume of <acronym>WAL</acronym> data that
   separates them, so they are used to measure the progress of replication
   and recovery.
-->
新しいレコードが作成されるごとに、<acronym>WAL</acronym>レコードが<acronym>WAL</acronym>ファイルに追加されます。
挿入位置はログシーケンス番号(<acronym>LSN</acronym>)によって記録されます。LSNはWALのバイトオフセットで、新しいレコードごとに単調増加します。
<acronym>LSN</acronym>値は、<link linkend="datatype-pg-lsn"><type>pg_lsn</type></link>データ型として返されます。
2つの<acronym>LSN</acronym>値を比較することで<acronym>WAL</acronym>データの差分量を計算することができるので、レプリケーションやリカバリの進捗状況を測定できます。
  </para>

  <para>
<!--
   <acronym>WAL</acronym> files are stored in the directory
   <filename>pg_wal</filename> under the data directory, as a set of
   segment files, normally each 16 MB in size (but the size can be changed
   by altering the <option>&#45;-wal-segsize</option> <application>initdb</application> option).  Each segment is
   divided into pages, normally 8 kB each (this size can be changed via the
   <option>&#45;-with-wal-blocksize</option> configure option).  The WAL record headers
   are described in <filename>access/xlogrecord.h</filename>; the record
   content is dependent on the type of event that is being logged.  Segment
   files are given ever-increasing numbers as names, starting at
   <filename>000000010000000000000001</filename>.  The numbers do not wrap,
   but it will take a very, very long time to exhaust the
   available stock of numbers.
-->
<acronym>WAL</acronym>ファイルは、データディレクトリ以下の<filename>pg_wal</filename>ディレクトリに、通常16メガバイトのサイズを持つセグメントファイルの集合として格納されています(ただし、このサイズは<application>initdb</application>の<option>--wal-segsize</option>オプションで変更できます)。
各セグメントは通常8キロバイトのページに分割されます(このサイズは<option>--with-wal-blocksize</option>というconfigureオプションで変更できます)。
WALレコード用のヘッダは<filename>access/xlogrecord.h</filename>に記述されています。レコードの内容は、ログの対象となるイベントの種類によって異なります。
セグメントファイルは名前として<filename>000000010000000000000001</filename>から始まる、常に増加する数が与えられています。
数字は巡回しませんが、利用可能な数字を使い尽くすには非常に長い時間がかかるはずです。
  </para>

  <para>
<!--
   It is advantageous if the WAL is located on a different disk from the
   main database files.  This can be achieved by moving the
   <filename>pg_wal</filename> directory to another location (while the server
   is shut down, of course) and creating a symbolic link from the
   original location in the main data directory to the new location.
-->
主要なデータベースファイルが置いてあるディスクとは別のディスクにWALを置くと利点があります。
これは<filename>pg_wal</filename>ディレクトリを別の場所に（もちろんサーバを終了しておいてから）移動し、主データディレクトリ以下の元々の場所から新しい場所へのシンボリックリンクを張ることによって可能となります。
  </para>

  <para>
<!--
   The aim of <acronym>WAL</acronym> is to ensure that the log is
   written before database records are altered, but this can be subverted by
   disk drives<indexterm><primary>disk drive</primary></indexterm> that falsely report a
   successful write to the kernel,
   when in fact they have only cached the data and not yet stored it
   on the disk.  A power failure in such a situation might lead to
   irrecoverable data corruption.  Administrators should try to ensure
   that disks holding <productname>PostgreSQL</productname>'s
   <acronym>WAL</acronym> files do not make such false reports.
   (See <xref linkend="wal-reliability"/>.)
-->
<acronym>WAL</acronym>の目的である、確実にデータベースレコードが変更される前にログが書き出されることは、実際にはキャッシュにしかデータがなく、ディスクには格納されていない時にディスクドライブ<indexterm><primary>ディスクドライブ</primary></indexterm>が格納に成功したとカーネルに虚偽の報告を行うことによって失われる可能性があります。
そのような状況では、電源が落ちた際に、復旧不可能なデータ破損が起こることがあります。
管理者は、<productname>PostgreSQL</productname>の<acronym>WAL</acronym>ファイルを保持しているディスク装置がそのような嘘の報告をしないように保証するべきです。(<xref linkend="wal-reliability"/>を参照して下さい。)
  </para>

  <para>
<!--
   After a checkpoint has been made and the WAL flushed, the
   checkpoint's position is saved in the file
   <filename>pg_control</filename>. Therefore, at the start of recovery,
   the server first reads <filename>pg_control</filename> and
   then the checkpoint record; then it performs the REDO operation by
   scanning forward from the WAL location indicated in the checkpoint
   record.  Because the entire content of data pages is saved in the
   WAL on the first page modification after a checkpoint (assuming
   <xref linkend="guc-full-page-writes"/> is not disabled), all pages
   changed since the checkpoint will be restored to a consistent
   state.
-->
チェックポイントが実行され、WALがフラッシュされた後、チェックポイントの位置は<filename>pg_control</filename>に保存されます。
したがって、リカバリの開始時は、サーバはまず<filename>pg_control</filename>を読み、次にチェックポイントレコードを読みます。
そして、チェックポイントレコード内で示されたWALの位置から前方にスキャンしてREDO処理を行います。
データページの内容全体は、チェックポイント後の最初のページ変更時にWAL内に保存されますので(<xref linkend="guc-full-page-writes"/>パラメータが無効にされていないという前提です)、そのチェックポイント以降に変更された全てのページは一貫した状態に復旧されます。
  </para>

  <para>
<!--
   To deal with the case where <filename>pg_control</filename> is
   corrupt, we should support the possibility of scanning existing WAL
   segments in reverse order &mdash; newest to oldest &mdash; in order to find the
   latest checkpoint.  This has not been implemented yet.
   <filename>pg_control</filename> is small enough (less than one disk page)
   that it is not subject to partial-write problems, and as of this writing
   there have been no reports of database failures due solely to the inability
   to read <filename>pg_control</filename> itself.  So while it is
   theoretically a weak spot, <filename>pg_control</filename> does not
   seem to be a problem in practice.
-->
<filename>pg_control</filename>が壊れた場合に備え、既存のWALセグメントを逆順に読み（すなわち新しいものから古いものへと）、最終チェックポイントを見つける方法を実際には実装した方が良いと思われます。
まだこれはできていません。
<filename>pg_control</filename>はかなり小さなもの（1ディスクページ未満）ですので、一部のみ書き込みされるという問題は起こりません。
またこの書き込みの時点では、<filename>pg_control</filename>自体の読み込みができないことによるデータベースエラーという報告はありません。
このため、<filename>pg_control</filename>は理屈では弱点ですが、実質問題になりません。
  </para>
 </sect1>

</chapter>
